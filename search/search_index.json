{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to BioStatRx","text":"<p>Hi, I\u2019m Rahul.</p> <p>I\u2019m building BioStatRx to make biostatistics feel clearer and more usable\u2014through practical notes, real examples, and hands-on code in R and Python. If you\u2019re working with health data (or learning to), I hope this becomes a helpful place to return to.</p>"},{"location":"#a-bit-about-me","title":"A bit about me","text":"<p>I\u2019m originally from India and currently based in the United Kingdom.</p> <p>In 2020, I founded StatisticaHub, an e-tutoring platform where I\u2019ve mentored 500+ international students across mathematics and statistics courses (2020\u20132025). Teaching has shaped how I explain things: simple language, clean intuition, and focus on what actually works.</p>"},{"location":"#education","title":"Education","text":"<ul> <li>BSc (Statistics) \u2014 University of Delhi, India  </li> <li>MSc (Statistics) \u2014 IIT Kanpur, India  </li> <li>MSc (Medical Statistics &amp; Health Data Science) \u2014 University of Bristol, UK  </li> </ul>"},{"location":"#open-to-collaboration","title":"Open to collaboration","text":"<p>I\u2019m happy to collaborate on projects in:</p> <ul> <li>Biostatistics &amp; medical statistics</li> <li>Regression modeling (linear/logistic/Poisson/negative binomial)</li> <li>Survival analysis (Cox, time-dependent covariates, competing risks, frailty, recurrent events)</li> <li>Clinical research analytics + reproducible workflows</li> <li>Education content for health data science</li> </ul> <p>If you\u2019d like to work together, feel free to reach out.</p>"},{"location":"#contact","title":"Contact","text":"<ul> <li>Email: rahulbalwan1910@gmail.com </li> <li>LinkedIn: https://www.linkedin.com/in/rahul-yadav1910/</li> </ul>"},{"location":"#location","title":"Location","text":"<p>Current address: Bristol, United Kingdom</p>"},{"location":"Bayesian_Statistics/","title":"Bayesian Statistics","text":"<p>I am currently working on this module. Thankyou!!!</p>"},{"location":"Clinical_Trials/","title":"Clinical Trials","text":"<p>Clinical trials are the gold standard for evaluating medical interventions because they are designed to support causal inference. In biostatistics, clinical trials sit at the intersection of study design, probability, modeling, ethics, and reproducible reporting.</p> <p>This module is written for learners targeting biostatistics / medical statistics work (academia, industry, and public health). Each chapter mixes: - clear conceptual explanations - practical trial scenarios from biomedical settings - hands-on Python and R code - analysis and reporting workflows that mirror real trial practice</p>"},{"location":"Clinical_Trials/#what-you-will-learn","title":"What you will learn","text":"<p>By the end of this section, you should be able to:</p> <ul> <li>Explain why randomization supports causal inference and what can go wrong operationally</li> <li>Choose an appropriate design (parallel, cross-over, cluster, factorial, adaptive) for a biomedical question</li> <li>Define outcomes, endpoints, and estimands clearly (and handle intercurrent events)</li> <li>Perform sample size and power calculations for common endpoint types</li> <li>Understand ITT vs per-protocol vs as-treated analyses and handle missing data responsibly</li> <li>Summarize and model adverse events using both risk and exposure-adjusted rates</li> <li>Report trial results transparently with effect sizes, confidence intervals, and CONSORT-style structure</li> </ul>"},{"location":"Clinical_Trials/#chapters","title":"Chapters","text":"<ol> <li> <p>Foundations &amp; Phases    What clinical trials are, why they matter, and how phases I\u2013IV differ.</p> </li> <li> <p>Randomization &amp; Allocation Concealment    Simple/block/stratified randomization, concealment vs blinding, and practical list generation.</p> </li> <li> <p>Trial Designs    Parallel-group, cross-over, cluster randomized trials, factorial designs, and adaptive design overview.</p> </li> <li> <p>Outcomes, Endpoints, and Estimands    How to translate a clinical question into an estimand; handling rescue medication, switching, discontinuation, and other intercurrent events.</p> </li> <li> <p>Sample Size &amp; Power    Continuous, binary, and time-to-event power; dropout inflation; simulation-based power intuition.</p> </li> <li> <p>Analysis Populations &amp; Missing Data    ITT, PP, and as-treated; missing data mechanisms (MCAR/MAR/MNAR); multiple imputation in R and practical strategies in Python.</p> </li> <li> <p>Safety Analysis &amp; Adverse Events    AE/SAE/AESI concepts; participant incidence vs event rates; exposure-adjusted incidence; Poisson/negative binomial modeling for AE rates.</p> </li> <li> <p>Reporting &amp; Interpretation    CONSORT flow and tables, effect sizes and confidence intervals, forest plots, subgroup interpretation, and reproducibility best practices.</p> </li> </ol>"},{"location":"Clinical_Trials/#how-to-use-this-module","title":"How to use this module","text":"<p>A simple learning path: 1. Read Chapter 01 \u2192 04 to understand trial logic and definitions. 2. Use Chapter 05 to learn how design choices connect to sample size and feasibility. 3. Use Chapter 06 and 07 to build practical analysis skills. 4. Use Chapter 08 to learn how to present results professionally.</p>"},{"location":"Clinical_Trials/#suggested-prerequisites","title":"Suggested prerequisites","text":"<ul> <li>Basic probability and random variables</li> <li>Linear regression fundamentals</li> <li>Comfort with reading code in Python or R</li> </ul> <p>If needed, review: - Probability &amp; Statistics Review (Foundations section) - Regression module (especially linear and logistic regression)</p>"},{"location":"Clinical_Trials/#next-steps","title":"Next steps","text":"<p>If you want to extend Clinical Trials further, strong next topics are: - interim monitoring / group sequential designs - multiplicity and hierarchical testing - Bayesian trial designs - adaptive randomization and response-adaptive designs - pragmatic trials and real-world evidence links - estimands in survival and competing risks settings</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/","title":"Clinical Trials Foundations &amp; Phases","text":"<p>Clinical trials are the gold standard for answering causal questions in medicine and public health. Unlike observational studies, trials are designed to control bias (especially confounding) using randomization, structured follow-up, and pre-specified analysis plans.</p> <p>This chapter builds the foundation you\u2019ll need for the rest of the Clinical Trials module.</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#1-what-is-a-clinical-trial","title":"1. What is a clinical trial?","text":"<p>A clinical trial is a prospective study in which participants are assigned to one or more interventions to evaluate effects on health outcomes.</p> <p>Core features: - Prospective follow-up (time flows forward) - Intervention is assigned by the study (not chosen by the patient/doctor) - Outcomes are measured in a structured way</p> <p>In biostatistics, trials are mainly about: - estimating treatment effects - quantifying uncertainty (confidence intervals) - preventing biased inference</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#2-why-trials-are-special-vs-observational-studies","title":"2. Why trials are special (vs observational studies)","text":""},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#21-the-confounding-problem","title":"2.1 The confounding problem","text":"<p>In observational studies, treatment is not assigned randomly. People who receive treatment can differ systematically.</p> <p>Example: - sicker patients might be more likely to receive a new drug - patients with more resources might access better care</p> <p>These differences cause confounding, making treatment comparisons biased.</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#22-randomization-breaks-confounding-in-expectation","title":"2.2 Randomization breaks confounding (in expectation)","text":"<p>Randomization ensures that, on average, treatment groups are comparable at baseline: - measured covariates: age, sex, BMI, severity - unmeasured covariates: unknown risk factors</p> <p>So differences in outcome can be attributed to treatment (under assumptions).</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#3-key-trial-terminology","title":"3. Key trial terminology","text":""},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#31-intervention-treatment","title":"3.1 Intervention / treatment","text":"<p>What is being tested: - drug vs placebo - new therapy vs standard care - dose A vs dose B</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#32-control-group","title":"3.2 Control group","text":"<p>The comparison group could be: - placebo - standard-of-care - active comparator</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#33-outcome-and-endpoint","title":"3.3 Outcome and endpoint","text":"<ul> <li>Outcome: what is measured (e.g., blood pressure)</li> <li>Endpoint: the specific trial-defined quantity used for analysis (e.g., change in SBP at 12 weeks)</li> </ul>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#34-follow-up-time","title":"3.4 Follow-up time","text":"<p>Most trials have: - start time (randomization/baseline) - fixed follow-up schedule - final assessment window</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#35-censoring-time-to-event-trials","title":"3.5 Censoring (time-to-event trials)","text":"<p>If the endpoint is time-to-event: - participant may not experience the event during the study - we handle it using survival analysis methods</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#4-types-of-clinical-trials-high-level","title":"4. Types of clinical trials (high-level)","text":""},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#41-superiority-trials","title":"4.1 Superiority trials","text":"<p>Goal: show new treatment is better than control.</p> \\[ H_0: \\Delta \\le 0 \\quad \\text{vs} \\quad H_1: \\Delta &gt; 0 \\]"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#42-non-inferiority-trials","title":"4.2 Non-inferiority trials","text":"<p>Goal: show new treatment is not worse than control beyond a margin \\(\\delta\\).</p> \\[ H_0: \\Delta \\le -\\delta \\quad \\text{vs} \\quad H_1: \\Delta &gt; -\\delta \\] <p>Common when: - new treatment is cheaper, safer, or easier to deliver</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#43-equivalence-trials","title":"4.3 Equivalence trials","text":"<p>Goal: show treatments are similar within a margin.</p> \\[ -\\delta &lt; \\Delta &lt; \\delta \\]"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#5-trial-phases-iiv","title":"5. Trial phases (I\u2013IV)","text":"<p>Clinical trials are often discussed in phases (drug development context).</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#phase-i-safety-dose-first-in-human","title":"Phase I \u2014 Safety &amp; dose (first-in-human)","text":"<ul> <li>small sample (20\u201380)</li> <li>focus: safety, tolerability, dose-finding</li> <li>may include healthy volunteers or patients (oncology often patients)</li> </ul>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#phase-ii-preliminary-efficacy","title":"Phase II \u2014 Preliminary efficacy","text":"<ul> <li>moderate sample (100\u2013300)</li> <li>focus: efficacy signals + continued safety</li> <li>refine dose, endpoints, feasibility</li> </ul>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#phase-iii-confirmatory-trials","title":"Phase III \u2014 Confirmatory trials","text":"<ul> <li>large sample (hundreds to thousands)</li> <li>focus: definitive evidence of efficacy + safety</li> <li>designed for regulatory approval decisions</li> </ul>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#phase-iv-post-marketing-surveillance","title":"Phase IV \u2014 Post-marketing surveillance","text":"<ul> <li>after approval</li> <li>rare adverse events, long-term outcomes, real-world effectiveness</li> </ul>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#6-efficacy-vs-effectiveness","title":"6. Efficacy vs Effectiveness","text":""},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#efficacy","title":"Efficacy","text":"<ul> <li>\u201cDoes it work under ideal conditions?\u201d</li> <li>often in controlled settings, strict inclusion/exclusion criteria</li> </ul>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#effectiveness","title":"Effectiveness","text":"<ul> <li>\u201cDoes it work in real-world practice?\u201d</li> <li>pragmatic trials, broader populations, messy conditions</li> </ul> <p>Biostat tip: - pragmatic designs often need careful handling of adherence and missingness.</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#7-trial-protocol-and-statistical-analysis-plan-sap","title":"7. Trial protocol and statistical analysis plan (SAP)","text":"<p>Every trial should have: - protocol (clinical + operational plan) - SAP (exact statistical methods before seeing data)</p> <p>This reduces: - p-hacking - outcome switching - selective reporting</p> <p>Minimum SAP items: - primary endpoint definition - analysis population (ITT vs PP) - model and covariates - missing data strategy - multiplicity strategy (if relevant)</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#8-a-simple-trial-example-continuous-endpoint","title":"8. A simple trial example (continuous endpoint)","text":"<p>Imagine a parallel-group trial: - treatment vs placebo - outcome: systolic blood pressure at 12 weeks - compare mean change from baseline</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#key-estimand-plain-language","title":"Key estimand (plain language)","text":"<p>\u201cAverage difference in BP at 12 weeks between treatment and placebo, among all randomized patients.\u201d</p> <p>This is typically an ITT-type estimand.</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#9-interactive-simulation-python-why-randomization-matters","title":"9. Interactive simulation (Python): why randomization matters","text":"<p>We will simulate a scenario where: - treatment is associated with severity in observational allocation - randomization fixes it</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\nn = 600\n\n# Baseline severity (higher = worse)\nseverity = np.random.normal(0, 1, n)\n\n# True treatment effect (reduces outcome)\ntrue_effect = -0.6\n\n# Outcome depends on severity + treatment + noise\nnoise = np.random.normal(0, 1, n)\n\n# -------- Observational allocation (confounded) --------\n# People with higher severity more likely to receive treatment\np_treat_obs = 1 / (1 + np.exp(-1.2 * severity))\ntreat_obs = np.random.binomial(1, p_treat_obs)\n\noutcome_obs = 1.5 * severity + true_effect * treat_obs + noise\n\ndf_obs = pd.DataFrame({\"severity\": severity, \"treat\": treat_obs, \"outcome\": outcome_obs})\n\n# naive difference in means\nnaive_diff_obs = df_obs[df_obs.treat==1].outcome.mean() - df_obs[df_obs.treat==0].outcome.mean()\nnaive_diff_obs\n</code></pre> <p>Interpretation: - even though treatment truly helps, confounding can distort the estimate.</p> <p>Now compare to randomized allocation:</p> <p>Python</p> <pre><code># -------- Randomized allocation --------\ntreat_rct = np.random.binomial(1, 0.5, n)\noutcome_rct = 1.5 * severity + true_effect * treat_rct + noise\n\ndf_rct = pd.DataFrame({\"severity\": severity, \"treat\": treat_rct, \"outcome\": outcome_rct})\n\nnaive_diff_rct = df_rct[df_rct.treat==1].outcome.mean() - df_rct[df_rct.treat==0].outcome.mean()\nnaive_diff_rct\n</code></pre> <p>You should see the randomized estimate is much closer to the true effect.</p>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#10-interactive-simulation-r-why-randomization-matters","title":"10. Interactive simulation (R): why randomization matters","text":"<p>R</p> <pre><code>set.seed(42)\n\nn &lt;- 600\nseverity &lt;- rnorm(n, 0, 1)\n\ntrue_effect &lt;- -0.6\nnoise &lt;- rnorm(n, 0, 1)\n\n# Observational allocation (confounded)\np_treat_obs &lt;- 1 / (1 + exp(-1.2 * severity))\ntreat_obs &lt;- rbinom(n, 1, p_treat_obs)\n\noutcome_obs &lt;- 1.5 * severity + true_effect * treat_obs + noise\ndf_obs &lt;- data.frame(severity=severity, treat=treat_obs, outcome=outcome_obs)\n\nnaive_diff_obs &lt;- mean(df_obs$outcome[df_obs$treat==1]) - mean(df_obs$outcome[df_obs$treat==0])\nnaive_diff_obs\n</code></pre> <p>Randomized allocation:</p> <p>R</p> <pre><code>treat_rct &lt;- rbinom(n, 1, 0.5)\noutcome_rct &lt;- 1.5 * severity + true_effect * treat_rct + noise\ndf_rct &lt;- data.frame(severity=severity, treat=treat_rct, outcome=outcome_rct)\n\nnaive_diff_rct &lt;- mean(df_rct$outcome[df_rct$treat==1]) - mean(df_rct$outcome[df_rct$treat==0])\nnaive_diff_rct\n</code></pre>"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#11-exercises","title":"11. Exercises","text":"Click to try  1. Modify the confounding strength (change 1.2 to 2.0 in the logistic allocation) and see how the naive observational estimate changes.   2. Change the true treatment effect from -0.6 to -0.2 and repeat.   3. Increase sample size to 3000 and check how the randomized estimate stabilizes.   4. Plot severity distributions by group for observational vs randomized settings.   5. Think: Why does randomization work \u201cin expectation\u201d but not necessarily perfectly in small samples?"},{"location":"Clinical_Trials/01-clinical-trials-foundations-%26-phases/#12-summary","title":"12. Summary","text":"<ul> <li>Clinical trials are designed for causal inference.</li> <li>Randomization reduces confounding and improves validity.</li> <li>Trial phases (I\u2013IV) reflect safety \u2192 efficacy \u2192 confirmation \u2192 surveillance.</li> <li>Trials must define endpoints, populations, and analysis strategy before seeing results.</li> <li>Simulations show how observational allocation can bias treatment comparisons.</li> </ul>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/","title":"Randomization &amp; Allocation Concealment","text":"<p>Randomization is the design feature that makes a clinical trial fundamentally different from an observational study. It protects the treatment comparison from confounding and forms the basis for valid inference.</p> <p>However, randomization only works as intended when it is paired with allocation concealment (to prevent selection bias) and, when feasible, blinding (to reduce performance and assessment bias).</p> <p>This chapter explains the major randomization approaches used in clinical trials, the logic behind each, and how to implement them in both Python and R.</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#1-why-randomize","title":"1. Why randomize?","text":""},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#11-confounding-in-observational-treatment-comparisons","title":"1.1 Confounding in observational treatment comparisons","text":"<p>In observational studies, treatment is often related to prognosis. For example, sicker patients might be more likely to receive an aggressive therapy. If we compare treated vs untreated outcomes, the comparison mixes: - the effect of treatment - the baseline differences in patients</p> <p>This is the classic confounding problem.</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#12-what-randomization-accomplishes","title":"1.2 What randomization accomplishes","text":"<p>Randomization makes treatment assignment independent of baseline covariates in expectation.</p> <p>This implies: - groups are comparable on both measured and unmeasured prognostic factors on average - differences in outcomes can be attributed to treatment (under the trial\u2019s conditions) - standard statistical inference (confidence intervals, p-values) is justified by the design</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#13-in-expectation-vs-in-any-single-trial","title":"1.3 \u201cIn expectation\u201d vs \u201cin any single trial\u201d","text":"<p>Randomization guarantees balance on average across repeated trials. In any single realized trial, chance imbalances can occur, especially when sample size is small. This is normal and not evidence of trial failure.</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#2-allocation-concealment-vs-blinding","title":"2. Allocation concealment vs blinding","text":"<p>These two concepts are often confused. They address different biases.</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#21-allocation-concealment","title":"2.1 Allocation concealment","text":"<p>Allocation concealment means: - the person enrolling participants cannot predict or influence the next assignment</p> <p>It happens at the time of enrollment, before treatment is assigned.</p> <p>If allocation is not concealed, investigators may unconsciously alter enrollment behavior: - enrolling high-risk patients when they expect the better arm - delaying enrollment when they expect the worse arm</p> <p>This breaks comparability of groups.</p> <p>Common concealment methods: - centralized web/telephone randomization service - pharmacy-controlled dispensing - sequentially numbered, opaque, sealed envelopes (SNOSE) when done correctly</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#22-blinding","title":"2.2 Blinding","text":"<p>Blinding means: - participants, clinicians, and/or outcome assessors do not know treatment assignment</p> <p>It happens after assignment.</p> <p>Blinding reduces bias from: - differential co-interventions or care - placebo and behavioral effects - biased outcome assessment (especially for subjective outcomes)</p> <p>You can have: - concealed allocation without blinding - blinding without proper concealment (rare but possible) - both (ideal in many drug trials)</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#3-randomization-methods","title":"3. Randomization methods","text":""},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#31-simple-randomization","title":"3.1 Simple randomization","text":"<p>Each participant is assigned independently using a fixed probability.</p> <p>For 1:1 allocation:</p> \\[ P(\\mathrm{Treatment}) = 0.5,\\qquad P(\\mathrm{Control}) = 0.5 \\] <p>Pros: - simplest - strong unpredictability (good for concealment)</p> <p>Cons: - imbalance can occur in small trials (e.g., 14 vs 6 in a trial of n=20) - imbalance within sites (multicenter trials) is possible</p> <p>Best used in: - large trials where imbalance is unlikely to be problematic - settings where balance at interim time points is not crucial</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#32-block-randomization","title":"3.2 Block randomization","text":"<p>Block randomization forces balance within small blocks.</p> <p>Example: block size 4, 1:1 allocation Each block contains 2 treatment and 2 control assignments, in random order.</p> <p>Pros: - ensures near-perfect balance throughout enrollment - useful in small/medium sample trials - helpful when enrollment may stop early or when interim analyses occur</p> <p>Cons: - can become predictable if block size is fixed and known</p> <p>Mitigation: - use random block sizes (e.g., 4 and 6) - keep block structure hidden (allocation concealment)</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#33-unequal-allocation-ratios-eg-21","title":"3.3 Unequal allocation ratios (e.g., 2:1)","text":"<p>Sometimes trials allocate more patients to treatment: - more safety data on new therapy - recruitment incentives (higher chance to get active drug) - cost or ethical constraints</p> <p>If ratio is Treatment:Control = 2:1, then within a block size 6: - 4 treatment - 2 control</p> <p>Trade-off: - power is maximized near 1:1 for fixed total n - unequal allocation increases required sample size for same power</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#34-stratified-randomization","title":"3.4 Stratified randomization","text":"<p>Stratified randomization aims to balance groups within levels of important variables (strata), typically using block randomization inside each stratum.</p> <p>Common stratification factors: - center/site in multicenter trials - disease severity category - sex - prior treatment history</p> <p>Pros: - improves balance on strong prognostic variables - useful when sample is moderate and imbalance would harm credibility</p> <p>Cons: - too many strata becomes unmanageable - small strata might still be imbalanced due to sparse data</p> <p>Practical guidance: - stratify only on the most prognostic variables - keep number of strata modest</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#35-minimization-covariate-adaptive-randomization","title":"3.5 Minimization (covariate-adaptive randomization)","text":"<p>Minimization assigns treatment based on current imbalance across multiple covariates. Many implementations include a random component.</p> <p>Pros: - can balance several covariates even with small samples - useful when many baseline factors are critical</p> <p>Cons: - more complex to implement and audit - requires careful documentation and concealment - analysis often still uses standard ITT methods, but design must be described clearly</p> <p>Minimization is often run via specialized randomization systems rather than simple scripts.</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#4-baseline-balance-what-to-do-and-what-not-to-do","title":"4. Baseline balance: what to do and what not to do","text":""},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#41-what-to-do","title":"4.1 What to do","text":"<ul> <li>Provide a baseline characteristics table </li> <li>Look for clinically meaningful imbalances</li> <li>Pre-specify adjustment covariates</li> </ul>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#42-what-not-to-do-baseline-p-values","title":"4.2 What not to do: baseline p-values","text":"<p>Testing baseline differences with p-values is widely discouraged because: - under randomization, any imbalance is due to chance - baseline p-values do not diagnose trial quality - they encourage incorrect thinking about randomization</p> <p>Instead: - report descriptive summaries - optionally report standardized differences </p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#part-a-implementation-in-python","title":"Part A \u2014 Implementation in Python","text":"<p>The goal here is to generate reproducible randomization lists that you can actually use in a study workflow.</p> <p>We will show: - simple randomization - block randomization - random block sizes - stratified block randomization - 2:1 allocation example - quick checks for balance</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#5a-python-simple-randomization-11","title":"5A. Python: Simple randomization (1:1)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 40\nassignments = np.random.choice([\"Treatment\", \"Control\"], size=n, p=[0.5, 0.5])\n\nrand_list = pd.DataFrame({\n    \"participant_id\": range(1, n+1),\n    \"assignment\": assignments\n})\n\nrand_list[\"assignment\"].value_counts()\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#6a-python-block-randomization-fixed-block-size-11","title":"6A. Python: Block randomization (fixed block size, 1:1)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\ndef block_randomization(n, block_size=4, seed=42):\n    if block_size % 2 != 0:\n        raise ValueError(\"For 1:1 allocation, block_size must be even.\")\n    rng = np.random.default_rng(seed)\n\n    assignments = []\n    while len(assignments) &lt; n:\n        block = [\"Treatment\"]*(block_size//2) + [\"Control\"]*(block_size//2)\n        rng.shuffle(block)\n        assignments.extend(block)\n\n    assignments = assignments[:n]\n    return pd.DataFrame({\"participant_id\": range(1, n+1), \"assignment\": assignments})\n\nrand_block = block_randomization(n=40, block_size=4, seed=7)\nrand_block.head(12)\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#7a-python-random-block-sizes","title":"7A. Python: Random block sizes","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\ndef random_block_randomization(n, block_sizes=(4,6), seed=123):\n    rng = np.random.default_rng(seed)\n    assignments = []\n\n    while len(assignments) &lt; n:\n        b = int(rng.choice(block_sizes))\n        if b % 2 != 0:\n            continue\n\n        block = [\"Treatment\"]*(b//2) + [\"Control\"]*(b//2)\n        rng.shuffle(block)\n        assignments.extend(block)\n\n    assignments = assignments[:n]\n    return pd.DataFrame({\"participant_id\": range(1, n+1), \"assignment\": assignments})\n\nrand_rb = random_block_randomization(n=40, block_sizes=(4,6), seed=77)\nrand_rb[\"assignment\"].value_counts(), rand_rb.head(15)\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#8a-python-block-randomization-with-21-allocation","title":"8A. Python: Block randomization with 2:1 allocation","text":"<p>Treatment:Control = 2:1 A convenient block size is 6 (4 treatment, 2 control).</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\ndef block_randomization_ratio(n, ratio=(2,1), block_size=6, seed=123):\n    rng = np.random.default_rng(seed)\n\n    t, c = ratio\n    k = block_size // (t + c)\n    block = [\"Treatment\"]*(t*k) + [\"Control\"]*(c*k)\n\n    assignments = []\n    while len(assignments) &lt; n:\n        b = block.copy()\n        rng.shuffle(b)\n        assignments.extend(b)\n\n    assignments = assignments[:n]\n    return pd.DataFrame({\"participant_id\": range(1, n+1), \"assignment\": assignments})\n\nrand_21 = block_randomization_ratio(n=60, ratio=(2,1), block_size=6, seed=9)\nrand_21[\"assignment\"].value_counts()\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#9a-python-stratified-block-randomization","title":"9A. Python: Stratified block randomization","text":"<p>This is common in multicenter trials: - stratify by site - stratify by sex - within each stratum, block randomize with random block sizes</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(10)\n\nn = 80\ndf = pd.DataFrame({\n    \"participant_id\": range(1, n+1),\n    \"site\": np.random.choice([\"SiteA\", \"SiteB\", \"SiteC\"], size=n),\n    \"sex\": np.random.choice([\"F\", \"M\"], size=n)\n})\n\ndef stratified_randomization(df, strata_cols, block_sizes=(4,6), seed=123):\n    rng = np.random.default_rng(seed)\n    out = df.copy()\n    out[\"assignment\"] = None\n\n    for _, idx in out.groupby(strata_cols).groups.items():\n        m = len(idx)\n        sub_seed = int(rng.integers(1, 10**9))\n        sub = random_block_randomization(m, block_sizes=block_sizes, seed=sub_seed)\n        out.loc[list(idx), \"assignment\"] = sub[\"assignment\"].values\n\n    return out.sort_values(\"participant_id\")\n\ndf_rand = stratified_randomization(df, [\"site\", \"sex\"], block_sizes=(4,6), seed=5)\ndf_rand.head(12)\n</code></pre> <p>Quick balance check:</p> <p>Python</p> <pre><code>balance = df_rand.groupby([\"site\", \"sex\", \"assignment\"]).size().unstack(fill_value=0)\nbalance\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#part-b-implementation-in-r","title":"Part B \u2014 Implementation in R","text":"<p>R is frequently used by trial statisticians for randomization lists and audit-friendly scripts.</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#10b-r-simple-randomization-11","title":"10B. R: Simple randomization (1:1)","text":"<p>R</p> <pre><code>set.seed(123)\n\nn &lt;- 40\nassignment &lt;- sample(c(\"Treatment\", \"Control\"), n, replace=TRUE)\n\nrand_list &lt;- data.frame(\n  participant_id = 1:n,\n  assignment = assignment\n)\n\ntable(rand_list$assignment)\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#11b-r-block-randomization-fixed-block-size","title":"11B. R: Block randomization (fixed block size)","text":"<p>R</p> <pre><code>set.seed(7)\n\nblock_randomization &lt;- function(n, block_size=4) {\n  if (block_size %% 2 != 0) stop(\"For 1:1 allocation, block_size must be even.\")\n\n  assignments &lt;- c()\n\n  while (length(assignments) &lt; n) {\n    block &lt;- rep(c(\"Treatment\", \"Control\"), each=block_size/2)\n    block &lt;- sample(block, length(block))\n    assignments &lt;- c(assignments, block)\n  }\n\n  assignments &lt;- assignments[1:n]\n  data.frame(participant_id=1:n, assignment=assignments)\n}\n\nrand_block &lt;- block_randomization(40, block_size=4)\nhead(rand_block, 12)\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#12b-r-random-block-sizes","title":"12B. R: Random block sizes","text":"<p>R</p> <pre><code>set.seed(77)\n\nrandom_block_randomization &lt;- function(n, block_sizes=c(4,6)) {\n  assignments &lt;- c()\n\n  while (length(assignments) &lt; n) {\n    b &lt;- sample(block_sizes, 1)\n    if (b %% 2 != 0) next\n\n    block &lt;- rep(c(\"Treatment\", \"Control\"), each=b/2)\n    block &lt;- sample(block, length(block))\n    assignments &lt;- c(assignments, block)\n  }\n\n  assignments &lt;- assignments[1:n]\n  data.frame(participant_id=1:n, assignment=assignments)\n}\n\nrand_rb &lt;- random_block_randomization(40, block_sizes=c(4,6))\ntable(rand_rb$assignment)\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#13b-r-21-allocation-with-blocks","title":"13B. R: 2:1 allocation with blocks","text":"<p>For ratio 2:1, a block size of 6 gives: - 4 Treatment - 2 Control</p> <p>R</p> <pre><code>set.seed(9)\n\nblock_randomization_ratio &lt;- function(n, ratio=c(2,1), block_size=6) {\n  t &lt;- ratio[1]\n  c &lt;- ratio[2]\n  k &lt;- block_size / (t + c)\n  if (k != floor(k)) stop(\"Choose a block_size divisible by sum(ratio).\")\n\n  block &lt;- c(rep(\"Treatment\", t*k), rep(\"Control\", c*k))\n\n  assignments &lt;- c()\n  while (length(assignments) &lt; n) {\n    b &lt;- sample(block, length(block))\n    assignments &lt;- c(assignments, b)\n  }\n\n  assignments &lt;- assignments[1:n]\n  data.frame(participant_id=1:n, assignment=assignments)\n}\n\nrand_21 &lt;- block_randomization_ratio(60, ratio=c(2,1), block_size=6)\ntable(rand_21$assignment)\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#14b-r-stratified-block-randomization-by-site-and-sex","title":"14B. R: Stratified block randomization (by site and sex)","text":"<p>R</p> <pre><code>set.seed(10)\n\nn &lt;- 80\ndf &lt;- data.frame(\n  participant_id = 1:n,\n  site = sample(c(\"SiteA\",\"SiteB\",\"SiteC\"), n, replace=TRUE),\n  sex = sample(c(\"F\",\"M\"), n, replace=TRUE)\n)\n\nstratified_randomization &lt;- function(df, strata_cols=c(\"site\",\"sex\"), block_sizes=c(4,6)) {\n  out &lt;- df\n  out$assignment &lt;- NA\n\n  strata_key &lt;- interaction(out[, strata_cols], drop=TRUE)\n\n  for (s in levels(strata_key)) {\n    idx &lt;- which(strata_key == s)\n    m &lt;- length(idx)\n\n    a &lt;- random_block_randomization(m, block_sizes=block_sizes)$assignment\n    out$assignment[idx] &lt;- a\n  }\n\n  out[order(out$participant_id), ]\n}\n\ndf_rand &lt;- stratified_randomization(df, strata_cols=c(\"site\",\"sex\"), block_sizes=c(4,6))\nhead(df_rand, 12)\n</code></pre> <p>Balance check:</p> <p>R</p> <pre><code>with(df_rand, table(site, sex, assignment))\n</code></pre>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#15-practical-notes-for-real-trial-implementation","title":"15. Practical notes for real trial implementation","text":""},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#151-dont-treat-a-simple-script-as-the-full-randomization-system","title":"15.1 Don\u2019t treat a simple script as the full randomization system","text":"<p>In real regulated trials: - randomization must be auditable - list generation must be documented - access to the list must be restricted - concealment must be guaranteed operationally</p> <p>A script is typically used to generate a list that is then implemented via: - IRT/EDC system - pharmacy - central randomization service</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#152-document-decisions-clearly","title":"15.2 Document decisions clearly","text":"<p>Include in the protocol/SAP: - allocation ratio - method (simple/block/stratified) - block size policy (random sizes recommended) - stratification factors - who generates the list and who has access</p>"},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#16-exercises","title":"16. Exercises","text":"Click to try the exercises  1. Use Python or R to generate a randomization list for n=120 with 1:1 allocation using random block sizes (4 and 6).   2. Repeat the generation 100 times and record how often Treatment count differs from Control by more than 10 participants (simple randomization vs block randomization).   3. Create stratified randomization by site only and compare within-site imbalance to non-stratified randomization.   4. Write a short paragraph describing your randomization and concealment approach as if for a protocol.   5. Explain why fixed block size can create predictability and how random block sizes help."},{"location":"Clinical_Trials/02-randomization-%26-allocation-concealment/#17-summary","title":"17. Summary","text":"<p>Randomization protects treatment comparisons from confounding, but proper implementation matters: - simple randomization is unpredictable but can be imbalanced in small trials - block randomization improves balance but can be predictable if poorly implemented - stratified randomization improves balance on important prognostic factors - allocation concealment prevents selection bias and is essential even if blinding is not possible - baseline p-values are discouraged; use descriptive baseline tables instead</p>"},{"location":"Clinical_Trials/03-trial-designs/","title":"Trial Designs (Parallel, Cross-over, Cluster, Factorial, Adaptive)","text":"<p>A trial design is the blueprint that determines: - how participants are assigned to interventions - what comparisons are made - how outcomes are measured - what sources of bias and variability must be controlled</p> <p>In biostatistics, the design choice affects: - what causal question you can answer - sample size and power - the correct analysis method - how generalizable the results are</p> <p>This chapter covers the major clinical trial designs used in biomedical research, with clear guidance on when to use each design and how to analyze them in practice.</p>"},{"location":"Clinical_Trials/03-trial-designs/#1-parallel-group-randomized-controlled-trials","title":"1. Parallel-group randomized controlled trials","text":""},{"location":"Clinical_Trials/03-trial-designs/#11-what-it-is","title":"1.1 What it is","text":"<p>Participants are randomized to one of two or more groups and followed forward.</p> <p>Example: - Treatment vs Control - Dose A vs Dose B vs Placebo</p> <p>Each participant receives only one assigned intervention.</p>"},{"location":"Clinical_Trials/03-trial-designs/#12-strengths","title":"1.2 Strengths","text":"<ul> <li>simple interpretation</li> <li>minimal assumptions relative to other designs</li> <li>widely accepted by regulators</li> <li>works for many endpoint types: continuous, binary, time-to-event</li> </ul>"},{"location":"Clinical_Trials/03-trial-designs/#13-weaknesses","title":"1.3 Weaknesses","text":"<ul> <li>between-subject variability can be large</li> <li>may require larger sample size than within-subject designs</li> </ul>"},{"location":"Clinical_Trials/03-trial-designs/#14-typical-analysis","title":"1.4 Typical analysis","text":"<ul> <li>continuous outcome: two-sample t-test / linear regression</li> <li>binary outcome: chi-square / logistic regression</li> <li>time-to-event: log-rank / Cox regression</li> </ul>"},{"location":"Clinical_Trials/03-trial-designs/#2-cross-over-trials","title":"2. Cross-over trials","text":"<p>Cross-over designs are common when: - the condition is stable - the treatment effect is reversible - outcomes return to baseline after washout</p>"},{"location":"Clinical_Trials/03-trial-designs/#21-basic-22-cross-over-design","title":"2.1 Basic 2\u00d72 cross-over design","text":"<p>Each participant receives both treatments in different periods:</p> <ul> <li>Sequence 1: A \u2192 B</li> <li>Sequence 2: B \u2192 A</li> </ul> <p>Often includes a washout period between treatments.</p>"},{"location":"Clinical_Trials/03-trial-designs/#22-why-cross-over-is-efficient","title":"2.2 Why cross-over is efficient","text":"<p>Because each participant serves as their own control, variability is reduced.</p> <p>A simple way to think: - parallel design compares person-to-person differences - cross-over compares within-person differences</p> <p>This often increases power for the same \\(n\\).</p>"},{"location":"Clinical_Trials/03-trial-designs/#23-key-assumptions-and-problems","title":"2.3 Key assumptions and problems","text":"<ul> <li>Carryover effect: treatment effect persists into the next period</li> <li>Period effect: outcome changes across time regardless of treatment</li> <li>Washout adequacy: must remove lingering effects</li> <li>Dropout: can bias if not random</li> </ul> <p>Cross-over designs are not suitable for: - curative treatments - outcomes that permanently change after first treatment - progressive diseases where baseline changes over time</p>"},{"location":"Clinical_Trials/03-trial-designs/#24-typical-analysis-continuous-outcome","title":"2.4 Typical analysis (continuous outcome)","text":"<p>A standard model includes treatment and period effects, and accounts for repeated measures within subject:</p> \\[ Y_{ij} = \\beta_0 + \\beta_T T_{ij} + \\beta_P P_{ij} + b_i + \\varepsilon_{ij}, \\quad b_i \\sim \\mathcal{N}(0,\\sigma_b^2),\\ \\varepsilon_{ij}\\sim \\mathcal{N}(0,\\sigma^2) \\] <ul> <li>\\(i\\) indexes subject, \\(j\\) indexes period</li> <li>\\(T_{ij}\\) indicates treatment received in that period</li> <li>\\(P_{ij}\\) indicates period (1 or 2)</li> <li>\\(b_i\\) is a random subject effect</li> </ul> <p>(Sequence effects may be explored, but the above captures the core structure.)</p>"},{"location":"Clinical_Trials/03-trial-designs/#3-cluster-randomized-trials-crt","title":"3. Cluster randomized trials (CRT)","text":"<p>In a cluster randomized trial, the unit of randomization is a group (cluster), not an individual.</p> <p>Examples of clusters: - hospitals - schools - villages - clinics</p>"},{"location":"Clinical_Trials/03-trial-designs/#31-why-use-cluster-randomization","title":"3.1 Why use cluster randomization?","text":"<ul> <li>avoids contamination (e.g., education intervention would spill over)</li> <li>intervention naturally delivered at cluster level (policy, training)</li> <li>logistical reasons</li> </ul>"},{"location":"Clinical_Trials/03-trial-designs/#32-the-key-statistical-issue-intracluster-correlation-icc","title":"3.2 The key statistical issue: intracluster correlation (ICC)","text":"<p>Within a cluster, outcomes tend to be correlated.</p> <p>A common ICC definition (continuous outcomes):</p> \\[ \\rho = \\frac{\\sigma^2_{\\text{between}}}{\\sigma^2_{\\text{between}} + \\sigma^2_{\\text{within}}} \\] <p>Even small ICC can inflate required sample size.</p>"},{"location":"Clinical_Trials/03-trial-designs/#33-design-effect-effective-sample-size-reduction","title":"3.3 Design effect (effective sample size reduction)","text":"<p>For equal cluster size \\(m\\):</p> \\[ \\text{Design Effect} = 1 + (m-1)\\rho \\] <p>Effective sample size is approximately:</p> \\[ n_{\\text{eff}} \\approx \\frac{n}{\\text{Design Effect}} \\]"},{"location":"Clinical_Trials/03-trial-designs/#34-typical-analysis","title":"3.4 Typical analysis","text":"<p>You must account for clustering: - mixed effects models (random intercept for cluster) - GEEs with cluster-robust SE - cluster-level summary analyses (simple but less efficient)</p>"},{"location":"Clinical_Trials/03-trial-designs/#4-factorial-trials-testing-two-interventions-at-once","title":"4. Factorial trials (testing two interventions at once)","text":"<p>A common design is a 2\u00d72 factorial trial:</p> <ul> <li>Factor A: Drug vs No drug</li> <li>Factor B: Exercise vs No exercise</li> </ul> <p>Groups: 1. \\(A_0B_0\\) (control) 2. \\(A_1B_0\\) (drug only) 3. \\(A_0B_1\\) (exercise only) 4. \\(A_1B_1\\) (both)</p>"},{"location":"Clinical_Trials/03-trial-designs/#41-when-factorial-works-best","title":"4.1 When factorial works best","text":"<p>Factorial designs are most efficient when the two treatments: - act through different mechanisms - do not interact strongly</p>"},{"location":"Clinical_Trials/03-trial-designs/#42-main-effects-vs-interaction","title":"4.2 Main effects vs interaction","text":"<p>The key question is whether there is interaction:</p> \\[ Y = \\beta_0 + \\beta_A A + \\beta_B B + \\beta_{AB}(A\\times B) + \\varepsilon \\] <ul> <li>\\(\\beta_A\\) = main effect of A (averaged over B)</li> <li>\\(\\beta_B\\) = main effect of B</li> <li>\\(\\beta_{AB}\\) = interaction</li> </ul> <p>If interaction is large, interpretation becomes more complex and power for main effects can drop.</p>"},{"location":"Clinical_Trials/03-trial-designs/#5-adaptive-trial-designs","title":"5. Adaptive trial designs","text":"<p>Adaptive designs allow modifications based on interim data while controlling Type I error.</p> <p>Examples: - group sequential designs (early stopping) - sample size re-estimation - adaptive randomization (more weight to better arm) - multi-arm multi-stage (MAMS) designs</p> <p>Adaptive designs require: - careful pre-specification - an independent data monitoring committee - appropriate statistical control</p> <p>We keep this section conceptual; later pages can go deeper.</p>"},{"location":"Clinical_Trials/03-trial-designs/#part-a-simulations-and-analysis-in-python","title":"Part A \u2014 Simulations and analysis in Python","text":""},{"location":"Clinical_Trials/03-trial-designs/#6a-python-parallel-vs-cross-over-efficiency-simulation","title":"6A. Python: Parallel vs cross-over efficiency simulation","text":"<p>We simulate: - same treatment effect - compare standard error of estimated effect under two designs</p> <p>Python</p> <pre><code>import numpy as np\n\nnp.random.seed(202)\n\ndef simulate_parallel(n=60, effect=-1.0, sd=2.0):\n    trt = np.random.binomial(1, 0.5, n)\n    y = effect*trt + np.random.normal(0, sd, n)\n    est = y[trt==1].mean() - y[trt==0].mean()\n    return est\n\ndef simulate_crossover(n=30, effect=-1.0, sd_within=1.0):\n    # Each subject has a baseline level; both periods measured.\n    subj = np.random.normal(0, 1.0, n)\n\n    # Outcomes under A (treatment) and B (control)\n    y_A = subj + effect + np.random.normal(0, sd_within, n)\n    y_B = subj + 0.0    + np.random.normal(0, sd_within, n)\n\n    # Paired difference estimates treatment effect\n    est = (y_A - y_B).mean()\n    return est\n\nreps = 2000\npar_est = np.array([simulate_parallel() for _ in range(reps)])\ncro_est = np.array([simulate_crossover() for _ in range(reps)])\n\npar_est.std(), cro_est.std()\n</code></pre> <p>Interpretation: - Smaller SD of estimates means greater efficiency.</p>"},{"location":"Clinical_Trials/03-trial-designs/#7a-python-cluster-design-effect-calculation","title":"7A. Python: Cluster design effect calculation","text":"<p>Python</p> <pre><code>def design_effect(m, icc):\n    return 1 + (m - 1) * icc\n\nm = 25      # cluster size\nicc = 0.02  # intracluster correlation\nde = design_effect(m, icc)\nde\n</code></pre> <p>If your nominal sample size is \\(n\\) individuals: - effective \\(n\\) is about \\(n/\\text{DE}\\)</p>"},{"location":"Clinical_Trials/03-trial-designs/#8a-python-factorial-trial-simulation-with-interaction","title":"8A. Python: Factorial trial simulation with interaction","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\nnp.random.seed(777)\n\nn = 800\nA = np.random.binomial(1, 0.5, n)\nB = np.random.binomial(1, 0.5, n)\n\n# true model\nbeta0 = 0\nbetaA = -0.6\nbetaB = -0.4\nbetaAB = -0.8  # interaction (synergy)\n\ny = beta0 + betaA*A + betaB*B + betaAB*(A*B) + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({\"y\": y, \"A\": A, \"B\": B})\n\nfit = smf.ols(\"y ~ A + B + A:B\", data=df).fit()\nfit.summary().tables[1]\n</code></pre>"},{"location":"Clinical_Trials/03-trial-designs/#part-b-simulations-and-analysis-in-r","title":"Part B \u2014 Simulations and analysis in R","text":""},{"location":"Clinical_Trials/03-trial-designs/#9b-r-parallel-vs-cross-over-efficiency-simulation","title":"9B. R: Parallel vs cross-over efficiency simulation","text":"<p>R</p> <pre><code>set.seed(202)\n\nsimulate_parallel &lt;- function(n=60, effect=-1, sd=2) {\n  trt &lt;- rbinom(n, 1, 0.5)\n  y &lt;- effect*trt + rnorm(n, 0, sd)\n  mean(y[trt==1]) - mean(y[trt==0])\n}\n\nsimulate_crossover &lt;- function(n=30, effect=-1, sd_within=1) {\n  subj &lt;- rnorm(n, 0, 1)\n  yA &lt;- subj + effect + rnorm(n, 0, sd_within)\n  yB &lt;- subj + rnorm(n, 0, sd_within)\n  mean(yA - yB)\n}\n\nreps &lt;- 2000\npar_est &lt;- replicate(reps, simulate_parallel())\ncro_est &lt;- replicate(reps, simulate_crossover())\n\nsd(par_est)\nsd(cro_est)\n</code></pre>"},{"location":"Clinical_Trials/03-trial-designs/#10b-r-cluster-design-effect-calculation","title":"10B. R: Cluster design effect calculation","text":"<p>R</p> <pre><code>design_effect &lt;- function(m, icc) {\n  1 + (m-1)*icc\n}\n\nm &lt;- 25\nicc &lt;- 0.02\ndesign_effect(m, icc)\n</code></pre>"},{"location":"Clinical_Trials/03-trial-designs/#11b-r-factorial-trial-simulation-regression","title":"11B. R: Factorial trial simulation + regression","text":"<p>R</p> <pre><code>set.seed(777)\n\nn &lt;- 800\nA &lt;- rbinom(n, 1, 0.5)\nB &lt;- rbinom(n, 1, 0.5)\n\nbeta0 &lt;- 0\nbetaA &lt;- -0.6\nbetaB &lt;- -0.4\nbetaAB &lt;- -0.8\n\ny &lt;- beta0 + betaA*A + betaB*B + betaAB*(A*B) + rnorm(n, 0, 1)\n\ndf &lt;- data.frame(y=y, A=A, B=B)\n\nfit &lt;- lm(y ~ A + B + A:B, data=df)\nsummary(fit)\n</code></pre>"},{"location":"Clinical_Trials/03-trial-designs/#12-design-choice-guide","title":"12. Design choice guide","text":""},{"location":"Clinical_Trials/03-trial-designs/#parallel-group","title":"Parallel-group","text":"<p>Choose when: - outcomes irreversible or long-lasting - disease progresses over time - intervention has long-term effects</p>"},{"location":"Clinical_Trials/03-trial-designs/#cross-over","title":"Cross-over","text":"<p>Choose when: - condition stable - treatment effect reversible - outcome quickly measurable Avoid when: - carryover likely - disease progressive - long washout needed</p>"},{"location":"Clinical_Trials/03-trial-designs/#cluster-randomized","title":"Cluster randomized","text":"<p>Choose when: - contamination is likely - intervention is delivered at group level Remember: - account for ICC in sample size and analysis</p>"},{"location":"Clinical_Trials/03-trial-designs/#factorial","title":"Factorial","text":"<p>Choose when: - testing two interventions simultaneously - interaction expected to be small/moderate Plan: - pre-specify whether interaction will be tested formally</p>"},{"location":"Clinical_Trials/03-trial-designs/#adaptive","title":"Adaptive","text":"<p>Choose when: - early stopping or efficiency is needed Requires: - strong planning, governance, and pre-specified rules</p>"},{"location":"Clinical_Trials/03-trial-designs/#13-exercises","title":"13. Exercises","text":"Click to try  1. Modify the cross-over simulation so that carryover exists (e.g., add +0.4 to period 2 outcomes in one sequence) and see how it biases estimates if ignored.   2. Compute design effect for \\(m=10, 25, 50\\) across ICC \\(=0.01, 0.05, 0.10\\). Make a small table.   3. In factorial simulation, set \\(\\beta_{AB}=0\\) and compare how the interaction term behaves across repeated simulations.   4. Write a short paragraph: which design would you use for a vaccine education program delivered at school level, and why?   5. For a chronic stable condition with fast reversible effect, compare sample size needs of parallel vs cross-over conceptually."},{"location":"Clinical_Trials/03-trial-designs/#14-summary","title":"14. Summary","text":"<ul> <li>Parallel-group trials are the default and simplest to interpret.</li> <li>Cross-over trials gain efficiency but require strong assumptions (no carryover, stable condition).</li> <li>Cluster randomized trials need ICC-aware design and analysis.</li> <li>Factorial designs test multiple interventions efficiently but must consider interaction.</li> <li>Adaptive designs improve efficiency but require strict pre-planning and oversight.</li> </ul>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/","title":"Outcomes, Endpoints, and Estimands","text":"<p>Clinical trials are not just about collecting data \u2014 they are about answering a very specific question clearly and unambiguously.</p> <p>A common reason trials become confusing (or results become hard to interpret) is that the question is not precisely defined.</p> <p>This chapter teaches you how to define:</p> <ul> <li>Outcome (what is measured)</li> <li>Endpoint (what is analyzed)</li> <li>Estimand (what treatment effect you want to estimate)</li> <li>How to handle intercurrent events (treatment switching, rescue meds, death, dropout)</li> <li>How endpoint choice affects analysis, interpretation, and even trial success</li> </ul> <p>This is a practical biostatistics chapter: you will learn how to translate a clinical question into an analysis-ready estimand.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#1-outcome-vs-endpoint-vs-estimand","title":"1. Outcome vs endpoint vs estimand","text":""},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#11-outcome","title":"1.1 Outcome","text":"<p>An outcome is any measurement collected during the trial.</p> <p>Examples: - systolic blood pressure - HbA1c - tumor size - time-to-death - hospital admissions</p> <p>Outcomes may be collected at multiple times (baseline, week 4, week 12, etc.).</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#12-endpoint","title":"1.2 Endpoint","text":"<p>The endpoint is the trial-defined quantity derived from outcomes that will be analyzed.</p> <p>Examples: - change in systolic BP from baseline to week 12 - proportion achieving remission by week 24 - time from randomization to all-cause mortality</p> <p>A trial can collect many outcomes but must specify: - one primary endpoint - possibly multiple secondary endpoints</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#13-estimand-what-effect-are-we-trying-to-estimate","title":"1.3 Estimand (what effect are we trying to estimate?)","text":"<p>An estimand defines the treatment effect in a way that is robust to complications during follow-up.</p> <p>An estimand specifies: 1) Population 2) Treatment conditions (interventions) 3) Endpoint variable (how outcome is defined) 4) How intercurrent events are handled 5) Summary measure (difference in means, HR, RR, etc.)</p> <p>In plain language:</p> <p>The estimand is the precise question the trial is answering.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#2-primary-vs-secondary-endpoints","title":"2. Primary vs secondary endpoints","text":""},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#21-primary-endpoint","title":"2.1 Primary endpoint","text":"<ul> <li>drives trial success/failure</li> <li>determines sample size</li> <li>must be pre-specified</li> </ul> <p>Desirable properties: - clinically meaningful - measurable with low missingness - sensitive to treatment effect - not easily biased</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#22-secondary-endpoints","title":"2.2 Secondary endpoints","text":"<ul> <li>supportive evidence</li> <li>mechanistic outcomes</li> <li>safety-related outcomes</li> <li>exploratory biomarkers</li> </ul> <p>Statistical warning: - multiple endpoints increase false positives unless multiplicity is addressed</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#3-common-endpoint-types-in-biostatistics","title":"3. Common endpoint types in biostatistics","text":""},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#31-continuous-endpoints","title":"3.1 Continuous endpoints","text":"<p>Examples: - blood pressure (mmHg) - cholesterol levels - depression score - lung function (FEV1)</p> <p>Typical analysis: - t-test / ANCOVA / linear regression - mixed models for repeated measures (MMRM)</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#32-binary-endpoints","title":"3.2 Binary endpoints","text":"<p>Examples: - remission yes/no - event occurred yes/no - adverse event yes/no</p> <p>Typical analysis: - risk difference, risk ratio, odds ratio - logistic regression or log-binomial / Poisson with robust SE</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#33-count-endpoints","title":"3.3 Count endpoints","text":"<p>Examples: - number of hospital visits - infections per person-year</p> <p>Typical analysis: - Poisson or negative binomial regression (with offset if rate)</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#34-time-to-event-endpoints","title":"3.4 Time-to-event endpoints","text":"<p>Examples: - time to death - time to relapse - time to disease progression</p> <p>Typical analysis: - Kaplan\u2013Meier / log-rank - Cox regression - competing risks methods when appropriate</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#4-composite-endpoints","title":"4. Composite endpoints","text":"<p>Composite endpoints combine multiple events into one endpoint.</p> <p>Example: - major adverse cardiovascular events (MACE):   death OR MI OR stroke</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#41-why-use-composites","title":"4.1 Why use composites?","text":"<ul> <li>increases event rate (more power)</li> <li>captures multiple clinically relevant outcomes</li> </ul>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#42-pitfalls","title":"4.2 Pitfalls","text":"<ul> <li>components may differ in importance</li> <li>treatment may affect components differently</li> <li>interpretation becomes ambiguous</li> </ul> <p>Best practice: - report effect on the composite AND on each component.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#5-intercurrent-events-the-main-reason-estimands-matter","title":"5. Intercurrent events (the main reason estimands matter)","text":"<p>Intercurrent events happen after randomization and affect: - interpretation of outcomes - existence of outcome - whether outcome reflects the intended treatment effect</p> <p>Examples: - treatment discontinuation - rescue medication use - switching to another therapy - death before measurement - withdrawal / loss to follow-up</p> <p>Traditional trials sometimes handled these inconsistently. The estimand framework forces clarity.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#6-estimand-strategies-ich-e9r1-in-plain-language","title":"6. Estimand strategies (ICH E9(R1) in plain language)","text":"<p>We describe the most common strategies:</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#61-treatment-policy-strategy","title":"6.1 Treatment policy strategy","text":"<p>Ignore intercurrent events in the definition \u2014 analyze outcomes \u201cas observed\u201d regardless of switching/discontinuation.</p> <p>Interpretation:</p> <p>Effect of assigning the treatment, regardless of adherence.</p> <p>This often corresponds to ITT.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#62-hypothetical-strategy","title":"6.2 Hypothetical strategy","text":"<p>Ask:</p> <p>What would the outcome have been if the intercurrent event had not occurred?</p> <p>Example: - What would HbA1c be if no one used rescue medication?</p> <p>This requires modeling assumptions or imputation.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#63-composite-strategy","title":"6.3 Composite strategy","text":"<p>Make the intercurrent event part of the endpoint.</p> <p>Example: - define \u201cfailure\u201d as relapse OR rescue medication use</p> <p>Interpretation:</p> <p>Treatment effect on a broader clinical failure concept.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#64-while-on-treatment-strategy","title":"6.4 While-on-treatment strategy","text":"<p>Only consider outcomes while participants are on treatment.</p> <p>Interpretation:</p> <p>Effect of treatment during actual exposure.</p> <p>Danger: - can introduce bias if discontinuation relates to prognosis</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#65-principal-stratum-strategy","title":"6.5 Principal stratum strategy","text":"<p>Estimate effect within a latent subgroup defined by intercurrent event behavior.</p> <p>Example: - effect among those who would adhere under either treatment</p> <p>Powerful but complex and assumptions are strong.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#7-example-scenario-diabetes-trial-hba1c-at-24-weeks","title":"7. Example scenario: Diabetes trial (HbA1c at 24 weeks)","text":"<p>Trial: - New drug vs standard drug - Primary outcome: HbA1c at week 24 Complication: - some participants use rescue medication if glucose high</p> <p>Different estimands:</p> <p>1) Treatment policy: - compare HbA1c at week 24 regardless of rescue use</p> <p>2) Hypothetical: - estimate HbA1c if rescue medication had not been used</p> <p>3) Composite: - define failure as HbA1c above threshold OR rescue use</p> <p>Each answers a different clinical question.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#part-a-practical-simulations-python","title":"Part A \u2014 Practical simulations (Python)","text":"<p>We simulate a trial with rescue medication to show how estimand choice changes effect estimates.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#8a-python-simulation-rescue-medication-creates-complexity","title":"8A. Python simulation: rescue medication creates complexity","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\nn = 600\ntrt = np.random.binomial(1, 0.5, n)  # 1 = new drug, 0 = control\n\n# baseline HbA1c\nhba1c0 = np.random.normal(8.5, 0.8, n)\n\n# true treatment effect on HbA1c reduction\ntrue_delta = -0.6\nnoise = np.random.normal(0, 0.6, n)\n\n# Week 24 HbA1c if fully adherent and no rescue (latent)\nhba1c24_latent = hba1c0 + true_delta*trt + noise\n\n# Rescue medication used if latent HbA1c remains too high\nrescue = (hba1c24_latent &gt; 8.2).astype(int)\n\n# Rescue medication improves HbA1c by extra reduction (but only among those who take it)\nrescue_effect = -0.7\nhba1c24_observed = hba1c24_latent + rescue_effect*rescue\n\ndf = pd.DataFrame({\n    \"trt\": trt,\n    \"hba1c0\": hba1c0,\n    \"hba1c24_latent\": hba1c24_latent,\n    \"rescue\": rescue,\n    \"hba1c24_observed\": hba1c24_observed\n})\n\ndf.head()\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#9a-python-treatment-policy-estimand-use-observed-outcomes","title":"9A. Python: Treatment policy estimand (use observed outcomes)","text":"<p>Python</p> <pre><code># Treatment policy: compare observed HbA1c at 24 weeks\nmean_trt = df.loc[df.trt==1, \"hba1c24_observed\"].mean()\nmean_ctl = df.loc[df.trt==0, \"hba1c24_observed\"].mean()\nmean_trt - mean_ctl\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#10a-python-hypothetical-estimand-no-rescue-using-latent-outcome","title":"10A. Python: Hypothetical estimand (no rescue) using latent outcome","text":"<p>In real life, latent is unobserved; here we use it to show the concept.</p> <p>Python</p> <pre><code># Hypothetical: what if no rescue were used?\nmean_trt = df.loc[df.trt==1, \"hba1c24_latent\"].mean()\nmean_ctl = df.loc[df.trt==0, \"hba1c24_latent\"].mean()\nmean_trt - mean_ctl\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#11a-python-composite-estimand-failure-rescue-or-high-hba1c","title":"11A. Python: Composite estimand (failure = rescue OR high HbA1c)","text":"<p>Define failure as: - rescue used OR observed HbA1c &gt; 8.2</p> <p>Python</p> <pre><code>fail = ((df.rescue==1) | (df.hba1c24_observed &gt; 8.2)).astype(int)\nrate_trt = fail[df.trt==1].mean()\nrate_ctl = fail[df.trt==0].mean()\nrate_trt, rate_ctl, rate_trt - rate_ctl\n</code></pre> <p>Interpretation: - this answers a different question: risk of clinical \u201cfailure\u201d.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#part-b-practical-simulations-r","title":"Part B \u2014 Practical simulations (R)","text":""},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#12b-r-simulation-rescue-medication","title":"12B. R simulation: rescue medication","text":"<p>R</p> <pre><code>set.seed(42)\n\nn &lt;- 600\ntrt &lt;- rbinom(n, 1, 0.5)\n\nhba1c0 &lt;- rnorm(n, 8.5, 0.8)\ntrue_delta &lt;- -0.6\nnoise &lt;- rnorm(n, 0, 0.6)\n\nhba1c24_latent &lt;- hba1c0 + true_delta*trt + noise\n\nrescue &lt;- as.integer(hba1c24_latent &gt; 8.2)\n\nrescue_effect &lt;- -0.7\nhba1c24_observed &lt;- hba1c24_latent + rescue_effect*rescue\n\ndf &lt;- data.frame(\n  trt=trt,\n  hba1c0=hba1c0,\n  hba1c24_latent=hba1c24_latent,\n  rescue=rescue,\n  hba1c24_observed=hba1c24_observed\n)\n\nhead(df)\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#13b-r-treatment-policy-estimand-observed","title":"13B. R: Treatment policy estimand (observed)","text":"<p>R</p> <pre><code>mean(df$hba1c24_observed[df$trt==1]) - mean(df$hba1c24_observed[df$trt==0])\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#14b-r-hypothetical-estimand-no-rescue-using-latent-outcome","title":"14B. R: Hypothetical estimand (no rescue) using latent outcome","text":"<p>R</p> <pre><code>mean(df$hba1c24_latent[df$trt==1]) - mean(df$hba1c24_latent[df$trt==0])\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#15b-r-composite-estimand-failure","title":"15B. R: Composite estimand (failure)","text":"<p>R</p> <pre><code>fail &lt;- as.integer(df$rescue==1 | df$hba1c24_observed &gt; 8.2)\n\nrate_trt &lt;- mean(fail[df$trt==1])\nrate_ctl &lt;- mean(fail[df$trt==0])\n\nrate_trt\nrate_ctl\nrate_trt - rate_ctl\n</code></pre>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#16-how-to-write-endpointsestimands-in-a-protocol","title":"16. How to write endpoints/estimands in a protocol","text":"<p>Example template:</p> <p>Primary endpoint: HbA1c measured at 24 weeks post-randomization.</p> <p>Intercurrent event handling: Use of rescue medication will be handled using a treatment policy strategy (primary analysis). Sensitivity analyses using a hypothetical strategy will be conducted via multiple imputation assuming no rescue medication use.</p> <p>Population: All randomized participants (ITT).</p> <p>Summary measure: Difference in mean HbA1c between groups with 95% confidence interval.</p>"},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#17-exercises","title":"17. Exercises","text":"Click to try  1. Change the rescue threshold from 8.2 to 8.6 and see how the treatment policy estimate changes.   2. Increase the rescue effect magnitude (e.g., -1.2) and compare estimands.   3. Redefine the composite endpoint using a stricter cutoff (HbA1c &gt; 7.5).   4. Explain (in words) what clinical question each estimand answers.   5. In a time-to-event setting, propose intercurrent events and how you would handle them."},{"location":"Clinical_Trials/04-outcomes-endpoints-%26-estimands/#18-summary","title":"18. Summary","text":"<ul> <li>Outcomes are measurements; endpoints are analysis targets; estimands define the treatment effect question.</li> <li>Intercurrent events (switching, rescue, dropout) can change interpretation.</li> <li>Different estimand strategies answer different clinical questions.</li> <li>A well-written trial makes endpoints and estimands explicit before data is seen.</li> </ul>"},{"location":"Clinical_Trials/05-sample-size-%26-power/","title":"Sample Size &amp; Power","text":"<p>A clinical trial that is too small may fail to detect a clinically meaningful effect. A trial that is too large can waste resources or expose unnecessary participants to risk.</p> <p>Sample size planning is therefore both a scientific and ethical necessity.</p> <p>This chapter focuses on practical trial power calculations for common endpoint types:</p> <ul> <li>Continuous outcomes (difference in means)</li> <li>Binary outcomes (difference in proportions / risk)</li> <li>Time-to-event outcomes (log-rank / Cox; events drive power)</li> <li>Adjustments for dropout and non-adherence</li> <li>Simulation-based power (often the most intuitive)</li> </ul> <p>We provide implementations in R and Python.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#1-core-concepts-type-i-error-power-effect-size","title":"1. Core concepts: Type I error, power, effect size","text":""},{"location":"Clinical_Trials/05-sample-size-%26-power/#11-hypotheses","title":"1.1 Hypotheses","text":"<p>Most superiority trials test:</p> \\[ H_0: \\Delta = 0 \\quad \\text{vs} \\quad H_1: \\Delta \\ne 0 \\] <p>where \\(\\Delta\\) is the treatment effect (difference in means, difference in proportions, log hazard ratio, etc.).</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#12-type-i-error-alpha","title":"1.2 Type I error (\\(\\alpha\\))","text":"<p>Probability of rejecting \\(H_0\\) when \\(H_0\\) is true.</p> <p>Typical values: - 0.05 (two-sided) - 0.025 (one-sided)</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#13-power-1-beta","title":"1.3 Power (\\(1-\\beta\\))","text":"<p>Probability of detecting an effect if it truly exists.</p> <p>Common targets: - 80% power - 90% power</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#14-effect-size-clinically-meaningful-difference","title":"1.4 Effect size: clinically meaningful difference","text":"<p>You do not power a trial for \u201cany difference,\u201d you power it for a difference that matters clinically.</p> <p>Examples: - 5 mmHg reduction in systolic BP - 10% absolute increase in remission - hazard ratio 0.75 for mortality</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#2-general-sample-size-ingredients","title":"2. General sample size ingredients","text":"<p>To plan sample size you must specify: 1) primary endpoint type (continuous/binary/time-to-event) 2) effect size 3) variability (SD, baseline risk, hazard/event rate) 4) desired power 5) significance level 6) allocation ratio 7) expected dropout / loss-to-follow-up 8) design features (clustering, repeated measures, interim analyses)</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#3-continuous-outcomes-difference-in-means","title":"3. Continuous outcomes (difference in means)","text":""},{"location":"Clinical_Trials/05-sample-size-%26-power/#31-typical-setting","title":"3.1 Typical setting","text":"<p>Endpoint: change from baseline or post-treatment measurement.</p> <p>Common approach: - two-sample comparison (t-test) or regression-based comparison - ANCOVA-style planning can be approximated using an \u201ceffective SD\u201d</p> <p>Assume equal SD \\(\\sigma\\), 1:1 allocation, two-sided \\(\\alpha\\).</p> <p>The standardized effect size is:</p> \\[ d = \\frac{\\mu_1 - \\mu_0}{\\sigma} \\]"},{"location":"Clinical_Trials/05-sample-size-%26-power/#32-key-inputs","title":"3.2 Key inputs","text":"<ul> <li>\\(\\Delta = \\mu_1 - \\mu_0\\) (difference in means)</li> <li>\\(\\sigma\\) (SD)</li> <li>\\(\\alpha\\), power</li> <li>allocation ratio</li> </ul> <p>Practical note: Using ANCOVA (adjusting for baseline) often reduces variance and increases power. A common approximation is to use:</p> \\[ \\sigma_{\\text{eff}} = \\sigma \\sqrt{1-\\rho^2} \\] <p>where \\(\\rho\\) is the correlation between baseline and follow-up. (Higher \\(\\rho\\) \u2192 smaller \\(\\sigma_{\\text{eff}}\\) \u2192 more power.)</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#4-binary-outcomes-difference-in-proportions","title":"4. Binary outcomes (difference in proportions)","text":""},{"location":"Clinical_Trials/05-sample-size-%26-power/#41-typical-endpoints","title":"4.1 Typical endpoints","text":"<ul> <li>remission yes/no</li> <li>response yes/no</li> <li>event by fixed time yes/no</li> </ul> <p>Inputs: - control risk \\(p_0\\) - treatment risk \\(p_1\\)</p> <p>Effect measures: - absolute risk difference \\(p_1 - p_0\\) - risk ratio \\(p_1/p_0\\) - odds ratio (less intuitive clinically)</p> <p>Many standard power functions compute sample size for a difference in proportions using a normal approximation.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#5-time-to-event-outcomes-events-drive-power","title":"5. Time-to-event outcomes (events drive power)","text":"<p>For survival endpoints, power depends strongly on the number of events rather than the total sample size.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#51-hazard-ratio","title":"5.1 Hazard ratio","text":"<p>Common effect measure:</p> \\[ HR = \\frac{h_1(t)}{h_0(t)} \\] <p>If \\(HR &lt; 1\\), treatment reduces risk.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#52-event-based-approximation-log-rank","title":"5.2 Event-based approximation (log-rank)","text":"<p>A classic approximation (Freedman-type):</p> \\[ D \\approx \\frac{\\left(z_{1-\\alpha/2} + z_{1-\\beta}\\right)^2}{\\left(\\log HR\\right)^2 \\, p(1-p)} \\] <p>where: - \\(D\\) = required number of events - \\(p\\) = allocation proportion (0.5 for equal groups)</p> <p>Then total sample size depends on: - accrual time - follow-up time - baseline event rate - dropout / censoring</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#6-adjusting-for-dropout-loss-to-follow-up","title":"6. Adjusting for dropout / loss-to-follow-up","text":"<p>If you expect dropout proportion \\(r\\), inflate:</p> \\[ n_{\\text{adjusted}} = \\frac{n}{1-r} \\] <p>Example: - needed \\(n=200\\) - expect 15% dropout - adjusted \\(n = 200/0.85 = 235.3 \\rightarrow 236\\)</p> <p>In survival trials, dropout reduces observed events, so you may need additional inflation beyond this simple formula.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#part-a-practical-calculations-in-python","title":"Part A \u2014 Practical calculations in Python","text":"<p>Python\u2019s <code>statsmodels</code> provides power calculators for many common cases. For survival, we often use event-based calculations or simulations.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#7a-python-continuous-endpoint-sample-size-two-sample-t-test","title":"7A. Python: Continuous endpoint sample size (two-sample t-test)","text":"<p>Example: - target difference \\(\\Delta = 5\\) - SD = 12 - alpha = 0.05 - power = 0.80</p> <p>Python</p> <pre><code>from statsmodels.stats.power import TTestIndPower\n\ndelta = 5\nsd = 12\neffect_size = delta / sd\n\nanalysis = TTestIndPower()\nn_per_group = analysis.solve_power(\n    effect_size=effect_size,\n    alpha=0.05,\n    power=0.80,\n    ratio=1.0,\n    alternative=\"two-sided\"\n)\nn_per_group\n</code></pre> <p>Total \\(n \\approx 2 \\times n_{\\text{per group}}\\).</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#8a-python-binary-endpoint-sample-size-two-proportions","title":"8A. Python: Binary endpoint sample size (two proportions)","text":"<p>Example: - control response = 0.40 - treatment response = 0.55 - alpha = 0.05, power = 0.80</p> <p>Python</p> <pre><code>from statsmodels.stats.power import NormalIndPower\nfrom statsmodels.stats.proportion import proportion_effectsize\n\np0 = 0.40\np1 = 0.55\nes = proportion_effectsize(p1, p0)  # Cohen's h\n\nanalysis = NormalIndPower()\nn_per_group = analysis.solve_power(\n    effect_size=es,\n    alpha=0.05,\n    power=0.80,\n    ratio=1.0,\n    alternative=\"two-sided\"\n)\nn_per_group\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#9a-python-dropout-inflation-helper","title":"9A. Python: Dropout inflation helper","text":"<p>Python</p> <pre><code>import math\n\ndef inflate_dropout(n, dropout_rate):\n    return math.ceil(n / (1 - dropout_rate))\n\ninflate_dropout(200, 0.15)\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#10a-python-event-based-survival-calculation","title":"10A. Python: Event-based survival calculation","text":"<p>Example: - HR = 0.75 - alpha = 0.05 - power = 0.80 - equal allocation</p> <p>Python</p> <pre><code>import numpy as np\nfrom scipy.stats import norm\n\nalpha = 0.05\npower = 0.80\nHR = 0.75\np = 0.5\n\nz_alpha = norm.ppf(1 - alpha/2)\nz_beta = norm.ppf(power)\n\nD = ((z_alpha + z_beta)**2) / ((np.log(HR))**2 * p * (1 - p))\nD\n</code></pre> <p>This returns required number of events \\(D\\). To convert events into sample size, you need the expected event probability during follow-up (or simulate accrual/censoring).</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#11a-python-simulation-based-power-continuous-endpoint","title":"11A. Python: Simulation-based power (continuous endpoint)","text":"<p>Scenario: - n per group = 60 - SD = 12 - true difference = 5 - test: two-sample t-test - power estimated by repeated simulation</p> <p>Python</p> <pre><code>import numpy as np\nfrom scipy.stats import ttest_ind\n\nnp.random.seed(1)\n\ndef sim_power_continuous(n_per_group=60, delta=5, sd=12, reps=3000, alpha=0.05):\n    pvals = []\n    for _ in range(reps):\n        y0 = np.random.normal(0, sd, n_per_group)\n        y1 = np.random.normal(delta, sd, n_per_group)\n        pvals.append(ttest_ind(y1, y0, equal_var=True).pvalue)\n    return np.mean(np.array(pvals) &lt; alpha)\n\nsim_power_continuous(n_per_group=60, delta=5, sd=12, reps=2000)\n</code></pre> <p>Now vary \\(n\\) to see how power changes.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#part-b-practical-calculations-in-r","title":"Part B \u2014 Practical calculations in R","text":"<p>R is widely used for trial design because it has well-developed power and survival tools.</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#12b-r-continuous-endpoint-sample-size","title":"12B. R: Continuous endpoint sample size","text":"<p>R</p> <pre><code># Example: delta = 5, sd = 12, power = 0.80, alpha = 0.05\ndelta &lt;- 5\nsd &lt;- 12\n\npower.t.test(\n  delta = delta,\n  sd = sd,\n  power = 0.80,\n  sig.level = 0.05,\n  type = \"two.sample\",\n  alternative = \"two.sided\"\n)\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#13b-r-binary-endpoint-sample-size","title":"13B. R: Binary endpoint sample size","text":"<p>Example: - \\(p_0 = 0.40\\) - \\(p_1 = 0.55\\)</p> <p>R</p> <pre><code>p0 &lt;- 0.40\np1 &lt;- 0.55\n\npower.prop.test(\n  p1 = p0,\n  p2 = p1,\n  power = 0.80,\n  sig.level = 0.05,\n  alternative = \"two.sided\"\n)\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#14b-r-dropout-inflation","title":"14B. R: Dropout inflation","text":"<p>R</p> <pre><code>inflate_dropout &lt;- function(n, dropout_rate) ceiling(n / (1 - dropout_rate))\n\ninflate_dropout(200, 0.15)\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#15b-r-event-based-survival-calculation","title":"15B. R: Event-based survival calculation","text":"<p>R</p> <pre><code>alpha &lt;- 0.05\npower &lt;- 0.80\nHR &lt;- 0.75\np &lt;- 0.5\n\nz_alpha &lt;- qnorm(1 - alpha/2)\nz_beta &lt;- qnorm(power)\n\nD &lt;- ((z_alpha + z_beta)^2) / ((log(HR))^2 * p * (1 - p))\nD\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#16b-r-simulation-based-power-continuous-endpoint","title":"16B. R: Simulation-based power (continuous endpoint)","text":"<p>R</p> <pre><code>set.seed(1)\n\nsim_power_continuous &lt;- function(n_per_group=60, delta=5, sd=12, reps=2000, alpha=0.05) {\n  pvals &lt;- numeric(reps)\n  for (i in 1:reps) {\n    y0 &lt;- rnorm(n_per_group, 0, sd)\n    y1 &lt;- rnorm(n_per_group, delta, sd)\n    pvals[i] &lt;- t.test(y1, y0, var.equal=TRUE)$p.value\n  }\n  mean(pvals &lt; alpha)\n}\n\nsim_power_continuous(n_per_group=60, delta=5, sd=12)\n</code></pre>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#17-practical-guidance","title":"17. Practical guidance","text":""},{"location":"Clinical_Trials/05-sample-size-%26-power/#171-effect-size","title":"17.1 Effect size","text":"<p>Effect size should be: - clinically meaningful - realistic (based on prior studies or pilot data) - justified in the protocol</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#172-variability-event-rate","title":"17.2 Variability / event rate","text":"<p>Estimate from: - pilot studies - published literature - registry data - internal historical controls (use carefully)</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#173-sensitivity-analyses","title":"17.3 Sensitivity analyses","text":"<p>Always compute sample size under multiple plausible assumptions: - higher SD - lower effect - higher dropout - lower event probability (survival)</p> <p>Present as a table (best practice).</p>"},{"location":"Clinical_Trials/05-sample-size-%26-power/#18-exercises","title":"18. Exercises","text":"Click to try  1. Continuous endpoint: compute \\(n\\) per group for \\(\\Delta=3\\) and SD=12 (\\(\\alpha=0.05\\), power=0.80).   2. Binary endpoint: compute \\(n\\) per group for \\(p_0=0.30\\), \\(p_1=0.40\\).   3. Survival: compute required events for \\(HR=0.80\\) and \\(HR=0.70\\). Compare.   4. Use simulation to estimate power for \\(n\\) per group = 40, 60, 80 for \\(\\Delta=5\\), SD=12.   5. Apply dropout inflation: if you need 160 total participants and expect 20% dropout, how many should you recruit?"},{"location":"Clinical_Trials/05-sample-size-%26-power/#19-summary","title":"19. Summary","text":"<ul> <li>Sample size requires specifying effect size, variability/rates, \\(\\alpha\\), power, and allocation ratio.</li> <li>Continuous and binary endpoints have standard formula-based power methods.</li> <li>Time-to-event power is driven by the number of events; sample size depends on event probability during follow-up.</li> <li>Dropout inflates required recruitment.</li> <li>Simulation-based power provides an intuitive and flexible approach.</li> </ul>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/","title":"Analysis Populations (ITT, Per-Protocol, As-Treated) + Missing Data","text":"<p>A trial\u2019s design starts with randomization, but the credibility of results often depends on how we define:</p> <ul> <li>Who is included in the analysis? </li> <li>How do we handle missing outcomes and protocol deviations?</li> </ul> <p>This chapter covers the most important analysis populations: - Intention-to-treat (ITT) - Per-protocol (PP) - As-treated (AT)</p> <p>and provides practical strategies for handling missing data: - complete-case (when acceptable and when not) - multiple imputation (MI) - model-based approaches (likelihood / mixed models concept)</p> <p>We focus on biostatistical thinking: - what estimand each approach answers - what biases can enter - what to report in a paper/SAP</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#1-why-analysis-populations-matter","title":"1. Why analysis populations matter","text":"<p>Trials rarely run perfectly: - participants discontinue treatment - participants cross over or switch therapies - outcomes are missing due to dropout or missed visits - protocol deviations occur</p> <p>How you define the analysis population determines: - whether randomization is preserved - what causal question is being answered - whether results are biased</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#2-intention-to-treat-itt","title":"2. Intention-to-treat (ITT)","text":""},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#21-definition","title":"2.1 Definition","text":"<p>In the ITT principle, you analyze participants as randomized, regardless of: - adherence - switching - dropout (in principle; missingness still needs handling)</p> <p>Population: - usually \u201call randomized participants\u201d (sometimes called \u201cfull analysis set\u201d)</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#22-why-itt-is-the-default-primary-analysis","title":"2.2 Why ITT is the default primary analysis","text":"<ul> <li>preserves the benefits of randomization</li> <li>estimates the effect of \u201ctreatment policy\u201d:</li> <li>assigning the treatment in practice</li> <li>including real-world non-adherence</li> </ul> <p>Interpretation:</p> <p>What happens if we assign patients to this treatment strategy in clinical practice?</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#23-itt-does-not-mean-ignore-missing-data","title":"2.3 ITT does not mean \u201cignore missing data\u201d","text":"<p>A common misconception: - ITT is not \u201canalyze only those with observed outcomes\u201d - missingness must be addressed appropriately</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#3-per-protocol-pp","title":"3. Per-protocol (PP)","text":""},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#31-definition","title":"3.1 Definition","text":"<p>Per-protocol analysis includes only participants who: - adhered sufficiently to the protocol - had no major protocol deviations - met key eligibility criteria - received adequate exposure</p> <p>Different trials define PP differently, so PP must be clearly specified.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#32-what-pp-estimates","title":"3.2 What PP estimates","text":"<p>PP aims to estimate the effect of treatment under perfect adherence.</p> <p>Interpretation:</p> <p>What would the treatment effect be if everyone adhered as intended?</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#33-the-main-danger-selection-bias","title":"3.3 The main danger: selection bias","text":"<p>Once you exclude participants post-randomization based on adherence or deviations, groups may no longer be comparable.</p> <p>Adherence can relate to prognosis: - sicker participants may discontinue more - adverse events may cause discontinuation</p> <p>So PP can be biased unless handled carefully.</p> <p>PP is usually a sensitivity analysis, not primary.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#4-as-treated-at","title":"4. As-treated (AT)","text":""},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#41-definition","title":"4.1 Definition","text":"<p>Participants are analyzed according to what they actually received, not what they were randomized to.</p> <p>This is closer to observational analysis: - randomization is partially lost if switching occurs</p> <p>Interpretation:</p> <p>Effect of receiving treatment, rather than being assigned treatment.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#42-when-at-is-used","title":"4.2 When AT is used","text":"<p>Often used as: - secondary analysis - safety analysis - exploratory analysis</p> <p>Main risk: - confounding due to post-randomization switching</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#5-a-practical-trial-workflow-itt-primary-sensitivity-analyses","title":"5. A practical trial workflow: ITT primary + sensitivity analyses","text":"<p>A common robust plan is:</p> <p>Primary: - ITT analysis, aligned with the primary estimand</p> <p>Sensitivity: - PP analysis (carefully defined) - hypothetical estimand approaches (if relevant) - alternative missing data assumptions</p> <p>This allows readers and regulators to evaluate robustness.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#6-missing-data","title":"6. Missing data","text":"<p>Missing outcomes occur due to: - dropout - missed visits - withdrawal - administrative censoring - death (sometimes a competing event rather than \u201cmissing\u201d)</p> <p>Before choosing methods, understand why data are missing.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#7-missing-data-mechanisms","title":"7. Missing data mechanisms","text":""},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#71-mcar-missing-completely-at-random","title":"7.1 MCAR: Missing Completely At Random","text":"<p>Missingness does not depend on observed or unobserved data.</p> <p>Example: - lab machine failure on random days</p> <p>If MCAR holds, complete-case analysis can be unbiased (but still loses power).</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#72-mar-missing-at-random","title":"7.2 MAR: Missing At Random","text":"<p>Missingness may depend on observed data, but not on unobserved outcomes after conditioning.</p> <p>Example: - older participants miss visits more, but age is recorded</p> <p>Many standard methods (MI, likelihood) assume MAR.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#73-mnar-missing-not-at-random","title":"7.3 MNAR: Missing Not At Random","text":"<p>Missingness depends on unobserved outcomes even after conditioning on observed data.</p> <p>Example: - participants with worsening symptoms are more likely to drop out, and worsening is not fully captured by observed variables</p> <p>MNAR requires sensitivity analyses; it cannot be \u201cfixed\u201d by standard MI without assumptions.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#8-common-missing-data-approaches-in-trials","title":"8. Common missing-data approaches in trials","text":""},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#81-complete-case-analysis","title":"8.1 Complete-case analysis","text":"<p>Analyze only participants with observed outcomes.</p> <p>Pros: - simple</p> <p>Cons: - biased if missingness is related to outcomes (common in trials) - reduces power</p> <p>Acceptable only under strong conditions (rare).</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#82-single-imputation","title":"8.2 Single imputation","text":"<p>Examples: - last observation carried forward (LOCF) - baseline carried forward - mean imputation</p> <p>Problems: - can bias treatment effect - underestimates uncertainty - LOCF makes strong assumptions about disease trajectory</p> <p>Usually not recommended as primary for modern trials.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#83-multiple-imputation-mi","title":"8.3 Multiple imputation (MI)","text":"<p>MI fills in missing values multiple times to create several completed datasets. Each dataset is analyzed, then results are combined (Rubin\u2019s rules).</p> <p>Key advantages: - accounts for uncertainty in imputation - flexible for many outcome types - widely accepted if assumptions are justified</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#84-model-based-likelihood-methods-eg-mixed-models","title":"8.4 Model-based likelihood methods (e.g., mixed models)","text":"<p>For repeated continuous outcomes, mixed models (MMRM) can provide valid inference under MAR without explicit imputation.</p> <p>These are common in longitudinal clinical trials.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#part-a-practical-demonstration-in-python","title":"Part A \u2014 Practical demonstration in Python","text":"<p>Python has strong imputation tools; full Rubin\u2019s-rule MI for regression is less standard than in R, but we can still demonstrate correct workflow and make the logic clear.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#9a-python-simulate-a-trial-dataset-with-dropout","title":"9A. Python: Simulate a trial dataset with dropout","text":"<p>We simulate: - baseline severity - treatment effect - dropout that depends on worsening (MAR/MNAR-like depending on variables included)</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 500\ntrt = np.random.binomial(1, 0.5, n)\n\nseverity0 = np.random.normal(0, 1, n)\n# true treatment effect on outcome\ntrue_delta = -0.5\nnoise = np.random.normal(0, 1, n)\n\n# continuous outcome at follow-up\ny = 1.0*severity0 + true_delta*trt + noise\n\n# dropout probability depends on outcome (worse outcomes more likely to drop)\n# we don't observe y if dropped -&gt; MNAR-ish in truth\np_drop = 1 / (1 + np.exp(-0.8*(y - 0.5)))\ndrop = np.random.binomial(1, p_drop)\n\ny_obs = y.copy()\ny_obs[drop==1] = np.nan\n\ndf = pd.DataFrame({\"trt\": trt, \"severity0\": severity0, \"y_true\": y, \"y\": y_obs, \"drop\": drop})\ndf.head()\n</code></pre> <p>Check missingness rate by group:</p> <p>Python</p> <pre><code>df.groupby(\"trt\")[\"y\"].apply(lambda s: s.isna().mean())\n</code></pre>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#10a-python-itt-naive-complete-case-estimate-often-biased","title":"10A. Python: ITT naive complete-case estimate (often biased)","text":"<p>Python</p> <pre><code>cc = df.dropna(subset=[\"y\"])\nest_cc = cc.loc[cc.trt==1, \"y\"].mean() - cc.loc[cc.trt==0, \"y\"].mean()\nest_cc\n</code></pre> <p>Compare to the true ITT difference using the latent true outcome:</p> <p>Python</p> <pre><code>true_itt = df.loc[df.trt==1, \"y_true\"].mean() - df.loc[df.trt==0, \"y_true\"].mean()\ntrue_itt\n</code></pre> <p>If missingness is related to outcome, complete-case can distort the effect.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#11a-python-simple-imputation-mean-imputation-shown-only-to-demonstrate-why-its-weak","title":"11A. Python: Simple imputation (mean imputation) \u2014 shown only to demonstrate why it\u2019s weak","text":"<p>Python</p> <pre><code>df_meanimp = df.copy()\ndf_meanimp[\"y_imp\"] = df_meanimp[\"y\"].fillna(df_meanimp[\"y\"].mean())\n\nest_meanimp = df_meanimp.loc[df_meanimp.trt==1, \"y_imp\"].mean() - df_meanimp.loc[df_meanimp.trt==0, \"y_imp\"].mean()\nest_meanimp\n</code></pre> <p>Mean imputation can bias effect and understate uncertainty.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#12a-python-imputation-using-observed-covariates-mi-style-workflow","title":"12A. Python: Imputation using observed covariates (MI-style workflow)","text":"<p>We do a principled imputation using baseline severity and treatment as predictors.</p> <p>This is not full Rubin\u2019s-rule MI, but it shows the essential idea: - use observed data to predict missing outcomes</p> <p>Python</p> <pre><code>import statsmodels.api as sm\n\ndf_imp = df.copy()\n\n# Fit a regression model on observed cases\nobs = df_imp.dropna(subset=[\"y\"])\nX = sm.add_constant(obs[[\"trt\", \"severity0\"]])\nmodel = sm.OLS(obs[\"y\"], X).fit()\n\n# Predict missing y and add random noise based on residual SD (one stochastic imputation)\nmiss = df_imp[\"y\"].isna()\nXmiss = sm.add_constant(df_imp.loc[miss, [\"trt\", \"severity0\"]])\n\nresid_sd = obs[\"y\"].sub(model.predict(X)).std()\ny_pred = model.predict(Xmiss)\ndf_imp.loc[miss, \"y\"] = y_pred + np.random.normal(0, resid_sd, miss.sum())\n\n# ITT estimate after imputation\nest_imp = df_imp.loc[df_imp.trt==1, \"y\"].mean() - df_imp.loc[df_imp.trt==0, \"y\"].mean()\nest_imp\n</code></pre> <p>In real MI: - repeat this M times - analyze each dataset - pool estimates + SE via Rubin\u2019s rules R makes this easier and is standard for clinical trials.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#part-b-practical-multiple-imputation-in-r-recommended-for-trials","title":"Part B \u2014 Practical multiple imputation in R (recommended for trials)","text":"<p>We show MI using the <code>mice</code> package.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#13b-r-simulate-trial-with-dropout","title":"13B. R: Simulate trial with dropout","text":"<p>R</p> <pre><code>set.seed(123)\n\nn &lt;- 500\ntrt &lt;- rbinom(n, 1, 0.5)\nseverity0 &lt;- rnorm(n, 0, 1)\n\ntrue_delta &lt;- -0.5\nnoise &lt;- rnorm(n, 0, 1)\n\ny_true &lt;- 1.0*severity0 + true_delta*trt + noise\n\np_drop &lt;- 1 / (1 + exp(-0.8*(y_true - 0.5)))\ndrop &lt;- rbinom(n, 1, p_drop)\n\ny &lt;- y_true\ny[drop==1] &lt;- NA\n\ndf &lt;- data.frame(trt=trt, severity0=severity0, y=y, drop=drop, y_true=y_true)\nhead(df)\n</code></pre> <p>Missingness rate:</p> <p>R</p> <pre><code>tapply(is.na(df$y), df$trt, mean)\n</code></pre>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#14b-r-complete-case-itt-estimate-naive","title":"14B. R: Complete-case ITT estimate (naive)","text":"<p>R</p> <pre><code>cc &lt;- df[!is.na(df$y), ]\nest_cc &lt;- mean(cc$y[cc$trt==1]) - mean(cc$y[cc$trt==0])\nest_cc\n</code></pre> <p>True ITT (latent):</p> <p>R</p> <pre><code>true_itt &lt;- mean(df$y_true[df$trt==1]) - mean(df$y_true[df$trt==0])\ntrue_itt\n</code></pre>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#15b-r-multiple-imputation-using-mice","title":"15B. R: Multiple imputation using mice","text":"<p>If you don't have it installed: <code>install.packages(\"mice\")</code></p> <p>R</p> <pre><code>library(mice)\n\n# Use predictors: trt and severity0\nimp &lt;- mice(df[, c(\"trt\",\"severity0\",\"y\")], m=20, seed=202, printFlag=FALSE)\n\n# Fit the analysis model within each imputed dataset\nfit &lt;- with(imp, lm(y ~ trt + severity0))\n\n# Pool results (Rubin's rules)\npooled &lt;- pool(fit)\nsummary(pooled)\n</code></pre> <p>Interpretation: - coefficient of <code>trt</code> is the adjusted treatment effect estimate - MI accounts for uncertainty due to missingness under MAR assumptions (given included predictors)</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#16-sensitivity-analyses","title":"16. Sensitivity analyses","text":"<p>Because missingness may be MNAR, trials often include sensitivity analyses such as: - different imputation models - pattern-mixture models (e.g., shift imputed values down/up) - tipping-point analysis</p> <p>A simple \u201cdelta adjustment\u201d idea: - after imputation, subtract a fixed amount from imputed outcomes in one group to represent worse-than-assumed outcomes</p> <p>This is not a universal method, but it illustrates sensitivity thinking.</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#17-reporting-what-should-appear-in-a-trial-reportsap","title":"17. Reporting: what should appear in a trial report/SAP","text":"<p>For analysis populations: - define ITT (full analysis set) - define PP criteria explicitly - specify handling of protocol deviations</p> <p>For missing data: - describe extent and reasons for missingness - justify assumptions (MAR vs plausible MNAR) - specify primary method (MI or likelihood) - include sensitivity analyses</p>"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#18-exercises","title":"18. Exercises","text":"Click to try  1. Modify dropout so it depends on baseline severity only (more MAR-like). Compare CC vs MI estimates.   2. In the R MI example, increase number of imputations from 20 to 50 and see if results stabilize.   3. Create a PP dataset by excluding participants with severe baseline severity and compare ITT vs PP (note the bias risk).   4. Simulate treatment switching (e.g., some control patients switch if outcome is high) and discuss whether ITT and AT differ.   5. Write a short paragraph: which analysis population is primary and why?"},{"location":"Clinical_Trials/06-analysis-population-%26-missing-data/#19-summary","title":"19. Summary","text":"<ul> <li>ITT preserves randomization and is typically primary.</li> <li>PP and as-treated analyses can be biased because they break randomization.</li> <li>Missing data is not solved by simply dropping incomplete cases.</li> <li>Multiple imputation and likelihood-based methods provide principled handling under MAR assumptions.</li> <li>Sensitivity analyses are essential when MNAR is plausible.</li> </ul>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/","title":"Safety Analysis and Adverse Events (AE/SAE) + Practical Reporting","text":"<p>Efficacy is only half the story. In clinical trials, safety evaluation is equally important.</p> <p>Safety analysis answers questions like: - Is the new treatment associated with more adverse events? - Are there specific event types that occur more often? - Is the safety profile acceptable relative to benefits? - Do adverse events depend on exposure time?</p> <p>This chapter gives a practical, biostatistics-focused framework for analyzing and reporting safety data: - AE vs SAE vs AESI definitions - safety analysis populations - incidence proportions vs exposure-adjusted incidence rates (EAIR) - summary tables by event category (SOC/PT style) - lab abnormalities and shift tables - reproducible reporting in R and Python with toy data</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#1-key-safety-terminology","title":"1. Key safety terminology","text":"<p>Different trials have slightly different definitions, but the concepts are consistent.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#11-adverse-event-ae","title":"1.1 Adverse event (AE)","text":"<p>Any untoward medical occurrence after treatment starts, whether or not related to treatment.</p> <p>Important: - \u201cAE\u201d does not require causality. - If it happens after exposure, it can be recorded as an AE.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#12-serious-adverse-event-sae","title":"1.2 Serious adverse event (SAE)","text":"<p>Typically includes events such as: - death - life-threatening event - hospitalization or prolonged hospitalization - persistent disability or incapacity - congenital anomaly - other medically important event</p> <p>These are high-priority events for monitoring and reporting.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#13-adverse-event-of-special-interest-aesi","title":"1.3 Adverse event of special interest (AESI)","text":"<p>Events pre-specified as important due to: - known drug class risks - biological plausibility - earlier trial signals</p> <p>Example: - thrombosis with certain therapies - liver injury markers for hepatotoxic drugs</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#14-treatment-emergent-adverse-event-teae","title":"1.4 Treatment-emergent adverse event (TEAE)","text":"<p>A TEAE is an AE that begins (or worsens) after treatment initiation within a defined risk window.</p> <p>Safety reporting often focuses on TEAEs because they align with exposure.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#2-safety-analysis-populations","title":"2. Safety analysis populations","text":"<p>Safety analysis is usually based on an \u201cas-treated\u201d or \u201csafety set\u201d population.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#21-safety-set","title":"2.1 Safety set","text":"<p>All participants who received at least one dose of study treatment, analyzed according to treatment actually received.</p> <p>This differs from ITT because: - safety is linked to exposure, not assignment.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#22-why-not-always-itt-for-safety","title":"2.2 Why not always ITT for safety?","text":"<p>If someone is randomized but never takes treatment, counting them in safety summaries can dilute or distort safety risk.</p> <p>Safety analyses often use: - actual exposure time - risk windows - on-treatment vs intended treatment definitions</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#3-what-to-summarize-in-safety-analysis","title":"3. What to summarize in safety analysis?","text":"<p>Safety summaries usually include:</p> <p>1) Overall AE burden - number (%) with at least one AE - number (%) with at least one SAE - number (%) with discontinuation due to AE - number (%) with death</p> <p>2) Most common AEs - by system organ class (SOC) - by preferred term (PT) - often sorted by frequency</p> <p>3) Exposure-adjusted rates - events per person-year (often per 100 person-years) - important if follow-up differs between arms</p> <p>4) Severity and relatedness - mild/moderate/severe - related vs unrelated to treatment (reported, but interpret cautiously)</p> <p>5) Labs and vitals - shifts from baseline category to worst post-baseline category - threshold-based abnormality rates (e.g., ALT &gt; 3\u00d7 ULN)</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#4-incidence-proportion-vs-exposure-adjusted-incidence-rate-eair","title":"4. Incidence proportion vs exposure-adjusted incidence rate (EAIR)","text":""},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#41-incidence-proportion-risk","title":"4.1 Incidence proportion (risk)","text":"\\[ \\text{Risk} = \\frac{\\#\\text{participants with at least one event}}{\\#\\text{participants at risk}} \\] <p>This answers:</p> <p>What proportion of participants experienced at least one event?</p> <p>Use when: - follow-up time is similar - you want a participant-level interpretation</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#42-exposure-adjusted-incidence-rate-eair","title":"4.2 Exposure-adjusted incidence rate (EAIR)","text":"\\[ \\text{EAIR} = \\frac{\\#\\text{events}}{\\text{total person-time}} \\] <p>Often expressed per 100 person-years:</p> \\[ \\text{EAIR}_{100} = 100 \\times \\frac{\\#\\text{events}}{\\text{total person-years}} \\] <p>This answers:</p> <p>How frequently do events occur, accounting for time under observation?</p> <p>Use when: - follow-up differs between groups - events can repeat (multiple infections, multiple hospitalizations) - exposure time is clinically important</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#43-which-numerator-to-use-for-eair","title":"4.3 Which numerator to use for EAIR?","text":"<p>Two common choices: - number of participants with at least one event (first-event rate) - number of events (recurrent-event rate)</p> <p>You must clearly specify which.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#5-comparing-safety-between-groups-methods","title":"5. Comparing safety between groups (methods)","text":"<p>Safety comparisons are often descriptive, but inferential methods exist.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#51-risk-difference-risk-ratio","title":"5.1 Risk difference / risk ratio","text":"<p>For \u201cany AE yes/no\u201d: - compare proportions - compute confidence intervals for risk difference or risk ratio</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#52-poisson-negative-binomial-models-for-rates","title":"5.2 Poisson / negative binomial models for rates","text":"<p>For count outcomes (multiple events), with an offset:</p> \\[ \\log\\bigl(E[Y]\\bigr) = \\beta_0 + \\beta_1 \\,\\mathrm{Trt} + \\log(\\text{person-time}) \\] <p>Then: - \\(\\exp(\\beta_1)\\) is the rate ratio (treatment vs control)</p> <p>If overdispersion exists, use negative binomial.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#53-time-to-event-for-first-ae","title":"5.3 Time-to-event for first AE","text":"<p>You can use survival methods to analyze time to first AE.</p> <p>Important nuance: - time to first AE can be influenced by follow-up duration and competing risks (e.g., death).</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#part-a-practice-in-python","title":"Part A \u2014 Practice in Python","text":"<p>We generate toy AE data with: - participant-level exposure time - SOC and PT categories - recurrent event counts</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#6a-python-simulate-a-trial-safety-dataset","title":"6A. Python: Simulate a trial safety dataset","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(2026)\n\nn = 300\ntrt = np.random.binomial(1, 0.5, n)  # 1=treatment, 0=control\n\n# exposure time in days (treatment group slightly shorter, e.g., discontinuations)\nexposure_days = np.where(\n    trt == 1,\n    np.random.gamma(shape=5, scale=18, size=n),  # mean ~90\n    np.random.gamma(shape=5, scale=20, size=n)   # mean ~100\n)\n\nexposure_py = exposure_days / 365.25\n\n# AE event generation: Poisson rate depends on treatment\nbase_rate = 2.0  # events per person-year in control\nrate = np.where(trt == 1, base_rate * 1.25, base_rate)  # higher AE rate on treatment\nae_count = np.random.poisson(rate * exposure_py)\n\n# create SOC/PT categories for each AE event (event-level dataset)\nsocs = [\"Gastrointestinal disorders\", \"Nervous system disorders\", \"Infections\", \"Skin disorders\"]\npts_by_soc = {\n    \"Gastrointestinal disorders\": [\"Nausea\", \"Diarrhoea\", \"Abdominal pain\"],\n    \"Nervous system disorders\": [\"Headache\", \"Dizziness\"],\n    \"Infections\": [\"Upper respiratory infection\", \"Urinary tract infection\"],\n    \"Skin disorders\": [\"Rash\", \"Pruritus\"]\n}\n\nrows = []\nfor pid in range(1, n + 1):\n    k = ae_count[pid - 1]\n    if k == 0:\n        continue\n    for _ in range(k):\n        soc = np.random.choice(socs, p=[0.28, 0.26, 0.26, 0.20])\n        pt = np.random.choice(pts_by_soc[soc])\n        severity = np.random.choice([\"Mild\", \"Moderate\", \"Severe\"], p=[0.65, 0.30, 0.05])\n        sae = np.random.binomial(1, 0.04)  # rare SAEs\n        rows.append([pid, trt[pid - 1], soc, pt, severity, sae])\n\nae = pd.DataFrame(rows, columns=[\"participant_id\", \"trt\", \"SOC\", \"PT\", \"severity\", \"SAE\"])\n\n# participant-level frame\nsubj = pd.DataFrame({\n    \"participant_id\": range(1, n + 1),\n    \"trt\": trt,\n    \"exposure_days\": exposure_days,\n    \"exposure_py\": exposure_py,\n    \"ae_count\": ae_count\n})\n\nsubj.head(), ae.head()\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#7a-python-participant-level-safety-summary-at-least-one-ae-at-least-one-sae","title":"7A. Python: Participant-level safety summary (at least one AE, at least one SAE)","text":"<p>Python</p> <pre><code># indicator: at least one AE\nsubj[\"any_AE\"] = (subj[\"ae_count\"] &gt; 0).astype(int)\n\n# indicator: any SAE (participant-level)\nif len(ae) &gt; 0:\n    any_sae = ae.groupby(\"participant_id\")[\"SAE\"].max()\n    subj = subj.merge(any_sae.rename(\"any_SAE\"), left_on=\"participant_id\", right_index=True, how=\"left\")\n    subj[\"any_SAE\"] = subj[\"any_SAE\"].fillna(0).astype(int)\nelse:\n    subj[\"any_SAE\"] = 0\n\n# proportions by arm\nsummary = subj.groupby(\"trt\")[[\"any_AE\", \"any_SAE\"]].mean()\nsummary\n</code></pre> <p>Interpretation: - values are proportions (risk of any AE/SAE)</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#8a-python-exposure-adjusted-incidence-rate-eair","title":"8A. Python: Exposure-adjusted incidence rate (EAIR)","text":"<p>We compute: - total events / total person-years</p> <p>Python</p> <pre><code>eair = subj.groupby(\"trt\").apply(lambda d: d[\"ae_count\"].sum() / d[\"exposure_py\"].sum())\neair\n</code></pre> <p>Convert to events per 100 person-years:</p> <p>Python</p> <pre><code>(100 * eair).rename(\"events_per_100_person_years\")\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#9a-python-soc-and-pt-frequency-tables","title":"9A. Python: SOC and PT frequency tables","text":"<p>Often safety tables report: - number (%) of participants with at least one event in a category</p> <p>We compute participant-level incidence by SOC and PT.</p> <p>Python</p> <pre><code># participant-level SOC incidence: unique participants within each SOC\nif len(ae) &gt; 0:\n    soc_inc = (ae.groupby([\"trt\", \"SOC\", \"participant_id\"])\n                 .size()\n                 .reset_index(name=\"n\")\n                 .groupby([\"trt\", \"SOC\"])\n                 .size()\n                 .reset_index(name=\"n_participants\"))\n\n    denom = subj.groupby(\"trt\").size().rename(\"N\").reset_index()\n\n    soc_inc = soc_inc.merge(denom, on=\"trt\")\n    soc_inc[\"pct\"] = 100 * soc_inc[\"n_participants\"] / soc_inc[\"N\"]\n\n    soc_inc.sort_values([\"trt\", \"n_participants\"], ascending=[True, False]).head(10)\n</code></pre> <p>Similarly for PT:</p> <p>Python</p> <pre><code>if len(ae) &gt; 0:\n    pt_inc = (ae.groupby([\"trt\", \"PT\", \"participant_id\"])\n                .size()\n                .reset_index(name=\"n\")\n                .groupby([\"trt\", \"PT\"])\n                .size()\n                .reset_index(name=\"n_participants\"))\n\n    denom = subj.groupby(\"trt\").size().rename(\"N\").reset_index()\n\n    pt_inc = pt_inc.merge(denom, on=\"trt\")\n    pt_inc[\"pct\"] = 100 * pt_inc[\"n_participants\"] / pt_inc[\"N\"]\n\n    pt_inc.sort_values([\"trt\", \"n_participants\"], ascending=[True, False]).head(12)\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#10a-python-modeling-ae-counts-with-poisson-regression-rate-ratio","title":"10A. Python: Modeling AE counts with Poisson regression (rate ratio)","text":"<p>We fit:</p> \\[ \\log\\bigl(E[Y]\\bigr) = \\beta_0 + \\beta_1 \\,\\mathrm{trt} + \\log(\\text{person-years}) \\] <p>so \\(\\exp(\\beta_1)\\) is the AE rate ratio.</p> <p>Python</p> <pre><code>import statsmodels.api as sm\nimport numpy as np\n\nX = sm.add_constant(subj[\"trt\"])\nmodel = sm.GLM(\n    subj[\"ae_count\"],\n    X,\n    family=sm.families.Poisson(),\n    offset=np.log(subj[\"exposure_py\"])\n)\nfit = model.fit()\nfit.summary().tables[1]\n</code></pre> <p>Rate ratio estimate:</p> <p>Python</p> <pre><code>rr = float(np.exp(fit.params[\"trt\"]))\nrr\n</code></pre> <p>Overdispersion check (quick heuristic): - compare deviance to df_resid</p> <p>Python</p> <pre><code>fit.deviance / fit.df_resid\n</code></pre> <p>If this is much larger than ~1, consider negative binomial.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#part-b-practice-in-r","title":"Part B \u2014 Practice in R","text":""},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#11b-r-simulate-safety-dataset","title":"11B. R: Simulate safety dataset","text":"<p>R</p> <pre><code>set.seed(2026)\n\nn &lt;- 300\ntrt &lt;- rbinom(n, 1, 0.5)\n\nexposure_days &lt;- ifelse(\n  trt == 1,\n  rgamma(n, shape=5, scale=18),\n  rgamma(n, shape=5, scale=20)\n)\nexposure_py &lt;- exposure_days / 365.25\n\nbase_rate &lt;- 2.0\nrate &lt;- ifelse(trt == 1, base_rate * 1.25, base_rate)\nae_count &lt;- rpois(n, rate * exposure_py)\n\nsubj &lt;- data.frame(\n  participant_id = 1:n,\n  trt = trt,\n  exposure_days = exposure_days,\n  exposure_py = exposure_py,\n  ae_count = ae_count\n)\n\nhead(subj)\n</code></pre> <p>Create event-level AE data with SOC/PT:</p> <p>R</p> <pre><code>socs &lt;- c(\"Gastrointestinal disorders\", \"Nervous system disorders\", \"Infections\", \"Skin disorders\")\n\npts_by_soc &lt;- list(\n  \"Gastrointestinal disorders\" = c(\"Nausea\", \"Diarrhoea\", \"Abdominal pain\"),\n  \"Nervous system disorders\" = c(\"Headache\", \"Dizziness\"),\n  \"Infections\" = c(\"Upper respiratory infection\", \"Urinary tract infection\"),\n  \"Skin disorders\" = c(\"Rash\", \"Pruritus\")\n)\n\nae &lt;- data.frame()\n\nfor (pid in 1:n) {\n  k &lt;- ae_count[pid]\n  if (k == 0) next\n\n  for (j in 1:k) {\n    soc &lt;- sample(socs, 1, prob=c(0.28, 0.26, 0.26, 0.20))\n    pt &lt;- sample(pts_by_soc[[soc]], 1)\n    severity &lt;- sample(c(\"Mild\", \"Moderate\", \"Severe\"), 1, prob=c(0.65, 0.30, 0.05))\n    sae &lt;- rbinom(1, 1, 0.04)\n\n    ae &lt;- rbind(ae, data.frame(\n      participant_id = pid,\n      trt = trt[pid],\n      SOC = soc,\n      PT = pt,\n      severity = severity,\n      SAE = sae\n    ))\n  }\n}\n\nhead(ae)\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#12b-r-participant-level-safety-summary","title":"12B. R: Participant-level safety summary","text":"<p>R</p> <pre><code>subj$any_AE &lt;- as.integer(subj$ae_count &gt; 0)\n\nif (nrow(ae) &gt; 0) {\n  any_sae &lt;- aggregate(SAE ~ participant_id, data=ae, FUN=max)\n  subj &lt;- merge(subj, any_sae, by=\"participant_id\", all.x=TRUE)\n  subj$SAE[is.na(subj$SAE)] &lt;- 0\n  names(subj)[names(subj) == \"SAE\"] &lt;- \"any_SAE\"\n} else {\n  subj$any_SAE &lt;- 0\n}\n\naggregate(cbind(any_AE, any_SAE) ~ trt, data=subj, FUN=mean)\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#13b-r-exposure-adjusted-incidence-rate-eair","title":"13B. R: Exposure-adjusted incidence rate (EAIR)","text":"<p>R</p> <pre><code>eair &lt;- aggregate(cbind(ae_count, exposure_py) ~ trt, data=subj, FUN=sum)\neair$rate &lt;- eair$ae_count / eair$exposure_py\neair$rate_per_100py &lt;- 100 * eair$rate\neair\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#14b-r-soc-and-pt-incidence-participants-with-at-least-one-event","title":"14B. R: SOC and PT incidence (participants with at least one event)","text":"<p>R</p> <pre><code>denom &lt;- table(subj$trt)\n\nif (nrow(ae) &gt; 0) {\n  soc_inc &lt;- unique(ae[, c(\"trt\", \"SOC\", \"participant_id\")])\n  soc_tab &lt;- as.data.frame(table(soc_inc$trt, soc_inc$SOC))\n  names(soc_tab) &lt;- c(\"trt\", \"SOC\", \"n_participants\")\n  soc_tab$N &lt;- as.numeric(denom[as.character(soc_tab$trt)])\n  soc_tab$pct &lt;- 100 * soc_tab$n_participants / soc_tab$N\n\n  soc_tab[order(soc_tab$trt, -soc_tab$n_participants), ][1:10, ]\n}\n</code></pre> <p>PT incidence:</p> <p>R</p> <pre><code>if (nrow(ae) &gt; 0) {\n  pt_inc &lt;- unique(ae[, c(\"trt\", \"PT\", \"participant_id\")])\n  pt_tab &lt;- as.data.frame(table(pt_inc$trt, pt_inc$PT))\n  names(pt_tab) &lt;- c(\"trt\", \"PT\", \"n_participants\")\n  pt_tab$N &lt;- as.numeric(denom[as.character(pt_tab$trt)])\n  pt_tab$pct &lt;- 100 * pt_tab$n_participants / pt_tab$N\n\n  pt_tab[order(pt_tab$trt, -pt_tab$n_participants), ][1:12, ]\n}\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#15b-r-poisson-regression-for-ae-rate-ratio-with-offset","title":"15B. R: Poisson regression for AE rate ratio (with offset)","text":"<p>R</p> <pre><code>fit &lt;- glm(ae_count ~ trt + offset(log(exposure_py)), family=poisson(), data=subj)\nsummary(fit)\n\nrr &lt;- exp(coef(fit)[\"trt\"])\nrr\n</code></pre> <p>Overdispersion check:</p> <p>R</p> <pre><code>deviance(fit) / df.residual(fit)\n</code></pre> <p>If much larger than 1, consider negative binomial:</p> <p>R</p> <pre><code># install.packages(\"MASS\") if needed\nlibrary(MASS)\n\nfit_nb &lt;- glm.nb(ae_count ~ trt + offset(log(exposure_py)), data=subj)\nsummary(fit_nb)\n\nrr_nb &lt;- exp(coef(fit_nb)[\"trt\"])\nrr_nb\n</code></pre>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#16-lab-safety-and-shift-tables","title":"16. Lab safety and shift tables","text":"<p>Many trials monitor labs such as ALT/AST, creatinine, and neutrophils.</p> <p>A common reporting tool is a shift table: - baseline category (e.g., normal / high) - worst post-baseline category</p> <p>Example categories: - Normal - Grade 1 - Grade 2+</p> <p>based on clinical thresholds.</p> <p>Shift tables are descriptive but very informative for safety evaluation.</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#17-practical-reporting-guidance","title":"17. Practical reporting guidance","text":"<p>Safety reporting typically includes: - overall AE/SAE/discontinuation/death summary - most common AEs (SOC/PT) - exposure-adjusted rates if follow-up differs - severity breakdown - relationship to treatment (reported but interpret cautiously) - lab abnormality summaries</p> <p>Important reporting principle: - always provide denominators (N per arm) - clearly define the risk window (what counts as treatment-emergent)</p>"},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#18-exercises","title":"18. Exercises","text":"Click to try  1. Change `base_rate` from 2.0 to 1.0 and treatment multiplier from 1.25 to 1.10. Recompute EAIR and Poisson RR.   2. Make exposure time identical in both arms and compare incidence proportions vs EAIR. Do conclusions change?   3. Simulate a scenario with strong overdispersion (e.g., add subject-level frailty) and compare Poisson vs negative binomial.   4. Create a table of the top 5 PTs by incidence for each arm.   5. Define an AESI category (e.g., infections) and compute incidence proportion and rate ratio for that subset."},{"location":"Clinical_Trials/07-safety-analysis-adverse-events/#19-summary","title":"19. Summary","text":"<ul> <li>Safety analysis focuses on AEs/SAEs/AESIs, often in the safety set (exposed participants).</li> <li>Incidence proportions describe how many participants experience events.</li> <li>Exposure-adjusted rates account for different follow-up and recurrent events.</li> <li>Poisson/negative binomial models allow rate ratio estimation with person-time offsets.</li> <li>Clear, denominator-aware reporting is essential for interpretable safety results.</li> </ul>"},{"location":"Clinical_Trials/08-reporting/","title":"Reporting &amp; Interpretation","text":"<p>A clinical trial result is only useful if it is reported clearly and reproducibly.</p> <p>Good reporting is not just \u201cwriting well\u201d \u2014 it is about: - transparency in design and analysis - correct interpretation of effect sizes and uncertainty - communicating results so they can be trusted and reused</p> <p>In this chapter, we cover: - CONSORT reporting essentials - effect sizes + confidence intervals (what to emphasize) - common plots (Kaplan\u2013Meier, forest plot, effect plots) - subgroup analyses (and how to avoid misleading conclusions) - reproducible tables/figures in R and Python</p>"},{"location":"Clinical_Trials/08-reporting/#1-consort-the-standard-reporting-framework","title":"1. CONSORT: the standard reporting framework","text":"<p>CONSORT (Consolidated Standards of Reporting Trials) provides guidance for reporting randomized trials.</p> <p>Key components include: - trial design and allocation ratio - eligibility criteria and settings - interventions and follow-up - outcomes and sample size calculation - randomization method + concealment + blinding - participant flow (flow diagram) - baseline characteristics table - results for primary and secondary endpoints - harms (safety) - interpretation and generalizability - protocol registration and funding/conflicts</p> <p>Even if you don\u2019t memorize the checklist, your trial reporting should naturally answer: - Who was included? - What was compared? - How was bias controlled? - What was found, with uncertainty? - How robust are the results?</p>"},{"location":"Clinical_Trials/08-reporting/#2-participant-flow","title":"2. Participant flow","text":"<p>A typical flow includes: - assessed for eligibility - excluded (with reasons) - randomized - allocated to each group - follow-up completed and lost - analyzed (ITT, PP, safety)</p> <p>Even if the diagram is produced in a word processor, you should compute these counts from data.</p>"},{"location":"Clinical_Trials/08-reporting/#3-baseline-characteristics-table-table-1","title":"3. Baseline characteristics table (\u201cTable 1\u201d)","text":"<p>Baseline table is descriptive.</p> <p>Recommended content: - N randomized by arm - demographics: age, sex, race/ethnicity (context-dependent) - disease characteristics: baseline severity, stage, risk factors - key prognostic factors and stratification variables</p> <p>Important: - do not use p-values to \u201ctest baseline balance\u201d - report summaries and (optionally) standardized differences</p>"},{"location":"Clinical_Trials/08-reporting/#4-primary-endpoint-reporting-focus-on-effect-size-ci","title":"4. Primary endpoint reporting: focus on effect size + CI","text":"<p>The most important reporting elements are: - estimate of treatment effect - 95% confidence interval - p-value (secondary, not primary)</p> <p>Examples: - continuous: difference in means (adjusted or unadjusted) with CI - binary: risk difference / risk ratio / odds ratio with CI - time-to-event: hazard ratio with CI + KM curves</p> <p>Interpretation should answer: - Is the effect clinically meaningful? - How precise is the estimate? - Are conclusions robust to assumptions?</p>"},{"location":"Clinical_Trials/08-reporting/#5-interpreting-confidence-intervals-correctly","title":"5. Interpreting confidence intervals correctly","text":"<p>A 95% CI is not: - \u201cthere is a 95% probability the true effect is inside\u201d (frequentist CI interpretation is different)</p> <p>A practical interpretation:</p> <p>If we repeated this trial many times, 95% of such CIs would contain the true effect.</p> <p>For readers, CI gives: - direction and magnitude - plausible range of effects - whether results include \u201cno effect\u201d (0 for differences, 1 for ratios)</p>"},{"location":"Clinical_Trials/08-reporting/#6-subgroup-analyses-benefit-and-danger","title":"6. Subgroup analyses: benefit and danger","text":"<p>Subgroups are tempting but risky.</p>"},{"location":"Clinical_Trials/08-reporting/#61-why-subgroups-can-mislead","title":"6.1 Why subgroups can mislead","text":"<ul> <li>many subgroups \u2192 many false positives</li> <li>subgroups reduce sample size \u2192 unstable estimates</li> <li>\u201csignificant in subgroup A but not in subgroup B\u201d does not prove a difference</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#62-correct-approach-interaction-tests","title":"6.2 Correct approach: interaction tests","text":"<p>To test whether treatment differs by subgroup:</p> <p>Model: [ Y = \\beta_0 + \\beta_1 T + \\beta_2 S + \\beta_3(T \\times S) + \\epsilon ]</p> <ul> <li>\\(\\beta_3\\) is the interaction term</li> <li>interpret interaction CI and p-value, not separate subgroup p-values</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#63-recommended-reporting","title":"6.3 Recommended reporting","text":"<ul> <li>pre-specify subgroups</li> <li>show forest plot with estimates and CI</li> <li>interpret cautiously, emphasize exploratory unless strongly powered</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#7-key-plots-for-clinical-trial-reporting","title":"7. Key plots for clinical trial reporting","text":""},{"location":"Clinical_Trials/08-reporting/#71-continuous-endpoint-plots","title":"7.1 Continuous endpoint plots","text":"<ul> <li>mean change over time by arm (with CI bands)</li> <li>distribution plots (box/violin) if appropriate</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#72-binary-endpoint-plots","title":"7.2 Binary endpoint plots","text":"<ul> <li>bar plots of proportions with CI</li> <li>risk difference plot</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#73-time-to-event-plots","title":"7.3 Time-to-event plots","text":"<ul> <li>Kaplan\u2013Meier curves with number at risk</li> <li>cumulative incidence curves for competing risks</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#74-forest-plots","title":"7.4 Forest plots","text":"<ul> <li>subgroup effect estimates with CI</li> <li>helpful visual summary, but not proof of heterogeneity without interaction testing</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#8-reproducibility-minimal-standards","title":"8. Reproducibility: minimal standards","text":"<p>A reproducible trial analysis should: - fix package versions when possible - keep raw data separate from derived datasets - use scripted pipelines for tables/figures - include a clear \u201canalysis dataset\u201d construction step - log all outputs used in reporting</p> <p>Even for an educational site, teaching reproducibility builds professional habits.</p>"},{"location":"Clinical_Trials/08-reporting/#part-a-practical-reporting-workflow-in-python","title":"Part A \u2014 Practical reporting workflow in Python","text":"<p>We generate a toy parallel-group trial dataset and produce: - Table 1 baseline summary - primary endpoint estimate + CI - subgroup forest plot (illustration) - CONSORT-like counts summary</p>"},{"location":"Clinical_Trials/08-reporting/#9a-python-create-toy-trial-dataset","title":"9A. Python: Create toy trial dataset","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(100)\n\nn = 400\ntrt = np.random.binomial(1, 0.5, n)\n\nage = np.random.normal(55, 12, n)\nsex = np.random.binomial(1, 0.48, n)  # 1=male\nbaseline = np.random.normal(150, 18, n)  # baseline SBP\n\n# primary endpoint: SBP at week 12 (lower is better)\ntrue_delta = -6.0\ny = baseline + true_delta*trt + np.random.normal(0, 12, n)\n\n# dropout indicator (for reporting)\ndropout = np.random.binomial(1, 0.08, n)  # 8% missing\ny_obs = y.copy()\ny_obs[dropout==1] = np.nan\n\ndf = pd.DataFrame({\n    \"trt\": trt,\n    \"age\": age,\n    \"sex\": sex,\n    \"baseline_sbp\": baseline,\n    \"sbp12\": y_obs,\n    \"dropout\": dropout\n})\n\ndf.head()\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#10a-python-baseline-table-table-1","title":"10A. Python: Baseline table (\u201cTable 1\u201d)","text":"<p>We compute descriptive summaries by group.</p> <p>Python</p> <pre><code>def summarize_cont(x):\n    return pd.Series({\"mean\": x.mean(), \"sd\": x.std()})\n\ndef summarize_bin(x):\n    return pd.Series({\"n\": x.sum(), \"pct\": 100*x.mean()})\n\ntable1_age = df.groupby(\"trt\")[\"age\"].apply(summarize_cont).unstack()\ntable1_base = df.groupby(\"trt\")[\"baseline_sbp\"].apply(summarize_cont).unstack()\ntable1_sex = df.groupby(\"trt\")[\"sex\"].apply(summarize_bin).unstack()\n\ntable1_age, table1_base, table1_sex\n</code></pre> <p>You can format these for display in the site as markdown tables if desired.</p>"},{"location":"Clinical_Trials/08-reporting/#11a-python-primary-endpoint-effect-estimate-with-ci-ancova","title":"11A. Python: Primary endpoint effect estimate with CI (ANCOVA)","text":"<p>ANCOVA often improves precision: [ \\text{SBP}_{12} = \\beta_0 + \\beta_1 T + \\beta_2 \\text{baseline} + \\epsilon ]</p> <p>Here \\(\\beta_1\\) estimates adjusted mean difference.</p> <p>Python</p> <pre><code>import statsmodels.formula.api as smf\n\ndfa = df.dropna(subset=[\"sbp12\"]).copy()\nfit = smf.ols(\"sbp12 ~ trt + baseline_sbp\", data=dfa).fit()\nfit.summary().tables[1]\n</code></pre> <p>Extract estimate + 95% CI:</p> <p>Python</p> <pre><code>est = fit.params[\"trt\"]\nci = fit.conf_int().loc[\"trt\"].tolist()\nest, ci\n</code></pre> <p>Interpretation: - if estimate is negative, treatment lowers SBP relative to control</p>"},{"location":"Clinical_Trials/08-reporting/#12a-python-consort-style-counts","title":"12A. Python: CONSORT-style counts","text":"<p>Python</p> <pre><code>consort = pd.DataFrame({\n    \"randomized\": df.groupby(\"trt\").size(),\n    \"missing_primary\": df.groupby(\"trt\")[\"sbp12\"].apply(lambda s: s.isna().sum()),\n    \"analyzed_primary\": df.groupby(\"trt\")[\"sbp12\"].apply(lambda s: s.notna().sum())\n})\nconsort\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#13a-python-forest-plot-for-subgroup-effects-illustration","title":"13A. Python: Forest plot for subgroup effects (illustration)","text":"<p>Subgroup: sex (male vs female)</p> <p>We estimate treatment effect within subgroup (descriptive) and show forest plot. The correct formal test is interaction (shown after).</p> <p>Python</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\neffects = []\nlabels = []\ncis = []\n\nfor s, name in [(0, \"Female\"), (1, \"Male\")]:\n    sub = dfa[dfa.sex==s]\n    f = smf.ols(\"sbp12 ~ trt + baseline_sbp\", data=sub).fit()\n    est = f.params[\"trt\"]\n    lo, hi = f.conf_int().loc[\"trt\"]\n    labels.append(name)\n    effects.append(est)\n    cis.append((lo, hi))\n\neffects = np.array(effects)\nlo = np.array([c[0] for c in cis])\nhi = np.array([c[1] for c in cis])\n\ny = np.arange(len(labels))\n\nplt.figure()\nplt.hlines(y, lo, hi)\nplt.plot(effects, y, marker=\"o\", linestyle=\"None\")\nplt.yticks(y, labels)\nplt.axvline(0, linestyle=\"--\")\nplt.xlabel(\"Treatment effect (adjusted mean difference)\")\nplt.title(\"Subgroup effects (illustration)\")\nplt.show()\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#14a-python-interaction-test-correct-subgroup-inference","title":"14A. Python: Interaction test (correct subgroup inference)","text":"<p>Python</p> <pre><code>fit_int = smf.ols(\"sbp12 ~ trt * sex + baseline_sbp\", data=dfa).fit()\nfit_int.summary().tables[1]\n</code></pre> <p>Interpretation: - the <code>trt:sex</code> term is the interaction - if it is near 0 with wide CI, evidence for heterogeneity is weak</p>"},{"location":"Clinical_Trials/08-reporting/#part-b-practical-reporting-workflow-in-r","title":"Part B \u2014 Practical reporting workflow in R","text":""},{"location":"Clinical_Trials/08-reporting/#15b-r-create-toy-trial-dataset","title":"15B. R: Create toy trial dataset","text":"<p>R</p> <pre><code>set.seed(100)\n\nn &lt;- 400\ntrt &lt;- rbinom(n, 1, 0.5)\n\nage &lt;- rnorm(n, 55, 12)\nsex &lt;- rbinom(n, 1, 0.48)\nbaseline &lt;- rnorm(n, 150, 18)\n\ntrue_delta &lt;- -6\ny &lt;- baseline + true_delta*trt + rnorm(n, 0, 12)\n\ndropout &lt;- rbinom(n, 1, 0.08)\ny_obs &lt;- y\ny_obs[dropout==1] &lt;- NA\n\ndf &lt;- data.frame(\n  trt=trt,\n  age=age,\n  sex=sex,\n  baseline_sbp=baseline,\n  sbp12=y_obs,\n  dropout=dropout\n)\n\nhead(df)\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#16b-r-baseline-table-table-1","title":"16B. R: Baseline table (\u201cTable 1\u201d)","text":"<p>R</p> <pre><code># continuous summaries\ntapply(df$age, df$trt, function(x) c(mean=mean(x), sd=sd(x)))\ntapply(df$baseline_sbp, df$trt, function(x) c(mean=mean(x), sd=sd(x)))\n\n# binary summary: sex=1\ntapply(df$sex, df$trt, function(x) c(n=sum(x), pct=100*mean(x)))\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#17b-r-primary-endpoint-analysis-with-ancova","title":"17B. R: Primary endpoint analysis with ANCOVA","text":"<p>R</p> <pre><code>dfa &lt;- df[!is.na(df$sbp12), ]\n\nfit &lt;- lm(sbp12 ~ trt + baseline_sbp, data=dfa)\nsummary(fit)\n\n# treatment effect estimate and CI\nest &lt;- coef(fit)[\"trt\"]\nci &lt;- confint(fit)[\"trt\", ]\nest\nci\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#18b-r-consort-style-counts","title":"18B. R: CONSORT-style counts","text":"<p>R</p> <pre><code>randomized &lt;- table(df$trt)\nmissing_primary &lt;- tapply(is.na(df$sbp12), df$trt, sum)\nanalyzed_primary &lt;- tapply(!is.na(df$sbp12), df$trt, sum)\n\ndata.frame(\n  trt = names(randomized),\n  randomized = as.numeric(randomized),\n  missing_primary = as.numeric(missing_primary),\n  analyzed_primary = as.numeric(analyzed_primary)\n)\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#19b-r-forest-plot-for-subgroup-effects-illustration","title":"19B. R: Forest plot for subgroup effects (illustration)","text":"<p>R</p> <pre><code># subgroup by sex\neffects &lt;- c()\nlo &lt;- c()\nhi &lt;- c()\nlabels &lt;- c(\"Female\",\"Male\")\n\nfor (s in c(0,1)) {\n  sub &lt;- dfa[dfa$sex==s, ]\n  f &lt;- lm(sbp12 ~ trt + baseline_sbp, data=sub)\n  est &lt;- coef(f)[\"trt\"]\n  ci &lt;- confint(f)[\"trt\", ]\n  effects &lt;- c(effects, est)\n  lo &lt;- c(lo, ci[1])\n  hi &lt;- c(hi, ci[2])\n}\n\n# simple base R forest-like plot\nplot(effects, 1:2, xlim=range(c(lo,hi)), yaxt=\"n\",\n     xlab=\"Treatment effect (adjusted mean difference)\", ylab=\"\",\n     pch=19)\naxis(2, at=1:2, labels=labels)\nsegments(lo, 1:2, hi, 1:2)\nabline(v=0, lty=2)\ntitle(\"Subgroup effects (illustration)\")\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#20b-r-interaction-test-correct-subgroup-inference","title":"20B. R: Interaction test (correct subgroup inference)","text":"<p>R</p> <pre><code>fit_int &lt;- lm(sbp12 ~ trt*sex + baseline_sbp, data=dfa)\nsummary(fit_int)\nconfint(fit_int)[\"trt:sex\", ]\n</code></pre>"},{"location":"Clinical_Trials/08-reporting/#21-how-to-write-results","title":"21. How to write results","text":"<p>A high-quality results paragraph usually includes: - point estimate - CI - clear directionality - clinical meaning</p> <p>Example (continuous endpoint):</p> <p>At week 12, the adjusted mean SBP was lower in the treatment group compared with control, with an adjusted mean difference of -5.8 mmHg (95% CI -8.1 to -3.5).  </p> <p>Do not over-focus on p-values; include them if required, but interpret the CI primarily.</p>"},{"location":"Clinical_Trials/08-reporting/#22-common-interpretation-mistakes","title":"22. Common interpretation mistakes","text":"<ul> <li>\u201cNo significant difference\u201d does not mean \u201cno difference\u201d</li> <li>check CI width and clinically relevant effects</li> <li>Subgroup results should not be claimed based on within-subgroup p-values</li> <li>interaction test matters</li> <li>Avoid interpreting secondary endpoints as confirmatory unless multiplicity controlled</li> <li>Avoid causal language outside what the design supports (e.g., for post-hoc analyses)</li> </ul>"},{"location":"Clinical_Trials/08-reporting/#23-reproducible-reporting-workflow","title":"23. Reproducible reporting workflow","text":"<p>A simple, robust structure:</p> <ul> <li><code>docs/</code> for narrative content and code examples</li> <li><code>analysis/</code> for scripts/notebooks that generate figures/tables</li> <li><code>data/</code> for toy or public datasets (avoid sensitive real trial data)</li> <li><code>outputs/</code> for generated tables/figures used in docs</li> </ul> <p>Even if your site is educational, this mirrors real-world trial reporting pipelines.</p>"},{"location":"Clinical_Trials/08-reporting/#24-exercises","title":"24. Exercises","text":"Click to try  1. Modify the toy dataset so the treatment effect is -3 instead of -6 and compare CI width and conclusions.   2. Increase dropout from 8% to 25% and recompute the primary analysis (complete-case). Discuss how missingness might bias conclusions.   3. Create an additional subgroup (age &lt; 60 vs \u2265 60) and make a forest plot. Then test interaction.   4. For a binary endpoint, compute risk difference and 95% CI.   5. Write a short CONSORT-style summary of participant flow using the computed counts."},{"location":"Clinical_Trials/08-reporting/#25-summary","title":"25. Summary","text":"<ul> <li>CONSORT provides a structured approach to transparent trial reporting.</li> <li>Report effect sizes and confidence intervals prominently.</li> <li>Baseline tables are descriptive; baseline p-values are discouraged.</li> <li>Subgroup claims require interaction testing and cautious interpretation.</li> <li>Reproducible scripts for tables/figures improve trust and reduce errors.</li> </ul>"},{"location":"Infectious_Disease_Modelling/","title":"Infectious Disease Modelling","text":"<p>I am currently working on this module. Thankyou!!!</p>"},{"location":"Machine_Learning/","title":"Machine Learning","text":"<p>I am currently working on this module. Thankyou!!!</p>"},{"location":"Meta_Analysis/","title":"Meta Analysis","text":"<p>I am currently working on this module. Thankyou!!!</p>"},{"location":"Probability_Statistics/","title":"Probability &amp; Statistics Review","text":"<p>This section is a focused refresher on the probability and statistics foundations you\u2019ll use throughout biostatistics, clinical trials, machine learning, regression, and survival analysis.</p> <p>The goal is not to be overly theoretical\u2014it's to build intuition so you can: - read formulas in papers confidently, - understand why methods work</p>"},{"location":"Probability_Statistics/#what-you-will-learn","title":"What you will learn","text":"<p>By the end of this module, you will be able to:</p> <ul> <li>Use the language of probability correctly: sample spaces, events, independence</li> <li>Work comfortably with random variables (discrete and continuous)</li> <li>Compute and interpret:</li> <li>expectation, variance, covariance</li> <li>conditional expectation</li> <li>Recognize and use common distributions in biostatistics:</li> <li>Bernoulli, Binomial, Poisson</li> <li>Uniform, Normal, Exponential</li> <li>Understand how distributions connect to real data problems:</li> <li>counts, rates, measurement error, waiting times</li> <li>Use core statistical summaries and functions:</li> <li>mean/median/mode</li> <li>variance/SD/IQR</li> <li>correlation and covariance</li> <li>Build a strong base for later topics:</li> <li>regression (linear/logistic/Poisson)</li> <li>survival analysis (hazard intuition)</li> <li>Bayesian methods (priors/likelihood)</li> <li>inference concepts (sampling variability)</li> </ul>"},{"location":"Probability_Statistics/#who-this-module-is-for","title":"Who this module is for","text":"<p>This section is ideal if you: - want a quick but clear refresh before starting regression/survival/ML, - feel shaky on distributions or expectation/variance</p> <p>You\u2019ll get the most benefit if you already know basic algebra.</p>"},{"location":"Probability_Statistics/#module-roadmap","title":"Module roadmap","text":"<p>This review is organized into five short chapters:</p> <ol> <li> <p>Probability Basics    Experiments, sample spaces, events, probability rules, and worked examples.</p> </li> <li> <p>Random Variables    Discrete vs continuous random variables, PMF/PDF/CDF, and simulation intuition.</p> </li> <li> <p>Expectation &amp; Variance    Means, variances, standard deviation, and why these summaries matter in modeling.</p> </li> <li> <p>Probability Distributions    Key distributions used constantly in biostatistics (Binomial/Poisson/Normal/etc.) and when to use them.</p> </li> <li> <p>Statistical Functions &amp; Summaries    Descriptive statistics, variability measures, correlation/covariance, and practical data summaries.</p> </li> </ol>"},{"location":"Probability_Statistics/1-probability-basics/","title":"Probability Basics","text":"<p>Probability measures the likelihood of an event occurring. It is fundamental for statistical analysis and forms the foundation for modeling uncertainty in real-world phenomena.</p>"},{"location":"Probability_Statistics/1-probability-basics/#basic-definitions","title":"Basic Definitions","text":"<ul> <li>Experiment: A process that generates outcomes (e.g., toss a coin, roll a die).</li> <li>Sample Space \\(S\\): The set of all possible outcomes.</li> <li>Event \\(E\\): A subset of the sample space representing outcomes of interest.</li> <li>Probability: A measure that satisfies \\(0 \\le P(E) \\le 1\\), often computed as:</li> </ul> \\[ P(E) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total outcomes}} \\]"},{"location":"Probability_Statistics/1-probability-basics/#key-properties","title":"Key Properties","text":"<ol> <li>Non-negativity: \\(P(E) \\ge 0\\) for any event \\(E\\)</li> <li>Normalization: \\(P(S) = 1\\)</li> <li>Additivity: If \\(A\\) and \\(B\\) are mutually exclusive, then    $$    P(A \\cup B) = P(A) + P(B)    $$</li> </ol>"},{"location":"Probability_Statistics/1-probability-basics/#example-1-coin-toss","title":"Example 1: Coin Toss","text":"<p>Consider tossing a fair coin once:</p> <ul> <li>Sample Space: \\(S = \\{H, T\\}\\)</li> <li>Event: Getting a Head \\(E = \\{H\\}\\)</li> <li>Probability: \\(P(E) = \\frac{1}{2} = 0.5\\)</li> </ul>"},{"location":"Probability_Statistics/1-probability-basics/#example-2-rolling-a-die","title":"Example 2: Rolling a Die","text":"<ul> <li>Sample Space: \\(S = \\{1,2,3,4,5,6\\}\\)</li> <li>Event: Rolling an even number \\(E = \\{2,4,6\\}\\)</li> <li>Probability: \\(P(E) = \\frac{3}{6} = 0.5\\)</li> </ul>"},{"location":"Probability_Statistics/1-probability-basics/#interactive-simulation-in-python","title":"Interactive Simulation in Python","text":"<p>Python</p> <pre><code>import random\n\n# Simulate 10 coin tosses\ncoin = [\"H\", \"T\"]\ntosses = [random.choice(coin) for _ in range(10)]\nprint(\"Coin tosses:\", tosses)\n\n# Simulate rolling a die 10 times\ndie_rolls = [random.randint(1, 6) for _ in range(10)]\nprint(\"Die rolls:\", die_rolls)\n</code></pre> <p>Run this code online: Try Python Simulation</p>"},{"location":"Probability_Statistics/1-probability-basics/#interactive-simulation-in-r","title":"Interactive Simulation in R","text":"<p>R</p> <pre><code># Simulate 10 coin tosses\ncoin &lt;- c(\"H\", \"T\")\ntosses &lt;- sample(coin, 10, replace = TRUE)\nprint(tosses)\n\n# Simulate rolling a die 10 times\ndie_rolls &lt;- sample(1:6, 10, replace = TRUE)\nprint(die_rolls)\n</code></pre> <p>Run this code online: Try R Simulation</p>"},{"location":"Probability_Statistics/1-probability-basics/#exercises","title":"Exercises","text":"Click to try the exercises!  1. Toss a fair coin 20 times. Count the number of heads and tails.   2. Roll a six-sided die 15 times. What is the probability of rolling a number greater than 4?   3. Toss two coins simultaneously. List the sample space and calculate the probability of getting exactly one head."},{"location":"Probability_Statistics/1-probability-basics/#summary","title":"Summary","text":"<ul> <li>Probability quantifies uncertainty in random experiments.</li> <li>Understanding sample spaces and events is crucial for statistical analysis.</li> <li>Python and R simulations help visualize probability concepts interactively.</li> </ul>"},{"location":"Probability_Statistics/2-random-variables/","title":"Random Variables","text":"<p>A random variable is a variable that takes numerical values based on the outcome of a random experiment. It allows us to quantify randomness mathematically.</p>"},{"location":"Probability_Statistics/2-random-variables/#types-of-random-variables","title":"Types of Random Variables","text":"<ol> <li>Discrete random variables</li> <li>Take countable values (integers or counts)</li> <li> <p>Examples: number of heads in coin tosses; number of patients who recover</p> </li> <li> <p>Continuous random variables</p> </li> <li>Take any real value within an interval</li> <li>Examples: height, weight, blood pressure, time until failure</li> </ol>"},{"location":"Probability_Statistics/2-random-variables/#probability-functions","title":"Probability Functions","text":"<ul> <li>Discrete RV: Probability Mass Function (PMF)</li> </ul> \\[ P(X=x) = \\text{Probability that } X \\text{ equals } x \\] <ul> <li>Continuous RV: Probability Density Function (PDF)</li> </ul> \\[ f(x) \\ge 0, \\quad \\int_{-\\infty}^{\\infty} f(x)\\,dx = 1 \\] <ul> <li>Cumulative Distribution Function (CDF):</li> </ul> \\[ F(x) = P(X \\le x) \\]"},{"location":"Probability_Statistics/2-random-variables/#example-1-discrete-random-variable","title":"Example 1: Discrete Random Variable","text":"<p>Number of heads in 3 coin tosses:</p> <ul> <li>Random Variable: \\(X =\\) number of heads</li> <li>Possible values: \\(X = 0,1,2,3\\)</li> <li>PMF:</li> </ul> \\[ P(X=0)=\\frac{1}{8},\\quad P(X=1)=\\frac{3}{8},\\quad P(X=2)=\\frac{3}{8},\\quad P(X=3)=\\frac{1}{8} \\]"},{"location":"Probability_Statistics/2-random-variables/#example-2-continuous-random-variable","title":"Example 2: Continuous Random Variable","text":"<ul> <li>Random Variable: \\(Y =\\) height of a person (cm)</li> <li>Continuous values: \\(140 \\le Y \\le 200\\)</li> <li>A common model is the normal distribution:</li> </ul> \\[ f(y) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\!\\Big(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\Big) \\]"},{"location":"Probability_Statistics/2-random-variables/#interactive-simulation-in-python-discrete-rv","title":"Interactive Simulation in Python: Discrete RV","text":"<p>Python</p> <pre><code>import numpy as np\n\nnp.random.seed(42)\n\n# Simulate 3 coin tosses, 10 trials (0=T, 1=H)\ntosses = np.random.choice([0, 1], size=(10, 3))\nheads_count = np.sum(tosses, axis=1)\nprint(\"Number of heads per trial:\", heads_count)\n</code></pre> <p>Run online: Try Python Simulation</p>"},{"location":"Probability_Statistics/2-random-variables/#interactive-simulation-in-python-continuous-rv","title":"Interactive Simulation in Python: Continuous RV","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# Simulate 1000 heights (Normal distribution)\nheights = np.random.normal(loc=170, scale=10, size=1000)\n\nplt.hist(heights, bins=30, edgecolor=\"black\")\nplt.title(\"Simulated Heights of Individuals\")\nplt.xlabel(\"Height (cm)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n</code></pre> <p>Run online: Try Python Simulation</p>"},{"location":"Probability_Statistics/2-random-variables/#interactive-simulation-in-r-discrete-rv","title":"Interactive Simulation in R: Discrete RV","text":"<p>R</p> <pre><code>set.seed(42)\n\n# Simulate 3 coin tosses, 10 trials\ntosses &lt;- matrix(sample(0:1, 30, replace=TRUE), ncol=3)\nheads_count &lt;- rowSums(tosses)\nprint(heads_count)\n</code></pre> <p>Run online: Try R Simulation</p>"},{"location":"Probability_Statistics/2-random-variables/#interactive-simulation-in-r-continuous-rv","title":"Interactive Simulation in R: Continuous RV","text":"<p>R</p> <pre><code>set.seed(42)\n\n# Simulate 1000 heights\nheights &lt;- rnorm(1000, mean=170, sd=10)\nhist(heights, breaks=30, main=\"Simulated Heights\",\n     xlab=\"Height (cm)\", ylab=\"Frequency\")\n</code></pre> <p>Run online: Try R Simulation</p>"},{"location":"Probability_Statistics/2-random-variables/#properties-of-random-variables","title":"Properties of Random Variables","text":"Property Definition Mean (Expectation) Average value of the RV Variance Measure of spread of the RV Standard Deviation Square root of variance PMF / PDF Probability distribution of the RV CDF Cumulative probability function"},{"location":"Probability_Statistics/2-random-variables/#exercises","title":"Exercises","text":"Click to try!  1. Simulate 5 coin tosses 20 times. Count number of heads for each trial.   2. Roll a die 10 times. Record the sum of outcomes.   3. Simulate 500 random heights using Normal(mean = 165, sd = 12). Plot histogram.   4. Compare discrete and continuous RVs using Python or R.   5. Calculate and plot the CDF of a discrete random variable."},{"location":"Probability_Statistics/2-random-variables/#summary","title":"Summary","text":"<ul> <li>Random variables quantify randomness numerically.</li> <li>Discrete vs continuous RVs use different probability functions (PMF vs PDF).</li> <li>Simulations help visualize distributions and understand their behavior.</li> </ul>"},{"location":"Probability_Statistics/3-expectation-variance/","title":"Expectation &amp; Variance","text":"<p>Expectation and variance are fundamental properties of random variables that summarize their behavior mathematically.</p> <ul> <li>Expectation (Mean): the \u201ccenter\u201d or long-term average of a random variable  </li> <li>Variance: how much values spread around the mean  </li> <li>Standard deviation: square root of variance (same units as the variable)</li> </ul>"},{"location":"Probability_Statistics/3-expectation-variance/#1-expectation-mean","title":"1. Expectation (Mean)","text":"<p>For a discrete random variable \\(X\\) with PMF \\(P(X=x)\\):</p> \\[ \\mathbb{E}[X] = \\sum_x x \\, P(X=x) \\] <p>For a continuous random variable with PDF \\(f(x)\\):</p> \\[ \\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x\\, f(x)\\, dx \\] <p>Interpretation: expectation is the average outcome if the experiment is repeated many times.</p>"},{"location":"Probability_Statistics/3-expectation-variance/#2-variance","title":"2. Variance","text":"<p>Variance measures the spread of a random variable around its mean:</p> \\[ \\mathrm{Var}(X) = \\mathbb{E}\\big[(X - \\mathbb{E}[X])^2\\big] \\] <ul> <li>Standard deviation: \\(\\sigma_X = \\sqrt{\\mathrm{Var}(X)}\\) </li> <li>Small variance \u2192 values close to the mean  </li> <li>Large variance \u2192 values more spread out  </li> </ul>"},{"location":"Probability_Statistics/3-expectation-variance/#example-1-discrete-random-variable","title":"Example 1: Discrete Random Variable","text":"<p>Number of heads in 3 coin tosses:</p> \\(X\\) (Heads) 0 1 2 3 \\(P(X=x)\\) 1/8 3/8 3/8 1/8 \\[ \\mathbb{E}[X] = 0\\cdot\\frac{1}{8} + 1\\cdot\\frac{3}{8} + 2\\cdot\\frac{3}{8} + 3\\cdot\\frac{1}{8} = 1.5 \\] \\[ \\mathrm{Var}(X) = \\sum_x (x - 1.5)^2 P(X=x) = 0.75 \\]"},{"location":"Probability_Statistics/3-expectation-variance/#example-2-continuous-random-variable","title":"Example 2: Continuous Random Variable","text":"<p>Simulate heights:</p> <ul> <li>Mean: \\(\\mu = 170\\) cm  </li> <li>Standard deviation: \\(\\sigma = 10\\) cm  </li> </ul> <p>We can estimate mean and variance from simulated data.</p>"},{"location":"Probability_Statistics/3-expectation-variance/#interactive-simulation-discrete-rv-python","title":"Interactive Simulation: Discrete RV (Python)","text":"<p>Python</p> <pre><code>import numpy as np\n\nnp.random.seed(42)\n\n# Simulate 3 coin tosses, 1000 trials\ntosses = np.random.choice([0, 1], size=(1000, 3))\nheads_count = np.sum(tosses, axis=1)\n\n# Mean and variance\nmean_heads = np.mean(heads_count)\nvar_heads = np.var(heads_count)\n\nmean_heads, var_heads\n</code></pre> <p>Run online: Try Python Simulation</p>"},{"location":"Probability_Statistics/3-expectation-variance/#interactive-simulation-continuous-rv-python","title":"Interactive Simulation: Continuous RV (Python)","text":"<p>Python</p> <pre><code>import numpy as np\n\nnp.random.seed(42)\n\n# Simulate 1000 heights\nheights = np.random.normal(loc=170, scale=10, size=1000)\n\nmean_height = np.mean(heights)\nvar_height = np.var(heights)\n\nmean_height, var_height\n</code></pre> <p>Run online: Try Python Simulation</p>"},{"location":"Probability_Statistics/3-expectation-variance/#interactive-simulation-discrete-rv-r","title":"Interactive Simulation: Discrete RV (R)","text":"<p>R</p> <pre><code>set.seed(42)\n\ntosses &lt;- matrix(sample(0:1, 3000, replace=TRUE), ncol=3)\nheads_count &lt;- rowSums(tosses)\n\nmean_heads &lt;- mean(heads_count)\nvar_heads &lt;- var(heads_count)\n\nmean_heads\nvar_heads\n</code></pre> <p>Run online: Try R Simulation</p>"},{"location":"Probability_Statistics/3-expectation-variance/#interactive-simulation-continuous-rv-r","title":"Interactive Simulation: Continuous RV (R)","text":"<p>R</p> <pre><code>set.seed(42)\n\nheights &lt;- rnorm(1000, mean=170, sd=10)\n\nmean_height &lt;- mean(heights)\nvar_height &lt;- var(heights)\n\nmean_height\nvar_height\n</code></pre> <p>Run online: Try R Simulation</p>"},{"location":"Probability_Statistics/3-expectation-variance/#exercises","title":"Exercises","text":"Click to try!  1. Toss 5 coins, repeat 50 trials. Compute mean and variance of heads.   2. Roll a die 20 times, repeat 50 trials. Compute mean and variance.   3. Simulate 500 weights (mean = 70, SD = 12). Plot histogram; compute mean &amp; variance.   4. Compare sample variance with theoretical variance for a discrete RV.   5. Use Python or R to verify expectation and variance from simulated data."},{"location":"Probability_Statistics/3-expectation-variance/#summary","title":"Summary","text":"<ul> <li>Expectation gives the average value of a random variable.</li> <li>Variance quantifies how spread out values are around the mean.</li> <li>Simulations make these ideas concrete and visual.</li> </ul>"},{"location":"Probability_Statistics/4-probability-distributions/","title":"Probability Distributions","text":"<p>Probability distributions describe how probabilities are assigned to the possible outcomes of a random variable. They are fundamental in biostatistics, modeling uncertainty, and making data-driven decisions.</p>"},{"location":"Probability_Statistics/4-probability-distributions/#1-discrete-probability-distributions","title":"1. Discrete Probability Distributions","text":"<p>Discrete distributions describe random variables with countable outcomes.</p>"},{"location":"Probability_Statistics/4-probability-distributions/#11-bernoulli-distribution","title":"1.1 Bernoulli Distribution","text":"<ul> <li>Two outcomes: success (1) or failure (0)</li> <li>PMF:</li> </ul> \\[ P(X=1)=p,\\quad P(X=0)=1-p \\] <ul> <li>Mean: \\(\\mathbb{E}[X]=p\\)</li> <li>Variance: \\(\\mathrm{Var}(X)=p(1-p)\\)</li> </ul> <p>Example: coin toss with \\(p=0.5\\)</p>"},{"location":"Probability_Statistics/4-probability-distributions/#12-binomial-distribution","title":"1.2 Binomial Distribution","text":"<ul> <li>Number of successes in \\(n\\) independent Bernoulli trials</li> <li>PMF:</li> </ul> \\[ P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k},\\quad k=0,1,\\dots,n \\] <ul> <li>Mean: \\(\\mathbb{E}[X]=np\\)</li> <li>Variance: \\(\\mathrm{Var}(X)=np(1-p)\\)</li> </ul>"},{"location":"Probability_Statistics/4-probability-distributions/#13-poisson-distribution","title":"1.3 Poisson Distribution","text":"<ul> <li>Number of events in a fixed interval with rate \\(\\lambda\\)</li> <li>PMF:</li> </ul> \\[ P(X=k)=\\frac{\\lambda^k e^{-\\lambda}}{k!},\\quad k=0,1,2,\\dots \\] <ul> <li>Mean and variance: \\(\\mathbb{E}[X]=\\mathrm{Var}(X)=\\lambda\\)</li> </ul>"},{"location":"Probability_Statistics/4-probability-distributions/#2-continuous-probability-distributions","title":"2. Continuous Probability Distributions","text":"<p>Continuous distributions describe random variables that can take any real value in an interval.</p>"},{"location":"Probability_Statistics/4-probability-distributions/#21-uniform-distribution","title":"2.1 Uniform Distribution","text":"<ul> <li>PDF on \\([a,b]\\):</li> </ul> \\[ f(x)=\\frac{1}{b-a},\\quad a\\le x\\le b \\] <ul> <li>Mean: \\(\\mathbb{E}[X]=\\frac{a+b}{2}\\)</li> <li>Variance: \\(\\mathrm{Var}(X)=\\frac{(b-a)^2}{12}\\)</li> </ul>"},{"location":"Probability_Statistics/4-probability-distributions/#22-normal-gaussian-distribution","title":"2.2 Normal (Gaussian) Distribution","text":"<ul> <li>PDF:</li> </ul> \\[ f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\!\\Big(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\Big) \\] <ul> <li>Mean and variance: \\(\\mathbb{E}[X]=\\mu,\\quad \\mathrm{Var}(X)=\\sigma^2\\)</li> </ul>"},{"location":"Probability_Statistics/4-probability-distributions/#23-exponential-distribution","title":"2.3 Exponential Distribution","text":"<ul> <li>PDF:</li> </ul> \\[ f(x)=\\lambda e^{-\\lambda x},\\quad x\\ge 0 \\] <ul> <li>Mean: \\(1/\\lambda\\)</li> <li>Variance: \\(1/\\lambda^2\\)</li> </ul>"},{"location":"Probability_Statistics/4-probability-distributions/#3-interactive-simulations-in-python","title":"3. Interactive Simulations in Python","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, norm, expon\n\n# ----- Binomial -----\nn, p = 10, 0.5\nx_binom = np.arange(0, n + 1)\nplt.bar(x_binom, binom.pmf(x_binom, n, p), edgecolor=\"black\")\nplt.title(\"Binomial PMF (n=10, p=0.5)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"P(X=x)\")\nplt.show()\n\n# ----- Normal -----\nx_norm = np.linspace(140, 200, 200)\nplt.plot(x_norm, norm.pdf(x_norm, loc=170, scale=10))\nplt.title(\"Normal PDF (mu=170, sd=10)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n\n# ----- Exponential -----\nx_exp = np.linspace(0, 10, 200)\nlam = 0.5\nplt.plot(x_exp, expon.pdf(x_exp, scale=1/lam))\nplt.title(\"Exponential PDF (lambda=0.5)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n</code></pre> <p>Run online: Try Python Simulation</p>"},{"location":"Probability_Statistics/4-probability-distributions/#4-interactive-simulations-in-r","title":"4. Interactive Simulations in R","text":"<p>R</p> <pre><code># ----- Binomial -----\nx_binom &lt;- 0:10\nprobs &lt;- dbinom(x_binom, size=10, prob=0.5)\nbarplot(probs, names.arg=x_binom, main=\"Binomial PMF (n=10, p=0.5)\")\n\n# ----- Normal -----\nx_norm &lt;- seq(140, 200, length=200)\nplot(x_norm, dnorm(x_norm, mean=170, sd=10), type=\"l\",\n     main=\"Normal PDF (mu=170, sd=10)\", xlab=\"x\", ylab=\"f(x)\")\n\n# ----- Exponential -----\nx_exp &lt;- seq(0, 10, length=200)\nplot(x_exp, dexp(x_exp, rate=0.5), type=\"l\",\n     main=\"Exponential PDF (lambda=0.5)\", xlab=\"x\", ylab=\"f(x)\")\n</code></pre> <p>Run online: Try R Simulation</p>"},{"location":"Probability_Statistics/4-probability-distributions/#5-exercises","title":"5. Exercises","text":"Click to try!  1. Simulate 10 coin tosses 1000 times. Plot the histogram of number of heads (Binomial).   2. Generate 500 random heights from Normal(170, 10). Compute mean and variance.   3. Simulate Poisson arrivals with $\\lambda=3$ for 1000 intervals. Plot histogram.   4. Generate 1000 Uniform(0,1) values. Plot histogram and compute mean &amp; variance.   5. Compare Uniform vs Normal distributions visually in Python or R."},{"location":"Probability_Statistics/4-probability-distributions/#6-summary","title":"6. Summary","text":"<ul> <li>Discrete distributions: Bernoulli, Binomial, Poisson  </li> <li>Continuous distributions: Uniform, Normal, Exponential  </li> <li>Distributions are core building blocks in biostatistics and modeling uncertainty.</li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/","title":"Common Statistical Functions and Summaries","text":"<p>Descriptive statistics summarize and describe the main features of a dataset. They are essential before inferential or predictive analysis.</p>"},{"location":"Probability_Statistics/5-statistical-functions/#1-measures-of-central-tendency","title":"1. Measures of Central Tendency","text":"<p>Central tendency tells us where the \u201ccenter\u201d of the data lies.</p>"},{"location":"Probability_Statistics/5-statistical-functions/#11-mean-average","title":"1.1 Mean (Average)","text":"\\[ \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i \\] <ul> <li>Sensitive to outliers.</li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/#12-median","title":"1.2 Median","text":"<p>The middle value when the data is sorted:</p> <ul> <li>Resistant to outliers</li> <li>Splits data into two equal halves</li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/#13-mode","title":"1.3 Mode","text":"<p>The most frequent value in the dataset:</p> <ul> <li>Can be multi-modal</li> <li>Useful for categorical data</li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/#2-measures-of-spread","title":"2. Measures of Spread","text":""},{"location":"Probability_Statistics/5-statistical-functions/#21-variance-and-standard-deviation","title":"2.1 Variance and Standard Deviation","text":"\\[ \\mathrm{Var}(X) = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2 \\] \\[ \\sigma = \\sqrt{\\mathrm{Var}(X)} \\]"},{"location":"Probability_Statistics/5-statistical-functions/#22-range","title":"2.2 Range","text":"\\[ \\mathrm{Range} = \\max(x) - \\min(x) \\]"},{"location":"Probability_Statistics/5-statistical-functions/#23-interquartile-range-iqr","title":"2.3 Interquartile Range (IQR)","text":"\\[ \\mathrm{IQR} = Q_3 - Q_1 \\] <ul> <li>Resistant to extreme values  </li> <li>Useful for detecting outliers</li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/#3-covariance-and-correlation","title":"3. Covariance and Correlation","text":""},{"location":"Probability_Statistics/5-statistical-functions/#31-covariance","title":"3.1 Covariance","text":"\\[ \\mathrm{Cov}(X,Y) = \\frac{1}{n}\\sum_{i=1}^{n}(X_i-\\bar{X})(Y_i-\\bar{Y}) \\] <ul> <li>Positive \u2192 variables increase together  </li> <li>Negative \u2192 one increases as the other decreases  </li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/#32-correlation","title":"3.2 Correlation","text":"\\[ \\rho_{X,Y} = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X\\sigma_Y} \\] <ul> <li>Ranges from -1 to 1  </li> <li>Dimensionless</li> </ul>"},{"location":"Probability_Statistics/5-statistical-functions/#4-interactive-simulation-python","title":"4. Interactive Simulation: Python","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\ndata = pd.DataFrame({\n    \"height\": np.random.normal(170, 10, 100),\n    \"weight\": np.random.normal(70, 12, 100),\n    \"age\": np.random.randint(18, 60, 100)\n})\n\n# Central Tendency\nmean_height = data[\"height\"].mean()\nmedian_weight = data[\"weight\"].median()\nmode_age = data[\"age\"].mode()[0]\n\n# Spread\nvar_height = data[\"height\"].var()\nsd_weight = data[\"weight\"].std()\nrange_age = data[\"age\"].max() - data[\"age\"].min()\niqr_height = data[\"height\"].quantile(0.75) - data[\"height\"].quantile(0.25)\n\n# Correlation\ncorr_height_weight = data[\"height\"].corr(data[\"weight\"])\n\nmean_height, median_weight, mode_age, var_height, sd_weight, range_age, iqr_height, corr_height_weight\n</code></pre> <p>Run online: Try Python Simulation</p>"},{"location":"Probability_Statistics/5-statistical-functions/#5-interactive-simulation-r","title":"5. Interactive Simulation: R","text":"<p>R</p> <pre><code>set.seed(42)\nheight &lt;- rnorm(100, mean=170, sd=10)\nweight &lt;- rnorm(100, mean=70, sd=12)\nage &lt;- sample(18:59, 100, replace=TRUE)\ndata &lt;- data.frame(height, weight, age)\n\n# Central Tendency\nmean_height &lt;- mean(data$height)\nmedian_weight &lt;- median(data$weight)\nmode_age &lt;- as.numeric(names(sort(table(data$age), decreasing=TRUE)[1]))\n\n# Spread\nvar_height &lt;- var(data$height)\nsd_weight &lt;- sd(data$weight)\nrange_age &lt;- max(data$age) - min(data$age)\niqr_height &lt;- IQR(data$height)\n\n# Correlation\ncorr_height_weight &lt;- cor(data$height, data$weight)\n\nlist(mean_height=mean_height, median_weight=median_weight, mode_age=mode_age,\n     var_height=var_height, sd_weight=sd_weight, range_age=range_age,\n     iqr_height=iqr_height, corr_height_weight=corr_height_weight)\n</code></pre>"},{"location":"Probability_Statistics/5-statistical-functions/#6-visualization-python","title":"6. Visualization (Python)","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\n\n# Histogram\nplt.hist(data[\"height\"], bins=15, edgecolor=\"black\")\nplt.title(\"Histogram of Heights\")\nplt.xlabel(\"Height\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Boxplot\nplt.boxplot(data[\"weight\"], vert=False)\nplt.title(\"Boxplot of Weights\")\nplt.xlabel(\"Weight\")\nplt.show()\n\n# Scatter plot\nplt.scatter(data[\"height\"], data[\"weight\"])\nplt.title(\"Height vs Weight\")\nplt.xlabel(\"Height\")\nplt.ylabel(\"Weight\")\nplt.show()\n</code></pre>"},{"location":"Probability_Statistics/5-statistical-functions/#7-exercises","title":"7. Exercises","text":"Click to try!  1. Generate 100 random ages between 20 and 60. Compute mean, median, mode, SD, range, and IQR.   2. Simulate 100 weights (Normal distribution). Plot histogram and boxplot.   3. Compute correlation between height and weight for 50 simulated individuals.   4. Compare standard deviation vs IQR for a dataset with outliers."},{"location":"Probability_Statistics/5-statistical-functions/#8-summary","title":"8. Summary","text":"<ul> <li>Descriptive statistics provide quick insights into data.  </li> <li>Central tendency summarizes location, while spread measures variability.  </li> <li>Correlation and covariance describe relationships between variables.  </li> <li>Visualization complements numeric summaries.</li> </ul>"},{"location":"Regression/","title":"Regression","text":"<p>Regression is the core toolkit for quantifying relationships between variables and making predictions\u2014and it sits at the heart of biostatistics, epidemiology, and clinical research.</p> <p>In biomedical settings, regression helps answer questions like:</p> <ul> <li>How does blood pressure change with age and BMI?</li> <li>Does a treatment change the probability of an outcome after adjusting for covariates?</li> <li>Which risk factors are associated with disease incidence, counts, or time-to-event outcomes?</li> <li>How do we interpret results correctly and avoid common traps like confounding and collinearity?</li> </ul> <p>This module is designed for biostatistical applications and emphasizes: - clean interpretation (effect sizes + uncertainty) - practical modeling workflow - diagnostics and assumptions - interactive coding in R and Python</p>"},{"location":"Regression/#what-you-will-learn","title":"What you will learn","text":"<p>By the end of this module, you will be able to:</p> <ul> <li>Choose the correct regression model for different outcome types</li> <li>Create and interpret</li> <li>Diagnose and fix model problems</li> <li>Incorporate</li> <li>Write results like a biostat paper (tables, plots, wording)</li> </ul>"},{"location":"Regression/#who-this-module-is-for","title":"Who this module is for","text":"<p>This module is ideal for: - students learning regression for biostatistics / epidemiology - researchers working with clinical or public health datasets - anyone preparing analyses for papers, theses, or reports</p> <p>You should be comfortable with: - basic probability/statistics concepts (mean, variance, distributions) - reading a dataset and basic plotting - interpreting a confidence interval and p-value</p>"},{"location":"Regression/#recommended-tools-r-python","title":"Recommended tools (R + Python)","text":"<p>You can follow everything in either language.</p>"},{"location":"Regression/#r-packages","title":"R packages","text":"<ul> <li><code>stats</code> (lm, glm)</li> <li><code>car</code> (diagnostics, VIF)</li> <li><code>broom</code> (tidy summaries)</li> <li><code>ggplot2</code> (plots)</li> <li><code>splines</code> (natural splines)</li> <li><code>MASS</code> (negative binomial: <code>glm.nb</code>)</li> <li><code>survival</code> (Cox regression)</li> </ul>"},{"location":"Regression/#python-packages","title":"Python packages","text":"<ul> <li><code>statsmodels</code> (OLS/GLM, inference)</li> <li><code>scikit-learn</code> (regularization + prediction workflow)</li> <li><code>pandas</code>, <code>numpy</code> (data)</li> <li><code>matplotlib</code> (plots)</li> </ul>"},{"location":"Regression/#module-roadmap","title":"Module roadmap","text":"<p>Follow the pages in order for a smooth learning path. Each section includes: - clear concepts - biostatistical examples - code in R and Python - interpretation tips and common pitfalls</p> <ol> <li> <p>Overview    What regression is, outcome types, choosing the right model, and a biostat workflow.</p> </li> <li> <p>Simple Linear Regression    Modeling a continuous outcome with one predictor; slope interpretation and prediction.</p> </li> <li> <p>Multiple Linear Regression    Adjusting for confounders; interpreting adjusted effects; partial relationships.</p> </li> <li> <p>Logistic Regression    Binary outcomes; odds ratios; predicted probabilities; classification vs inference.</p> </li> <li> <p>Diagnostics (Linear)    Residual plots, normality, heteroscedasticity, leverage/influence, and what to do when assumptions fail.</p> </li> <li> <p>Categorical Predictors    Dummy coding, reference groups, interpretation of group effects, ANOVA-style comparisons.</p> </li> <li> <p>Interactions    Effect modification; how to model and interpret interaction terms; plotting interactions.</p> </li> <li> <p>Nonlinearity &amp; Splines    Flexible modeling of continuous predictors; splines in R/Python; avoiding overfitting.</p> </li> <li> <p>Collinearity &amp; Confounding    VIF, identifiability, unstable coefficients, confounding logic, DAG intuition (practical perspective).</p> </li> <li> <p>Regularization    Ridge/Lasso/Elastic Net; cross-validation; when and why regularization matters.</p> </li> <li> <p>Reporting Results    Tables, figures, clinical interpretation, and writing regression results for papers.</p> </li> <li> <p>Poisson Regression    Count outcomes and rates; offsets; interpreting incidence rate ratios (IRR).</p> </li> <li> <p>Negative Binomial Regression    Overdispersion; why Poisson fails; NB model interpretation; model checks.</p> </li> <li> <p>Cox Regression    Time-to-event regression; hazard ratios; connection to survival analysis.</p> </li> </ol>"},{"location":"Regression/1-linear-regression-simple/","title":"Simple Linear Regression","text":"<p>Simple linear regression models a continuous outcome using one predictor.</p> <p>Examples: - Systolic BP explained by age - Cholesterol explained by BMI - Lung function explained by smoking pack-years</p>"},{"location":"Regression/1-linear-regression-simple/#1-the-model","title":"1. The Model","text":"<p>Outcome \\(Y\\) (continuous) and predictor \\(X\\):</p> \\[ Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i \\] <ul> <li>\\(\\beta_0\\): expected \\(Y\\) when \\(X=0\\) (may be non-meaningful depending on scale)</li> <li>\\(\\beta_1\\): expected change in \\(Y\\) for a 1-unit increase in \\(X\\)</li> <li>\\(\\varepsilon_i\\): error term</li> </ul>"},{"location":"Regression/1-linear-regression-simple/#2-interpretation","title":"2. Interpretation","text":"<p>If \\(Y\\) = systolic BP (mmHg) and \\(X\\) = age (years), and you estimate \\(\\hat\\beta_1 = 0.8\\):</p> <p>Each additional year of age is associated with +0.8 mmHg higher systolic BP (on average).</p>"},{"location":"Regression/1-linear-regression-simple/#3-simulate-your-own-data-interactive-change-effect-size-noise","title":"3. Simulate Your Own Data (Interactive: change effect size + noise)","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(3)\n\n# ---- try editing these ----\nn = 120\nbeta0 = 110\nbeta1 = 0.7     # effect per year\nsigma = 10      # noise (sd)\n# --------------------------\n\nage = np.random.uniform(20, 80, size=n)\neps = np.random.normal(0, sigma, size=n)\nsbp = beta0 + beta1 * age + eps\n\n# Fit with numpy\nX = np.column_stack([np.ones(n), age])\nbeta_hat = np.linalg.lstsq(X, sbp, rcond=None)[0]\nb0, b1 = beta_hat\n\n# Plot\nplt.scatter(age, sbp)\nxgrid = np.linspace(age.min(), age.max(), 200)\nplt.plot(xgrid, b0 + b1 * xgrid)\nplt.title(\"Simple Linear Regression: SBP vs Age\")\nplt.xlabel(\"Age (years)\")\nplt.ylabel(\"SBP (mmHg)\")\nplt.show()\n\nprint(\"Estimated intercept (b0):\", round(b0, 3))\nprint(\"Estimated slope (b1):\", round(b1, 3))\n</code></pre> <p>Try: - Increase <code>sigma</code> \u2192 more scatter, weaker signal - Change <code>beta1</code> \u2192 stronger/weaker association - Reduce <code>n</code> \u2192 more uncertainty</p>"},{"location":"Regression/1-linear-regression-simple/#4-estimation-residuals","title":"4. Estimation + Residuals","text":"<p>Residual: $$ e_i = y_i - \\hat{y}_i $$</p> <p>If assumptions are reasonable, residuals should look: - centered around 0 - no trend with \\(X\\) - roughly constant spread</p> <p>Python</p> <pre><code>yhat = b0 + b1 * age\nresid = sbp - yhat\n\nplt.scatter(yhat, resid)\nplt.axhline(0)\nplt.title(\"Residuals vs Fitted\")\nplt.xlabel(\"Fitted values\")\nplt.ylabel(\"Residuals\")\nplt.show()\n\nplt.hist(resid, bins=20, edgecolor=\"black\")\nplt.title(\"Histogram of Residuals\")\nplt.xlabel(\"Residual\")\nplt.ylabel(\"Count\")\nplt.show()\n</code></pre>"},{"location":"Regression/1-linear-regression-simple/#5-inference-confidence-interval-for-slope","title":"5. Inference: Confidence Interval for Slope","text":"<p>A 95% CI for \\(\\beta_1\\) is: $$ \\hat\\beta_1 \\pm t_{0.975,\\,n-2}\\cdot SE(\\hat\\beta_1) $$</p> <p>In practice you use a stats library (below).</p> <p>Python</p> <pre><code>import statsmodels.api as sm\n\nmodel = sm.OLS(sbp, sm.add_constant(age)).fit()\nprint(model.summary())\n</code></pre>"},{"location":"Regression/1-linear-regression-simple/#6-exercises","title":"6. Exercises","text":"Click to try  1. Change `beta1` to 0 and confirm the fitted slope is near 0.   2. Increase `sigma` to 25 and observe what happens to significance / CI width.   3. Create a binary exposure (e.g., smoker/non-smoker) and fit a line using $X \\in \\{0,1\\}$. Interpret $\\beta_1$.   4. Add a non-linear pattern: try `sbp = beta0 + beta1*age + 0.02*(age-50)**2 + eps` and see residual patterns."},{"location":"Regression/10-reporting-and-interpretation/","title":"Reporting Regression Results","text":"<p>A regression model is only useful if you report it clearly: - effect sizes - uncertainty (CI) - clinical meaning (absolute risk, predicted values) - limitations</p>"},{"location":"Regression/10-reporting-and-interpretation/#1-what-to-report-minimum","title":"1. What to report (minimum)","text":""},{"location":"Regression/10-reporting-and-interpretation/#linear-regression","title":"Linear regression","text":"<ul> <li>\\(\\hat\\beta\\) with 95% CI (and units!)</li> <li>interpret per clinically meaningful increment (e.g., per 10 years, per 5 BMI)</li> <li>model diagnostics summary (residuals, influential points)</li> </ul>"},{"location":"Regression/10-reporting-and-interpretation/#logistic-regression","title":"Logistic regression","text":"<ul> <li>OR with 95% CI</li> <li>baseline risk or predicted probabilities for typical patient profiles</li> <li>AUC + calibration (if prediction)</li> <li>events per variable / overfitting consideration</li> </ul>"},{"location":"Regression/10-reporting-and-interpretation/#2-interactive-create-a-clean-results-table-linear","title":"2. Interactive: Create a clean results table (Linear)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(77)\nn = 350\nage = np.random.uniform(30, 80, n)\nbmi = np.random.normal(27, 4, n)\nsmoker = np.random.binomial(1, 0.3, n)\n\nsbp = 95 + 0.8*age + 1.1*bmi + 5.0*smoker + np.random.normal(0, 12, n)\n\ndf = pd.DataFrame({\"sbp\": sbp, \"age\": age, \"bmi\": bmi, \"smoker\": smoker})\n\nX = sm.add_constant(df[[\"age\", \"bmi\", \"smoker\"]])\nfit = sm.OLS(df[\"sbp\"], X).fit()\n\n# Build coefficient table with CI\nci = fit.conf_int()\nout = pd.DataFrame({\n    \"beta\": fit.params,\n    \"CI_low\": ci[0],\n    \"CI_high\": ci[1],\n    \"p_value\": fit.pvalues\n})\n\n# Optional: interpret age per 10 years\nout.loc[\"age\", [\"beta\", \"CI_low\", \"CI_high\"]] *= 10\nout.rename(index={\"age\": \"age (per 10 years)\"}, inplace=True)\n\nprint(out)\n</code></pre>"},{"location":"Regression/10-reporting-and-interpretation/#3-interactive-clean-or-table-logistic","title":"3. Interactive: Clean OR table (Logistic)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(78)\nn = 1200\nage = np.random.uniform(20, 85, n)\nsmoker = np.random.binomial(1, 0.25, n)\nbmi = np.random.normal(27, 4.5, n)\n\nlp = -7 + 0.06*age + 0.8*smoker + 0.07*bmi\np = 1/(1 + np.exp(-lp))\ndisease = np.random.binomial(1, p, n)\n\ndf = pd.DataFrame({\"disease\": disease, \"age\": age, \"bmi\": bmi, \"smoker\": smoker})\n\nX = sm.add_constant(df[[\"age\", \"bmi\", \"smoker\"]])\nfit = sm.Logit(df[\"disease\"], X).fit(disp=False)\n\nci = fit.conf_int()\ntab = pd.DataFrame({\n    \"beta\": fit.params,\n    \"OR\": np.exp(fit.params),\n    \"CI_low\": np.exp(ci[0]),\n    \"CI_high\": np.exp(ci[1]),\n    \"p_value\": fit.pvalues\n})\n\n# Interpret age per 10 years\ntab.loc[\"age\", [\"beta\"]] *= 10\ntab.loc[\"age\", [\"OR\", \"CI_low\", \"CI_high\"]] = np.exp(tab.loc[\"age\", \"beta\"]), np.exp(ci.loc[\"age\", 0]*10), np.exp(ci.loc[\"age\", 1]*10)\ntab.rename(index={\"age\": \"age (per 10 years)\"}, inplace=True)\n\nprint(tab)\nprint(\"\\nOutcome prevalence:\", round(df[\"disease\"].mean(), 3))\n</code></pre>"},{"location":"Regression/10-reporting-and-interpretation/#4-writing-the-interpretation","title":"4. Writing the interpretation","text":""},{"location":"Regression/10-reporting-and-interpretation/#linear-regression-interpretation-template","title":"Linear regression interpretation template","text":"<p>After adjusting for [covariates], a [unit] increase in X was associated with a \u03b2 change in Y (95% CI: [L, U]).</p>"},{"location":"Regression/10-reporting-and-interpretation/#logistic-regression-interpretation-template","title":"Logistic regression interpretation template","text":"<p>After adjusting for [covariates], X was associated with OR times the odds of Y=1 (95% CI: [L, U]).</p> <p>Add clinical translation: - predicted probability differences for typical patients - absolute risk is often more intuitive than OR</p>"},{"location":"Regression/10-reporting-and-interpretation/#5-checklist","title":"5. Checklist","text":"<ul> <li>Units correct and interpretable</li> <li>Reference groups clearly stated</li> <li>Linearity / nonlinearity checked for continuous predictors</li> <li>Influence diagnostics performed</li> <li>Sensitivity analysis documented (optional but strong)</li> <li>For prediction: AUC + calibration</li> <li>Avoid \u201csignificant/non-significant\u201d framing as the only conclusion</li> </ul>"},{"location":"Regression/10-reporting-and-interpretation/#exercises","title":"Exercises","text":"Click to try  1. Rewrite interpretation for smoker coefficient in both linear and logistic settings.   2. Report results using clinically meaningful increments (e.g., BMI per 5 units).   3. Create a predicted probability for a 60-year-old smoker with BMI=30 and compare to non-smoker."},{"location":"Regression/11-poisson-regression/","title":"Poisson Regression (Counts &amp; Rates)","text":"<p>Poisson regression is used for count outcomes: - number of infections - number of ER visits - number of adverse events - number of hospitalizations</p> <p>It\u2019s especially common when modeling rates (counts per person-time), e.g. events per patient-year.</p>"},{"location":"Regression/11-poisson-regression/#1-when-poisson-regression-is-appropriate","title":"1. When Poisson regression is appropriate","text":"<p>Use Poisson regression when: - \\(Y\\) is a count: \\(0,1,2,\\dots\\) - events happen independently in a time/space interval (approx.) - mean\u2013variance relationship is roughly Poisson:   $$   \\mathbb{E}[Y] \\approx \\mathrm{Var}(Y)   $$</p> <p>If variance is much larger than the mean \u2192 consider Negative Binomial (overdispersion).</p>"},{"location":"Regression/11-poisson-regression/#2-model-log-link-and-why","title":"2. Model: log link (and why)","text":"<p>Poisson regression models the log of the expected count:</p> \\[ Y_i \\sim \\mathrm{Poisson}(\\mu_i),\\quad \\log(\\mu_i) = \\beta_0 + \\beta_1 X_{1i} + \\cdots + \\beta_p X_{pi} \\] <p>Because of the log link: - \\(\\mu_i\\) is always positive - coefficients become multiplicative on the original count scale</p>"},{"location":"Regression/11-poisson-regression/#3-interpretation-rate-ratio-incidence-rate-ratio-irr","title":"3. Interpretation: Rate Ratio / Incidence Rate Ratio (IRR)","text":"<p>Exponentiating coefficients gives an incidence rate ratio (IRR):</p> \\[ \\mathrm{IRR}_j = e^{\\beta_j} \\] <p>Interpretation: - IRR = 1.20 \u2192 20% higher event rate per 1-unit increase in predictor - IRR = 0.80 \u2192 20% lower event rate</p>"},{"location":"Regression/11-poisson-regression/#4-modeling-rates-with-an-offset-person-time","title":"4. Modeling rates with an offset (person-time)","text":"<p>In cohort studies you often observe different follow-up times.</p> <p>Let: - \\(Y_i\\) = number of events for person \\(i\\) - \\(t_i\\) = person-time (e.g., years of follow-up)</p> <p>Model rate by including an offset:</p> \\[ \\log(\\mu_i) = \\beta_0 + \\beta_1 X_i + \\cdots + \\log(t_i) \\] <p>where \\(\\log(t_i)\\) is included as an offset (coefficient fixed at 1).</p> <p>This makes the model effectively: - predict events per time - compare rates across groups</p>"},{"location":"Regression/11-poisson-regression/#5-interactive-simulation-events-with-unequal-follow-up","title":"5. Interactive simulation: events with unequal follow-up","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(123)\nn = 1500\n\n# Predictors\nage = np.random.uniform(20, 80, n)\nsmoker = np.random.binomial(1, 0.25, n)\n\n# Follow-up time (person-years): varies across individuals\nt = np.random.uniform(0.5, 5.0, n)\n\n# ---- TRUE RATE MODEL (edit these) ----\nbeta0 = -3.2\nbeta_age = 0.015     # per year\nbeta_smoker = 0.55   # IRR ~ exp(0.55) \u2248 1.73\n# -------------------------------------\n\n# log(rate) = beta0 + beta_age*age + beta_smoker*smoker\nlog_rate = beta0 + beta_age*age + beta_smoker*smoker\nrate = np.exp(log_rate)  # events per person-year\n\n# expected count = rate * time\nmu = rate * t\n\n# generate counts\ny = np.random.poisson(mu, n)\n\ndf = pd.DataFrame({\"events\": y, \"age\": age, \"smoker\": smoker, \"py\": t})\n\n# Fit Poisson with offset log(person-time)\nX = sm.add_constant(df[[\"age\", \"smoker\"]])\npois = sm.GLM(df[\"events\"], X, family=sm.families.Poisson(), offset=np.log(df[\"py\"])).fit()\n\nprint(pois.summary())\n\n# IRRs with CI\nparams = pois.params\nci = pois.conf_int()\nirr = pd.DataFrame({\n    \"beta\": params,\n    \"IRR\": np.exp(params),\n    \"CI_low\": np.exp(ci[0]),\n    \"CI_high\": np.exp(ci[1]),\n})\nprint(\"\\nIRR table:\\n\", irr)\n\nprint(\"\\nMean events:\", round(df[\"events\"].mean(), 3))\nprint(\"Mean person-years:\", round(df[\"py\"].mean(), 3))\n</code></pre> <p>Try: - Increase <code>beta_smoker</code> to see smoking IRR grow - Set <code>beta_age=0</code> to remove age effect - Make follow-up time shorter (e.g., <code>t ~ Uniform(0.1, 1.0)</code>) and see counts drop</p>"},{"location":"Regression/11-poisson-regression/#6-overdispersion-check","title":"6. Overdispersion check","text":"<p>Poisson assumes variance \u2248 mean. Real data often has overdispersion.</p> <p>A quick check: $$ \\frac{\\text{Deviance}}{\\text{df}} \\approx 1 \\text{ (Poisson ok)}, \\quad \\gg 1 \\text{ (overdispersion)} $$</p> <p>Python</p> <pre><code>dev = pois.deviance\ndf_resid = pois.df_resid\nprint(\"Deviance/df:\", round(dev/df_resid, 3))\n</code></pre> <p>If Deviance/df is large (e.g., &gt; 1.5\u20132), consider: - robust SE - Negative Binomial regression - zero-inflated models (if many zeros)</p>"},{"location":"Regression/11-poisson-regression/#7-robust-standard-errors-easy-fix-for-mild-overdispersion","title":"7. Robust standard errors (easy fix for mild overdispersion)","text":"<p>Python</p> <pre><code>pois_rob = pois.get_robustcov_results(cov_type=\"HC3\")\nprint(pois_rob.summary())\n\n# Robust IRR table\nparams = pois_rob.params\nci = pois_rob.conf_int()\nirr_rob = pd.DataFrame({\n    \"beta\": params,\n    \"IRR\": np.exp(params),\n    \"CI_low\": np.exp(ci[0]),\n    \"CI_high\": np.exp(ci[1]),\n})\nprint(\"\\nRobust IRR table:\\n\", irr_rob)\n</code></pre>"},{"location":"Regression/11-poisson-regression/#8-examples","title":"8. Examples","text":"<ul> <li>Incidence rate of infections by treatment group (offset = person-time)</li> <li>Hospital visits by exposure status adjusting for age/sex</li> <li>Adverse event counts in clinical trials (often person-time differs due to dropout)</li> </ul>"},{"location":"Regression/11-poisson-regression/#9-exercises","title":"9. Exercises","text":"Click to try  1. Remove the offset and compare coefficients (should be biased when follow-up varies).   2. Create overdispersion by mixing two subpopulations (different baseline rates) and re-check Deviance/df.   3. Add a categorical predictor (treatment groups) and interpret IRR vs reference.   4. Simulate many zeros by making baseline rate very small; discuss if zero-inflated models might be needed."},{"location":"Regression/11-poisson-regression/#summary","title":"Summary","text":"<ul> <li>Poisson regression models counts using a log link.</li> <li>Exponentiated coefficients are IRRs (rate ratios).</li> <li>Use an offset to model event rates per person-time.</li> <li>Always check for overdispersion; consider robust SE or Negative Binomial if needed.</li> </ul>"},{"location":"Regression/12-negative-binomial-regression/","title":"Negative Binomial Regression (Overdispersed Counts)","text":"<p>Negative Binomial (NB) regression is used for count outcomes when Poisson regression fails due to overdispersion:</p> <ul> <li>Poisson assumption: \\(\\mathrm{Var}(Y) \\approx \\mathbb{E}[Y]\\)</li> <li>Overdispersion: \\(\\mathrm{Var}(Y) \\gg \\mathbb{E}[Y]\\) (very common in health data)</li> </ul> <p>Examples:  - number of ER visits (many zeros + a few heavy users)  - infections per patient-year  - asthma exacerbations per year  - adverse events per person-time</p>"},{"location":"Regression/12-negative-binomial-regression/#1-why-overdispersion-happens","title":"1. Why overdispersion happens","text":"<p>Common reasons:  - unmeasured heterogeneity (frailty): some patients are \u201chigh risk\u201d  - clustering (hospital/site/provider effects)  - event dependence (prior event increases future risk)  - excess zeros (sometimes)</p> <p>Poisson under overdispersion typically gives:  - too-small standard errors  - overly optimistic p-values / narrow CI</p>"},{"location":"Regression/12-negative-binomial-regression/#2-model-form-same-link-extra-dispersion","title":"2. Model form (same link, extra dispersion)","text":"<p>NB regression still uses the log link:</p> \\[ \\log(\\mu_i) = \\beta_0 + \\beta_1 X_{1i} + \\cdots + \\log(t_i) \\] <p>but variance is larger than mean. A common parameterization:</p> \\[ \\mathrm{Var}(Y_i) = \\mu_i + \\alpha \\mu_i^2 \\] <ul> <li>\\(\\alpha &gt; 0\\) captures extra-Poisson variability</li> <li>if \\(\\alpha \\to 0\\), NB behaves like Poisson</li> </ul>"},{"location":"Regression/12-negative-binomial-regression/#3-interpretation","title":"3. Interpretation:","text":"<p>Exponentiated coefficients are still incidence rate ratios (IRR):</p> \\[ \\mathrm{IRR}_j = e^{\\beta_j} \\] <p>Interpretation identical to Poisson: - IRR = 1.30 \u2192 30% higher event rate per 1-unit increase in \\(X_j\\)</p>"},{"location":"Regression/12-negative-binomial-regression/#4-interactive-simulation-generate-overdispersed-counts","title":"4. Interactive simulation: generate overdispersed counts","text":"<p>We create overdispersion by adding person-level unobserved heterogeneity (random multiplier).</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(100)\nn = 2000\n\nage = np.random.uniform(20, 80, n)\nsmoker = np.random.binomial(1, 0.25, n)\npy = np.random.uniform(0.5, 5.0, n)  # person-years\n\n# True log-rate model\nbeta0 = -3.4\nbeta_age = 0.015\nbeta_smoker = 0.55  # IRR ~ 1.73\n\nlog_rate = beta0 + beta_age*age + beta_smoker*smoker\nbase_rate = np.exp(log_rate)  # events per person-year\n\n# Unobserved heterogeneity (frailty-like): multiplicative random effect\n# Larger variance here -&gt; more overdispersion\nhetero_sd = 0.9\nu = np.exp(np.random.normal(0, hetero_sd, n))\n\nmu = base_rate * u * py\ny = np.random.poisson(mu)\n\ndf = pd.DataFrame({\"events\": y, \"age\": age, \"smoker\": smoker, \"py\": py})\n\n# Fit Poisson with offset\nX = sm.add_constant(df[[\"age\", \"smoker\"]])\npois = sm.GLM(df[\"events\"], X, family=sm.families.Poisson(), offset=np.log(df[\"py\"])).fit()\n\nprint(\"Poisson Deviance/df:\", round(pois.deviance/pois.df_resid, 3))\nprint(pois.summary())\n</code></pre> <p>Try: - Increase <code>hetero_sd</code> to 1.2 \u2192 more overdispersion - Decrease to 0.2 \u2192 Poisson becomes reasonable again</p>"},{"location":"Regression/12-negative-binomial-regression/#5-fit-negative-binomial-model-and-compare","title":"5. Fit Negative Binomial model (and compare)","text":"<p>Python</p> <pre><code># Negative Binomial GLM with offset\nnb = sm.GLM(df[\"events\"], X, family=sm.families.NegativeBinomial(), offset=np.log(df[\"py\"])).fit()\n\nprint(\"NB Deviance/df:\", round(nb.deviance/nb.df_resid, 3))\nprint(nb.summary())\n\n# IRR tables\nimport numpy as np\nimport pandas as pd\n\ndef irr_table(fit):\n    ci = fit.conf_int()\n    tab = pd.DataFrame({\n        \"beta\": fit.params,\n        \"IRR\": np.exp(fit.params),\n        \"CI_low\": np.exp(ci[0]),\n        \"CI_high\": np.exp(ci[1]),\n    })\n    return tab\n\nprint(\"\\nPoisson IRR:\\n\", irr_table(pois))\nprint(\"\\nNegative Binomial IRR:\\n\", irr_table(nb))\n</code></pre> <p>What you\u2019ll usually see: - Similar point estimates (sometimes) - NB has larger SE / wider CI when overdispersion is present</p>"},{"location":"Regression/12-negative-binomial-regression/#6-when-to-use-what","title":"6. When to use what","text":"<ul> <li>Poisson + offset is fine when Deviance/df ~ 1</li> <li>If Deviance/df &gt;&gt; 1, consider:</li> <li>Negative Binomial (best general default)</li> <li>Poisson with robust SE (mild overdispersion)</li> <li>Zero-inflated models (many structural zeros)</li> </ul>"},{"location":"Regression/12-negative-binomial-regression/#exercises","title":"Exercises","text":"Click to try  1. Reduce `hetero_sd` until Poisson Deviance/df is near 1. Compare Poisson vs NB outputs.   2. Simulate a 3-level treatment group and estimate IRRs vs placebo with NB.   3. Make follow-up times very unequal and verify offset is essential.   4. Add a second unmeasured subgroup (e.g., half the population has 3\u00d7 baseline rate) and see overdispersion increase."},{"location":"Regression/12-negative-binomial-regression/#summary","title":"Summary","text":"<ul> <li>NB regression is designed for overdispersed counts.</li> <li>IRR interpretation is the same as Poisson.</li> <li>In biostat data, NB is often more realistic and yields more reliable uncertainty.</li> </ul>"},{"location":"Regression/13-cox-regression/","title":"Cox Proportional Hazards Regression (Time-to-Event)","text":"<p>Cox regression is used for survival / time-to-event outcomes, where:  - not everyone experiences the event (censoring)  - time matters (not just event yes/no)</p> <p>Examples:  - time to death  - time to relapse  - time to hospitalization  - time to disease onset</p>"},{"location":"Regression/13-cox-regression/#1-key-ideas","title":"1. Key ideas","text":""},{"location":"Regression/13-cox-regression/#time-event-censoring","title":"Time, event, censoring","text":"<p>For each subject \\(i\\):  - \\(T_i\\) = observed time  - \\(\\delta_i\\) = event indicator (1=event occurred, 0=censored)</p> <p>Censoring (typical):  - lost to follow-up  - study ends before event</p>"},{"location":"Regression/13-cox-regression/#2-hazard-and-hazard-ratio-hr","title":"2. Hazard and Hazard Ratio (HR)","text":"<p>Hazard is the instantaneous event rate at time \\(t\\) given survival up to \\(t\\).</p> <p>Cox model: $$ h(t \\mid X) = h_0(t)\\exp(\\beta_1 X_1 + \\cdots + \\beta_p X_p) $$</p> <ul> <li>\\(h_0(t)\\): baseline hazard (unspecified)</li> <li>\\(\\exp(\\beta_j)\\): hazard ratio (HR) for a 1-unit increase in \\(X_j\\)</li> </ul> <p>Interpretation: - HR = 1.30 \u2192 30% higher instantaneous risk - HR = 0.70 \u2192 30% lower instantaneous risk (protective)</p>"},{"location":"Regression/13-cox-regression/#3-proportional-hazards-ph-assumption","title":"3. Proportional Hazards (PH) assumption","text":"<p>Cox assumes hazard ratios do not change over time: $$ \\frac{h(t \\mid X=1)}{h(t \\mid X=0)} = \\text{constant in } t $$</p> <p>If PH is violated: - consider time-varying effects - stratified Cox - alternative models (AFT, flexible parametric, etc.)</p>"},{"location":"Regression/13-cox-regression/#4-interactive-simulation-survival-data-with-known-hrs","title":"4. Interactive simulation: survival data with known HRs","text":"<p>We\u2019ll simulate with an exponential baseline hazard (for simplicity), then fit a Cox model.</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(999)\nn = 2000\n\nage = np.random.uniform(30, 85, n)\ntrt = np.random.binomial(1, 0.5, n)  # 1=drug, 0=control\n\n# ---- TRUE COX-LIKE LOG HAZARD MODEL (edit these) ----\nbeta_age = 0.035         # HR per 1 year = exp(0.035) ~ 1.036\nbeta_trt = -0.45         # HR for drug vs control = exp(-0.45) ~ 0.64\nbase_hazard = 0.03       # baseline hazard rate (per unit time)\n# ----------------------------------------------------\n\nlinpred = beta_age*age + beta_trt*trt\nhazard = base_hazard * np.exp(linpred)\n\n# Exponential survival time: T ~ Exp(rate=hazard)\nT = np.random.exponential(scale=1/hazard)\n\n# Random administrative censoring\nC = np.random.uniform(0.0, 40.0, n)\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event, \"age\": age, \"trt\": trt})\n\nprint(df.head())\nprint(\"\\nEvent fraction:\", round(df[\"event\"].mean(), 3))\n</code></pre>"},{"location":"Regression/13-cox-regression/#5-fit-cox-model-python","title":"5. Fit Cox model (Python)","text":"<p>We\u2019ll use <code>lifelines</code> (common in survival analysis). If it\u2019s not installed in your environment, install it in your venv with <code>pip install lifelines</code>.</p> <p>Python</p> <pre><code>from lifelines import CoxPHFitter\nimport numpy as np\n\ncph = CoxPHFitter()\ncph.fit(df, duration_col=\"time\", event_col=\"event\", formula=\"age + trt\")\ncph.print_summary()\n\n# HR table\nhr = np.exp(cph.params_)\nprint(\"\\nEstimated HRs:\\n\", hr)\n</code></pre> <p>Interpretation: - <code>trt</code> HR should be around ~0.64 (protective) - <code>age</code> HR &gt; 1 (higher risk with older age)</p>"},{"location":"Regression/13-cox-regression/#6-plot-survival-curves-example-profiles","title":"6. Plot survival curves (example profiles)","text":"<p>Cox can give survival curves for specified covariates.</p> <p>Python</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Two profiles: same age, different treatment\nprof_control = pd.DataFrame({\"age\": [60], \"trt\": [0]})\nprof_drug = pd.DataFrame({\"age\": [60], \"trt\": [1]})\n\nsf_control = cph.predict_survival_function(prof_control)\nsf_drug = cph.predict_survival_function(prof_drug)\n\nplt.plot(sf_control.index, sf_control.values, label=\"Control (age=60)\")\nplt.plot(sf_drug.index, sf_drug.values, label=\"Drug (age=60)\")\nplt.title(\"Predicted Survival Curves\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Survival probability\")\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"Regression/13-cox-regression/#7-checking-ph-assumption-important","title":"7. Checking PH assumption (important!)","text":"<p>lifelines provides checks using Schoenfeld residuals.</p> <p>Python</p> <pre><code>cph.check_assumptions(df, p_value_threshold=0.05, show_plots=False)\n</code></pre> <p>If PH is violated: - include time interaction terms - stratify by the violating covariate - use flexible survival models</p>"},{"location":"Regression/13-cox-regression/#8-cox-vs-logistic-biostat-intuition","title":"8. Cox vs Logistic (biostat intuition)","text":"<ul> <li>Logistic: models event occurrence by a fixed time (ignores exact timing)</li> <li>Cox: uses timing + handles censoring \u2192 more efficient and appropriate for follow-up studies</li> </ul>"},{"location":"Regression/13-cox-regression/#exercises","title":"Exercises","text":"Click to try  1. Increase censoring (make C smaller) and see precision drop.   2. Change `beta_trt` to 0 and confirm HR ~ 1.   3. Add an interaction `age*trt` and interpret effect modification.   4. Create PH violation by making treatment effect fade over time (advanced: simulate time-varying hazards)."},{"location":"Regression/13-cox-regression/#summary","title":"Summary","text":"<ul> <li>Cox regression models time-to-event with censoring.</li> <li>Exponentiated coefficients are hazard ratios (HR).</li> <li>Proportional hazards is a key assumption \u2014 always check it.</li> <li>Cox is standard in clinical trials and cohort survival studies.</li> </ul>"},{"location":"Regression/2-linear-regression-multiple/","title":"Multiple Linear Regression (Adjusted Effects)","text":"<p>Multiple linear regression extends linear regression to multiple predictors.</p> <p>Example: - Outcome: SBP (mmHg) - Predictors: age, BMI, sex, smoking - Goal: estimate association of BMI with SBP adjusting for age, etc.</p>"},{"location":"Regression/2-linear-regression-multiple/#1-model","title":"1. Model","text":"\\[ Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\cdots + \\beta_p X_{pi} + \\varepsilon_i \\] <p>Interpretation: - \\(\\beta_j\\) is the expected change in \\(Y\\) for a 1-unit increase in \\(X_j\\), holding the other predictors constant.</p>"},{"location":"Regression/2-linear-regression-multiple/#2-confounding-why-adjustment-matters","title":"2. Confounding (Why \u201cadjustment\u201d matters)","text":"<p>Suppose: - older people have higher SBP - older people also tend to have higher BMI</p> <p>Then BMI\u2013SBP association can look stronger than it truly is if you ignore age.</p>"},{"location":"Regression/2-linear-regression-multiple/#3-interactive-simulation-confounding-adjustment","title":"3. Interactive Simulation: confounding + adjustment","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(7)\n\nn = 400\n\n# Age is a confounder: affects both BMI and SBP\nage = np.random.uniform(20, 80, n)\n\n# BMI increases with age (confounding structure)\nbmi = 22 + 0.06*(age - 50) + np.random.normal(0, 2.5, n)\n\n# TRUE model: SBP depends on age strongly and BMI moderately\nsbp = 105 + 0.75*age + 0.9*bmi + np.random.normal(0, 10, n)\n\ndf = pd.DataFrame({\"sbp\": sbp, \"age\": age, \"bmi\": bmi})\n\n# Naive model (unadjusted): SBP ~ BMI\nm_naive = sm.OLS(df[\"sbp\"], sm.add_constant(df[\"bmi\"])).fit()\n\n# Adjusted model: SBP ~ BMI + Age\nm_adj = sm.OLS(df[\"sbp\"], sm.add_constant(df[[\"bmi\", \"age\"]])).fit()\n\nprint(\"Unadjusted BMI slope:\", round(m_naive.params[\"bmi\"], 3))\nprint(\"Adjusted BMI slope:  \", round(m_adj.params[\"bmi\"], 3))\nprint(\"\\nAdjusted model summary:\\n\")\nprint(m_adj.summary())\n</code></pre> <p>Try: - Change the BMI\u2013age relationship (<code>0.06</code>) to make confounding stronger/weaker - Change the true BMI effect (<code>0.9</code>) and see if adjustment recovers it</p>"},{"location":"Regression/2-linear-regression-multiple/#4-categorical-predictors-sex","title":"4. Categorical Predictors (Sex)","text":"<p>Binary coding: - sex = 0 (female), 1 (male)</p> <p>Then \\(\\beta_{\\text{sex}}\\) is the mean difference in \\(Y\\) between males vs females (adjusted).</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(10)\nn = 300\nage = np.random.uniform(20, 80, n)\nsex = np.random.binomial(1, 0.5, n)  # 0/1\nbmi = 23 + 0.05*(age-50) + 1.2*sex + np.random.normal(0, 2.2, n)\n\nsbp = 100 + 0.8*age + 0.7*bmi + 4.5*sex + np.random.normal(0, 10, n)\n\ndf = pd.DataFrame({\"sbp\": sbp, \"age\": age, \"bmi\": bmi, \"sex\": sex})\n\nmodel = sm.OLS(df[\"sbp\"], sm.add_constant(df[[\"age\", \"bmi\", \"sex\"]])).fit()\nprint(model.summary())\n</code></pre> <p>Interpret: - sex coefficient: adjusted mean difference in SBP for sex=1 vs sex=0</p>"},{"location":"Regression/2-linear-regression-multiple/#5-interaction-effect-modification","title":"5. Interaction (Effect Modification)","text":"<p>Sometimes the effect of BMI differs by sex:</p> \\[ SBP = \\beta_0 + \\beta_1 BMI + \\beta_2 Sex + \\beta_3 (BMI \\times Sex) + \\cdots \\] <ul> <li>If \\(\\beta_3 \\neq 0\\), the BMI slope depends on sex.</li> </ul> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\nnp.random.seed(11)\nn = 500\nsex = np.random.binomial(1, 0.5, n)\nbmi = np.random.normal(27, 4, n)\n\n# True effect: BMI slope is higher in sex=1\nsbp = 110 + 0.8*bmi + 3.0*sex + 0.6*(bmi*sex) + np.random.normal(0, 10, n)\n\ndf = pd.DataFrame({\"sbp\": sbp, \"bmi\": bmi, \"sex\": sex})\n\nm_no_int = smf.ols(\"sbp ~ bmi + sex\", data=df).fit()\nm_int = smf.ols(\"sbp ~ bmi * sex\", data=df).fit()\n\nprint(\"No interaction model:\\n\", m_no_int.params, \"\\n\")\nprint(\"With interaction model:\\n\", m_int.params)\n</code></pre>"},{"location":"Regression/2-linear-regression-multiple/#exercises","title":"Exercises","text":"Click to try  1. Create a strong confounder and show how unadjusted slope is biased.   2. Add collinearity: make BMI highly correlated with another predictor; watch standard errors inflate.   3. Fit an interaction model and interpret slopes separately for sex=0 and sex=1."},{"location":"Regression/3-logistic-regression/","title":"Logistic Regression (Binary Outcomes)","text":"<p>Logistic regression is used when the outcome is binary: - Disease yes/no - Treatment response yes/no - Hospitalization yes/no - Adverse event yes/no</p>"},{"location":"Regression/3-logistic-regression/#1-why-not-linear-regression","title":"1. Why not linear regression?","text":"<p>A linear model can predict probabilities &lt; 0 or &gt; 1. Logistic regression ensures predictions stay in [0,1] and models odds.</p>"},{"location":"Regression/3-logistic-regression/#2-model-probability-odds-log-odds","title":"2. Model: probability, odds, log-odds","text":"<p>Let \\(Y_i \\in \\{0,1\\}\\) and \\(p_i = P(Y_i=1 \\mid X_i)\\).</p> <p>Odds: $$ \\text{odds}_i = \\frac{p_i}{1-p_i} $$</p> <p>Logit (log-odds): $$ \\log\\left(\\frac{p_i}{1-p_i}\\right) = \\beta_0 + \\beta_1 X_{1i} + \\cdots + \\beta_p X_{pi} $$</p> <p>Convert log-odds back to probability: $$ p_i = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_{1i} + \\cdots + \\beta_p X_{pi})}} $$</p>"},{"location":"Regression/3-logistic-regression/#3-interpretation-odds-ratio-or","title":"3. Interpretation: Odds Ratio (OR)","text":"<p>For a 1-unit increase in \\(X_j\\): $$ \\text{OR}_j = e^{\\beta_j} $$</p> <ul> <li>OR &gt; 1: higher odds of outcome</li> <li>OR &lt; 1: lower odds</li> <li>OR = 1: no association</li> </ul> <p>Biostat example: OR = 1.30 for smoking means 30% higher odds of disease for smokers vs non-smokers, holding others constant.</p>"},{"location":"Regression/3-logistic-regression/#4-interactive-simulation-create-disease-data-with-known-ors","title":"4. Interactive Simulation: create disease data with known ORs","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(42)\nn = 1500\n\n# Predictors\nage = np.random.uniform(20, 80, n)\nsmoker = np.random.binomial(1, 0.25, n)        # 25% smokers\nbmi = np.random.normal(27, 4.5, n)\n\n# ---- TRUE LOGISTIC MODEL (edit these!) ----\nbeta0 = -9.0\nbeta_age = 0.07          # per year\nbeta_smoker = 0.9        # log-odds; OR = exp(0.9) ~ 2.46\nbeta_bmi = 0.08          # per 1 BMI\n# ------------------------------------------\n\nlinpred = beta0 + beta_age*age + beta_smoker*smoker + beta_bmi*bmi\np = 1/(1 + np.exp(-linpred))\ndisease = np.random.binomial(1, p, n)\n\ndf = pd.DataFrame({\"disease\": disease, \"age\": age, \"smoker\": smoker, \"bmi\": bmi})\n\nX = sm.add_constant(df[[\"age\", \"smoker\", \"bmi\"]])\nmodel = sm.Logit(df[\"disease\"], X).fit(disp=False)\n\n# ORs with CI\nparams = model.params\nconf = model.conf_int()\nor_table = pd.DataFrame({\n    \"beta\": params,\n    \"OR\": np.exp(params),\n    \"CI_low\": np.exp(conf[0]),\n    \"CI_high\": np.exp(conf[1]),\n})\n\nprint(or_table)\nprint(\"\\nDisease prevalence:\", round(df['disease'].mean(), 4))\n</code></pre> <p>Try: - Increase <code>beta_smoker</code> and see OR increase and prevalence rise - Make <code>beta_bmi</code> negative (protective) and watch OR &lt; 1 - Make <code>beta0</code> less negative to increase baseline risk</p>"},{"location":"Regression/3-logistic-regression/#5-predicted-probabilities-clinical-meaning","title":"5. Predicted probabilities (clinical meaning)","text":"<p>Odds ratios can be hard to interpret clinically. Probabilities are often easier.</p> <p>Python</p> <pre><code>import numpy as np\n\n# Pull fitted coefficients\nb = model.params\n\ndef predict_prob(age, smoker, bmi):\n    lp = b[\"const\"] + b[\"age\"]*age + b[\"smoker\"]*smoker + b[\"bmi\"]*bmi\n    return 1/(1 + np.exp(-lp))\n\n# Example patients\np1 = predict_prob(age=40, smoker=0, bmi=24)\np2 = predict_prob(age=40, smoker=1, bmi=24)\np3 = predict_prob(age=65, smoker=1, bmi=31)\n\nprint(\"Age 40, non-smoker, BMI 24:\", round(p1, 4))\nprint(\"Age 40, smoker, BMI 24:    \", round(p2, 4))\nprint(\"Age 65, smoker, BMI 31:    \", round(p3, 4))\n</code></pre>"},{"location":"Regression/3-logistic-regression/#6-model-performance-roc-auc-discrimination","title":"6. Model performance: ROC-AUC (discrimination)","text":"<p>AUC answers: \u201cHow well can the model separate cases vs non-cases?\u201d</p> <p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\npred = model.predict(X)\n\nfpr, tpr, thr = roc_curve(df[\"disease\"], pred)\nauc = roc_auc_score(df[\"disease\"], pred)\n\nplt.plot(fpr, tpr)\nplt.plot([0,1],[0,1], linestyle=\"--\")\nplt.title(f\"ROC Curve (AUC = {auc:.3f})\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.show()\n</code></pre>"},{"location":"Regression/3-logistic-regression/#7-calibration-are-predicted-risks-too-highlow","title":"7. Calibration (are predicted risks too high/low?)","text":"<p>Discrimination (AUC) is not calibration. Calibration checks whether predicted probabilities match observed rates.</p> <p>Python</p> <pre><code>import pandas as pd\nimport numpy as np\n\npred = model.predict(X)\ndf_cal = df.copy()\ndf_cal[\"pred\"] = pred\ndf_cal[\"bin\"] = pd.qcut(df_cal[\"pred\"], 10, duplicates=\"drop\")\n\ncal = df_cal.groupby(\"bin\").agg(\n    mean_pred=(\"pred\", \"mean\"),\n    obs_rate=(\"disease\", \"mean\"),\n    n=(\"disease\", \"size\")\n).reset_index(drop=True)\n\nprint(cal)\n</code></pre> <p>If mean_pred is much higher than obs_rate in many bins, your model is overpredicting.</p>"},{"location":"Regression/3-logistic-regression/#8-categorical-predictors-reference-groups","title":"8. Categorical predictors + reference groups","text":"<p>If you have multi-level categories (e.g., race/ethnicity groups), logistic regression uses dummy variables with a reference level.</p> <p>Interpretation of an OR for a category:</p> <p>odds relative to the reference group, adjusted for other covariates.</p>"},{"location":"Regression/3-logistic-regression/#9-common-pitfalls-in-biostat-logistic-regression","title":"9. Common pitfalls in biostat logistic regression","text":"<ul> <li>Odds ratio \u2260 risk ratio (especially when outcome is common)</li> <li>Separation (perfect prediction \u2192 unstable estimates)</li> <li>Too many predictors for too few events (overfitting)</li> <li>Nonlinearity for continuous predictors (consider splines)</li> <li>Interactions (effect modification) matter clinically</li> </ul>"},{"location":"Regression/3-logistic-regression/#exercises-very-applied","title":"Exercises (very applied)","text":"Click to try  1. Make the disease outcome common by increasing `beta0`. Compare OR interpretation vs probability interpretation.   2. Add an interaction `smoker * age` in the true model and fit a model with/without interaction.   3. Create a confounder: make smokers older, refit models with/without age adjustment, compare smoker OR.   4. Change the sample size `n` and observe CI width and AUC stability."},{"location":"Regression/4-diagnostics-linear/","title":"Diagnostics &amp; Assumptions (Linear Regression)","text":"<p>Linear regression is powerful, but only interpretable when model assumptions are reasonably met.</p> <p>Biostat examples: - SBP ~ age + BMI - LDL ~ statin dose + adherence</p>"},{"location":"Regression/4-diagnostics-linear/#1-key-assumptions-what-to-check","title":"1. Key Assumptions (What to check)","text":"<p>For inference (p-values, CI) to be reliable, we usually want:</p> <ol> <li>Linearity: mean of \\(Y\\) changes linearly with predictors  </li> <li>Independent errors: observations independent (common in cohort, not in repeated measures)  </li> <li>Constant variance (homoscedasticity): residual spread is roughly constant  </li> <li>Normality of residuals: mainly for small samples / inference  </li> <li>No extreme influence: no single point drives the whole model  </li> </ol>"},{"location":"Regression/4-diagnostics-linear/#2-interactive-create-data-that-violates-assumptions","title":"2. Interactive: Create data that violates assumptions","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\nnp.random.seed(1)\n\nn = 200\nx = np.random.uniform(0, 10, n)\n\n# ---- choose ONE scenario by uncommenting ----\n# (A) Well-behaved linear model\ny = 5 + 2*x + np.random.normal(0, 2, n)\n\n# (B) Nonlinearity\n# y = 5 + 2*x + 0.6*(x-5)**2 + np.random.normal(0, 2, n)\n\n# (C) Heteroscedasticity (variance increases with x)\n# y = 5 + 2*x + np.random.normal(0, 0.3*x, n)\n\n# (D) Outlier / influential point\n# y = 5 + 2*x + np.random.normal(0, 2, n)\n# y[0] += 40\n# x[0] += 8\n# --------------------------------------------\n\nX = sm.add_constant(x)\nfit = sm.OLS(y, X).fit()\n\n# Scatter + fitted line\nplt.scatter(x, y)\nxg = np.linspace(x.min(), x.max(), 200)\nplt.plot(xg, fit.params[0] + fit.params[1]*xg)\nplt.title(\"Data + fitted linear regression\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.show()\n\nprint(fit.summary())\n</code></pre>"},{"location":"Regression/4-diagnostics-linear/#3-residual-plots-the-1-diagnostic","title":"3. Residual plots (the #1 diagnostic)","text":"<p>Residuals vs fitted: - random cloud around 0  - curve pattern \u2192 nonlinearity  - funnel shape \u2192 heteroscedasticity </p> <p>Python</p> <pre><code>yhat = fit.predict(X)\nresid = y - yhat\n\nplt.scatter(yhat, resid)\nplt.axhline(0)\nplt.title(\"Residuals vs Fitted\")\nplt.xlabel(\"Fitted values\")\nplt.ylabel(\"Residuals\")\nplt.show()\n</code></pre>"},{"location":"Regression/4-diagnostics-linear/#4-normal-q-q-plot-residual-normality","title":"4. Normal Q-Q plot (residual normality)","text":"<p>Normality matters most for: - small n - hypothesis tests, CI</p> <p>Python</p> <pre><code>import scipy.stats as st\n\nst.probplot(resid, dist=\"norm\", plot=plt)\nplt.title(\"Q-Q Plot of Residuals\")\nplt.show()\n</code></pre>"},{"location":"Regression/4-diagnostics-linear/#5-influence-leverage-cooks-distance","title":"5. Influence: leverage &amp; Cook\u2019s distance","text":"<p>In biostat datasets, a few unusual patients can dominate. We check Cook\u2019s distance.</p> <p>Python</p> <pre><code>infl = fit.get_influence()\ncooks = infl.cooks_distance[0]\n\nplt.stem(cooks, use_line_collection=True)\nplt.title(\"Cook's Distance by observation\")\nplt.xlabel(\"Observation index\")\nplt.ylabel(\"Cook's D\")\nplt.show()\n\n# Show top 5 influential points\ntop = np.argsort(cooks)[-5:][::-1]\nprint(\"Top influential indices:\", top)\nprint(\"Top Cook's D:\", cooks[top])\n</code></pre>"},{"location":"Regression/4-diagnostics-linear/#6-what-to-do-when-assumptions-fail-biostat-moves","title":"6. What to do when assumptions fail (biostat moves)","text":"<ul> <li>Nonlinearity \u2192 add transforms or splines (see next files)</li> <li>Heteroscedasticity \u2192 robust SE (HC3), transform outcome, or model variance</li> <li>Outliers/influence \u2192 verify data, robust regression, sensitivity analysis</li> <li>Non-independence (repeated measures) \u2192 mixed models / GEE (later topic)</li> </ul> <p>Python</p> <pre><code># Robust standard errors (HC3) for heteroscedasticity\nrobust = fit.get_robustcov_results(cov_type=\"HC3\")\nprint(robust.summary())\n</code></pre>"},{"location":"Regression/4-diagnostics-linear/#exercises","title":"Exercises","text":"Click to try  1. Turn on scenario (B). Explain what residual plot shows.   2. Turn on scenario (C). Compare standard vs robust SE.   3. Turn on scenario (D). Remove the influential point and compare coefficients.   4. Use a log-transform of y (if y&gt;0) and see if residuals improve."},{"location":"Regression/5-categorical-predictors/","title":"Categorical Predictors (Dummy Coding)","text":"<p>Many biostat predictors are categorical: - sex (female/male) - treatment group (placebo/drug) - smoking status (never/former/current) - genotype category (AA/AG/GG)</p>"},{"location":"Regression/5-categorical-predictors/#1-dummy-coding-one-hot-with-reference-group","title":"1. Dummy coding (one-hot with reference group)","text":"<p>For a 3-level variable (never/former/current): - choose a reference (e.g., never) - create indicators:   - former = 1 if former else 0   - current = 1 if current else 0</p> <p>Model: $$ Y = \\beta_0 + \\beta_1 \\cdot I(\\text{former}) + \\beta_2 \\cdot I(\\text{current}) + \\cdots $$</p> <p>Interpretation: - \\(\\beta_1\\) = difference (former \u2212 never), adjusted - \\(\\beta_2\\) = difference (current \u2212 never), adjusted</p>"},{"location":"Regression/5-categorical-predictors/#2-interactive-simulation-treatment-groups","title":"2. Interactive simulation: treatment groups","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\nnp.random.seed(5)\nn = 300\n\n# Categorical treatment variable\ntrt = np.random.choice([\"placebo\", \"low_dose\", \"high_dose\"], size=n, p=[0.4, 0.3, 0.3])\nage = np.random.uniform(30, 75, n)\n\n# True effects on SBP change (negative is improvement)\n# placebo: 0\n# low_dose: -4\n# high_dose: -8\neffect = np.where(trt == \"placebo\", 0, np.where(trt == \"low_dose\", -4, -8))\n\ny = 2 + 0.05*(age-50) + effect + np.random.normal(0, 4, n)\n\ndf = pd.DataFrame({\"sbp_change\": y, \"treatment\": trt, \"age\": age})\n\n# By default, statsmodels chooses an alphabetical reference.\n# Force placebo as reference:\nmodel = smf.ols(\"sbp_change ~ C(treatment, Treatment(reference='placebo')) + age\", data=df).fit()\nprint(model.summary())\n</code></pre> <p>Interpret: - treatment[T.low_dose] = low_dose \u2212 placebo (adjusted) - treatment[T.high_dose] = high_dose \u2212 placebo (adjusted)</p>"},{"location":"Regression/5-categorical-predictors/#3-logistic-regression-with-categories-or-interpretation","title":"3. Logistic regression with categories (OR interpretation)","text":"<p>Same idea, but exponentiate coefficients to get OR vs reference group.</p> <p>Python</p> <pre><code>import statsmodels.formula.api as smf\nimport numpy as np\n\nnp.random.seed(6)\nn = 1000\n\ntrt = np.random.choice([\"placebo\", \"drug\"], size=n, p=[0.5, 0.5])\nage = np.random.uniform(20, 80, n)\n\n# True log-odds: drug reduces risk\nbeta0 = -3.0\nbeta_age = 0.04\nbeta_drug = -0.6   # OR ~ 0.55\n\nlp = beta0 + beta_age*age + beta_drug*(trt==\"drug\")\np = 1/(1 + np.exp(-lp))\nevent = np.random.binomial(1, p, n)\n\ndf = pd.DataFrame({\"event\": event, \"treatment\": trt, \"age\": age})\n\nm = smf.logit(\"event ~ C(treatment) + age\", data=df).fit(disp=False)\nprint(m.summary())\n\n# ORs\nparams = m.params\nprint(\"\\nOdds Ratios:\")\nprint(np.exp(params))\n</code></pre>"},{"location":"Regression/5-categorical-predictors/#4-practical-tips","title":"4. Practical tips","text":"<ul> <li>Always state the reference group in reporting</li> <li>Make reference clinically meaningful (e.g., placebo, never-smoker)</li> <li>For ordered categories (mild/moderate/severe), consider trend tests or treat as ordinal</li> </ul>"},{"location":"Regression/5-categorical-predictors/#exercises","title":"Exercises","text":"Click to try  1. Change reference group to \"high_dose\" and re-interpret coefficients.   2. Add a 4-level smoking status and fit with adjustment for age and sex.   3. Fit the same model but treat categories as numeric codes and explain why it\u2019s risky."},{"location":"Regression/6-interactions-effect-modification/","title":"Interactions (Effect Modification)","text":"<p>In biostat, we often ask: - Does treatment work differently by sex? - Does exposure effect differ by age group? - Do comorbidities modify risk?</p> <p>This is effect modification \u2192 modeled with interactions.</p>"},{"location":"Regression/6-interactions-effect-modification/#1-concept","title":"1. Concept","text":"<p>Model with interaction: $$ Y = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\beta_3 (X \\times Z) + \\varepsilon $$</p> <p>Interpretation: - When \\(Z=0\\), slope of \\(X\\) is \\(\\beta_1\\) - When \\(Z=1\\), slope of \\(X\\) is \\(\\beta_1 + \\beta_3\\)</p>"},{"location":"Regression/6-interactions-effect-modification/#2-interactive-treatment-effect-differs-by-sex-linear-regression","title":"2. Interactive: treatment effect differs by sex (linear regression)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\nnp.random.seed(12)\nn = 500\n\nsex = np.random.binomial(1, 0.5, n)  # 0=female, 1=male\ntrt = np.random.binomial(1, 0.5, n)  # 0=control, 1=drug\n\n# True mean outcome (e.g., SBP reduction; more negative = better)\n# Drug works better in males:\nbase = -2\ntrt_effect_female = -3\ntrt_effect_male = -7\n\neffect = np.where(sex == 0, trt_effect_female, trt_effect_male)\ny = base + trt*effect + np.random.normal(0, 4, n)\n\ndf = pd.DataFrame({\"y\": y, \"trt\": trt, \"sex\": sex})\n\nm0 = smf.ols(\"y ~ trt + sex\", data=df).fit()\nm1 = smf.ols(\"y ~ trt * sex\", data=df).fit()  # includes interaction\n\nprint(\"No interaction:\\n\", m0.params, \"\\n\")\nprint(\"With interaction:\\n\", m1.params)\nprint(\"\\nFull summary:\\n\", m1.summary())\n</code></pre> <p>Interpret: - <code>trt</code> = treatment effect when sex=0 - <code>trt:sex</code> = difference in treatment effect between sex=1 vs sex=0</p>"},{"location":"Regression/6-interactions-effect-modification/#3-visualizing-interaction","title":"3. Visualizing interaction","text":"<p>Python</p> <pre><code>import numpy as np\n\n# Predicted means by group:\nb = m1.params\n# y = b0 + b1*trt + b2*sex + b3*(trt*sex)\ndef pred(trt, sex):\n    return b[\"Intercept\"] + b[\"trt\"]*trt + b[\"sex\"]*sex + b[\"trt:sex\"]*trt*sex\n\nprint(\"Female control:\", round(pred(0,0), 3))\nprint(\"Female drug:   \", round(pred(1,0), 3))\nprint(\"Male control:  \", round(pred(0,1), 3))\nprint(\"Male drug:     \", round(pred(1,1), 3))\n</code></pre>"},{"location":"Regression/6-interactions-effect-modification/#4-logistic-regression-interactions-or-depends-on-z","title":"4. Logistic regression interactions (OR depends on Z)","text":"<p>Logistic model: $$ \\log\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1 X+\\beta_2 Z+\\beta_3 XZ $$</p> <p>The OR for \\(X\\) is: - when \\(Z=0\\): \\(\\exp(\\beta_1)\\) - when \\(Z=1\\): \\(\\exp(\\beta_1 + \\beta_3)\\)</p>"},{"location":"Regression/6-interactions-effect-modification/#exercises","title":"Exercises","text":"Click to try  1. Reduce interaction strength by changing trt_effect_male closer to trt_effect_female.   2. Add age as an additional confounder and see if interaction remains.   3. Fit a logistic interaction: make event probabilities differ by treatment-by-sex."},{"location":"Regression/7-nonlinearity-splines/","title":"Nonlinearity &amp; Splines","text":"<p>Many biological relationships are not linear: - dose-response curves - risk vs age - biomarkers with thresholds</p> <p>Linear regression can mislead if the true pattern is curved.</p>"},{"location":"Regression/7-nonlinearity-splines/#1-detecting-nonlinearity","title":"1. Detecting nonlinearity","text":"<p>Signs: - residuals show curves vs fitted - scatterplot suggests curvature - strong model misspecification</p>"},{"location":"Regression/7-nonlinearity-splines/#2-polynomial-terms-simple-but-can-be-unstable","title":"2. Polynomial terms (simple but can be unstable)","text":"<p>Example: $$ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\varepsilon $$</p>"},{"location":"Regression/7-nonlinearity-splines/#3-splines-preferred","title":"3. Splines (preferred)","text":"<p>Splines allow smooth, flexible curves without forcing a global polynomial.</p> <p>A common option: natural cubic splines.</p>"},{"location":"Regression/7-nonlinearity-splines/#4-interactive-linear-vs-polynomial-vs-spline-fit","title":"4. Interactive: linear vs polynomial vs spline fit","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport statsmodels.formula.api as smf\nfrom patsy import dmatrix\n\nnp.random.seed(21)\nn = 250\nage = np.random.uniform(20, 80, n)\n\n# True nonlinear relationship (risk-like curve)\ny = 120 + 0.4*age + 0.03*(age-50)**2 + np.random.normal(0, 8, n)\n\ndf = pd.DataFrame({\"y\": y, \"age\": age})\n\n# Linear model\nm_lin = smf.ols(\"y ~ age\", data=df).fit()\n\n# Quadratic model\nm_quad = smf.ols(\"y ~ age + I(age**2)\", data=df).fit()\n\n# Spline model (natural cubic spline with df=4)\nspline_basis = dmatrix(\"cr(age, df=4)\", data=df, return_type=\"dataframe\")\ndf_s = pd.concat([df, spline_basis], axis=1)\n\ncols = spline_basis.columns.tolist()\nformula = \"y ~ \" + \" + \".join(cols)\nm_spline = smf.ols(formula, data=df_s).fit()\n\n# Plot\nxg = np.linspace(age.min(), age.max(), 300)\npred_lin = m_lin.predict(pd.DataFrame({\"age\": xg}))\npred_quad = m_quad.predict(pd.DataFrame({\"age\": xg}))\n\nxg_df = pd.DataFrame({\"age\": xg})\nxg_spline = dmatrix(\"cr(age, df=4)\", data=xg_df, return_type=\"dataframe\")\nxg_s = pd.concat([xg_df, xg_spline], axis=1)\npred_spline = m_spline.predict(xg_s)\n\nplt.scatter(age, y)\nplt.plot(xg, pred_lin, label=\"Linear\")\nplt.plot(xg, pred_quad, label=\"Quadratic\")\nplt.plot(xg, pred_spline, label=\"Spline (df=4)\")\nplt.title(\"Comparing Linear vs Polynomial vs Spline\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Outcome\")\nplt.legend()\nplt.show()\n\nprint(\"R^2 linear:\", round(m_lin.rsquared, 3))\nprint(\"R^2 quad:  \", round(m_quad.rsquared, 3))\nprint(\"R^2 spline:\", round(m_spline.rsquared, 3))\n</code></pre> <p>Try: - Change the true curve strength: the <code>0.03*(age-50)**2</code> term - Change spline flexibility: <code>df=3</code> vs <code>df=6</code></p>"},{"location":"Regression/7-nonlinearity-splines/#5-logistic-regression-splines","title":"5. Logistic regression + splines","text":"<p>Risk vs age is rarely linear in log-odds. Splines are standard in clinical prediction modeling.</p>"},{"location":"Regression/7-nonlinearity-splines/#exercises","title":"Exercises","text":"Click to try  1. Fit linear model only and inspect residual patterns.   2. Increase spline"},{"location":"Regression/8-collinearity-confounding-workflow/","title":"Collinearity, Confounding, and Practical Modeling Workflow","text":"<p>In biostat regression, the goal is often causal-ish interpretation (even if imperfect). So we must think about: - confounding (bias) - collinearity (unstable estimates) - model building strategy</p>"},{"location":"Regression/8-collinearity-confounding-workflow/#1-confounding-bias-in-estimated-association","title":"1. Confounding (bias in estimated association)","text":"<p>A confounder: - is associated with exposure \\(X\\) - independently affects outcome \\(Y\\) - is not on the causal pathway</p> <p>Example: - Exposure: smoking - Outcome: lung function - Confounder: age</p>"},{"location":"Regression/8-collinearity-confounding-workflow/#2-collinearity-big-se-unstable-coefficients","title":"2. Collinearity (big SE, unstable coefficients)","text":"<p>When predictors are highly correlated: - coefficients may flip sign - SE inflate - p-values become misleading</p>"},{"location":"Regression/8-collinearity-confounding-workflow/#3-interactive-build-collinearity-and-watch-se-explode","title":"3. Interactive: build collinearity and watch SE explode","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\nnp.random.seed(30)\nn = 400\n\nage = np.random.uniform(20, 80, n)\n\n# Two highly correlated predictors:\nbmi = 25 + 0.08*(age-50) + np.random.normal(0, 2, n)\nwaist = 0.9*bmi + np.random.normal(0, 0.5, n)  # very correlated with BMI\n\n# Outcome depends on BMI, not waist (truth)\ny = 100 + 0.7*age + 1.2*bmi + np.random.normal(0, 10, n)\n\ndf = pd.DataFrame({\"y\": y, \"age\": age, \"bmi\": bmi, \"waist\": waist})\n\nm1 = sm.OLS(df[\"y\"], sm.add_constant(df[[\"age\", \"bmi\"]])).fit()\nm2 = sm.OLS(df[\"y\"], sm.add_constant(df[[\"age\", \"bmi\", \"waist\"]])).fit()\n\nprint(\"Model without waist:\\n\", m1.summary(), \"\\n\")\nprint(\"Model with waist (collinearity):\\n\", m2.summary())\n</code></pre> <p>Watch: - BMI coefficient and SE change when waist enters - waist may look \u201csignificant\u201d or BMI may lose significance due to instability</p>"},{"location":"Regression/8-collinearity-confounding-workflow/#4-vif-variance-inflation-factor","title":"4. VIF (Variance Inflation Factor)","text":"<p>Rule of thumb: - VIF &gt; 5 (or 10) indicates problematic collinearity</p> <p>Python</p> <pre><code>from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX = sm.add_constant(df[[\"age\", \"bmi\", \"waist\"]]).values\nvifs = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\nprint([\"const\", \"age\", \"bmi\", \"waist\"])\nprint(vifs)\n</code></pre>"},{"location":"Regression/8-collinearity-confounding-workflow/#5-practical-workflow","title":"5. Practical workflow","text":"<ol> <li>Plot data (relationships + missingness patterns)</li> <li>Decide estimand: prediction vs association vs causal interpretation</li> <li>Pre-specify covariates using subject-matter knowledge</li> <li>Fit baseline model</li> <li>Check diagnostics and stability (VIF, influence)</li> <li>Sensitivity analyses (remove influential points, alternative coding, nonlinear terms)</li> <li>Report effect sizes with CI, not just p-values</li> </ol>"},{"location":"Regression/8-collinearity-confounding-workflow/#exercises","title":"Exercises","text":"Click to try  1. Reduce correlation between waist and BMI by changing `waist = 0.5*bmi + ...`.   2. Add a strong confounder and show bias when it\u2019s omitted.   3. Use regularization (next file) to stabilize correlated predictors."},{"location":"Regression/9-model-selection-regularization/","title":"Model Selection &amp; Regularization (Ridge / LASSO)","text":"<p>When you have many predictors: - clinical + lab + genetic variables - high-dimensional EHR features</p> <p>You risk overfitting and unstable estimates.</p> <p>Regularization helps: - better prediction performance - stability under collinearity</p>"},{"location":"Regression/9-model-selection-regularization/#1-the-idea","title":"1. The idea","text":"<p>For linear regression: - Ridge shrinks coefficients toward 0 (keeps all predictors) - LASSO can set some coefficients exactly to 0 (feature selection)</p> <p>For logistic regression: - same ideas using penalized likelihood</p>"},{"location":"Regression/9-model-selection-regularization/#2-interactive-compare-ols-vs-ridge-vs-lasso-prediction","title":"2. Interactive: compare OLS vs Ridge vs LASSO (prediction)","text":"<p>Python</p> <pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import mean_squared_error\n\nnp.random.seed(101)\n\nn = 600\np = 25\n\nX = np.random.normal(0, 1, size=(n, p))\n\n# True model uses only a few predictors\ntrue_beta = np.zeros(p)\ntrue_beta[[0, 3, 7, 10]] = [3.0, -2.0, 1.5, 2.2]\ny = X @ true_beta + np.random.normal(0, 3, size=n)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodels = {\n    \"OLS\": Pipeline([(\"sc\", StandardScaler()), (\"m\", LinearRegression())]),\n    \"Ridge(alpha=5)\": Pipeline([(\"sc\", StandardScaler()), (\"m\", Ridge(alpha=5))]),\n    \"Lasso(alpha=0.1)\": Pipeline([(\"sc\", StandardScaler()), (\"m\", Lasso(alpha=0.1))]),\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    rmse = mean_squared_error(y_test, pred, squared=False)\n    print(name, \"RMSE:\", round(rmse, 3))\n\n# Show which coefficients LASSO kept\nlasso = models[\"Lasso(alpha=0.1)\"].named_steps[\"m\"]\ncoef = lasso.coef_\nkept = np.where(np.abs(coef) &gt; 1e-6)[0]\nprint(\"\\nLASSO kept predictors:\", kept)\n</code></pre> <p>Try: - Increase noise SD (currently <code>3</code>) \u2192 selection gets harder - Increase p to 100 and see regularization become more helpful - Change LASSO alpha to 0.05 or 0.2</p>"},{"location":"Regression/9-model-selection-regularization/#3-regularized-logistic-regression-binary-outcomes","title":"3. Regularized Logistic Regression (binary outcomes)","text":"<p>Python</p> <pre><code>import numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nnp.random.seed(202)\n\nn = 1200\np = 30\nX = np.random.normal(0, 1, size=(n, p))\n\ntrue_beta = np.zeros(p)\ntrue_beta[[1, 4, 9]] = [1.0, -1.2, 0.8]\n\nlp = X @ true_beta - 0.3\nprob = 1/(1 + np.exp(-lp))\ny = np.random.binomial(1, prob, size=n)\n\nXtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=1)\n\n# L2 penalty (ridge-like)\nclf = Pipeline([\n    (\"sc\", StandardScaler()),\n    (\"m\", LogisticRegression(penalty=\"l2\", C=1.0, max_iter=2000))\n])\n\nclf.fit(Xtr, ytr)\npred = clf.predict_proba(Xte)[:, 1]\nprint(\"AUC:\", round(roc_auc_score(yte, pred), 3))\n</code></pre> <p>Note: - Penalization is common in risk prediction models - For causal interpretation, regularization can complicate inference (needs careful reporting)</p>"},{"location":"Regression/9-model-selection-regularization/#exercises","title":"Exercises","text":"Click to try  1. Increase p to 200 and compare OLS vs ridge/lasso RMSE.   2. Make predictors correlated and see ridge stabilize performance.   3. In logistic simulation, change baseline event rate by shifting intercept (-0.3)."},{"location":"Reproducible_Research/","title":"Reproducible Research","text":"<p>I am currently working on this module. Thankyou!!!</p>"},{"location":"Survival_Analysis/","title":"Survival Analysis","text":"<p>Survival analysis is the set of statistical tools used to study time-to-event outcomes\u2014for example, time to death, relapse, hospital readmission, device failure, or recovery. What makes survival data special is that:</p> <ul> <li>Not everyone experiences the event during follow-up (they are censored).</li> <li>Risk changes over time and we care about the entire trajectory, not just a final outcome.</li> <li>We often want both descriptive curves (Kaplan\u2013Meier) and adjusted effect estimates (Cox regression).</li> <li>Real clinical data frequently includes complexities like time-dependent treatments, competing risks, and recurrent events.</li> </ul> <p>This section is designed for biostatistics and biomedical research, with hands-on examples in R and Python and a clear focus on practical interpretation.</p>"},{"location":"Survival_Analysis/#what-you-will-learn","title":"What you will learn","text":"<p>By the end of this module, you will be able to:</p> <ul> <li>Explain censoring, risk sets, and why standard regression fails for time-to-event outcomes  </li> <li>Construct and interpret Kaplan\u2013Meier curves with confidence intervals and median survival  </li> <li>Compare groups using the log-rank test </li> <li>Fit and interpret Cox proportional hazards models (simple + multivariable)  </li> <li>Check assumptions using Schoenfeld residuals and other diagnostics  </li> <li>Handle time-dependent covariates correctly (avoid immortal time bias)  </li> <li>Fit and interpret parametric survival models (Weibull, log-normal, AFT)  </li> <li>Analyze competing risks using CIF and Fine\u2013Gray models  </li> <li>Account for clustering using frailty models and robust standard errors  </li> <li>Model recurrent events (Andersen\u2013Gill, PWP)  </li> <li>Produce publication-quality plots and tables</li> </ul>"},{"location":"Survival_Analysis/#who-this-module-is-for","title":"Who this module is for","text":"<p>This module is ideal for:</p> <ul> <li>Students learning biostatistics / epidemiology</li> <li>Researchers analyzing clinical or public health time-to-event data</li> <li>Anyone reading medical papers and wanting to understand survival results properly</li> </ul> <p>You do not need to be an expert in probability, but you should be comfortable with: - basic regression ideas - interpreting coefficients and confidence intervals - working with simple datasets in Python or R</p>"},{"location":"Survival_Analysis/#recommended-tools-r-python","title":"Recommended tools (R + Python)","text":"<p>You can follow the entire module using either language.</p>"},{"location":"Survival_Analysis/#r-packages","title":"R packages","text":"<ul> <li><code>survival</code> (core survival modeling)</li> <li><code>survminer</code> (best KM plots + risk tables)</li> <li><code>cmprsk</code> (competing risks + Fine\u2013Gray)</li> <li><code>flexsurv</code> (parametric models)</li> <li><code>riskRegression</code> (advanced competing risk prediction)</li> </ul>"},{"location":"Survival_Analysis/#python-packages","title":"Python packages","text":"<ul> <li><code>lifelines</code> (KM, Cox, time-varying Cox, parametric models)</li> <li><code>pandas</code>, <code>numpy</code>, <code>matplotlib</code> (data + visualization)</li> </ul>"},{"location":"Survival_Analysis/#module-roadmap","title":"Module roadmap","text":"<p>Below is the recommended learning path. Each page includes:</p> <ul> <li>strong conceptual explanation</li> <li>worked examples</li> <li>interactive code in both R and Python</li> <li>interpretation in biostatistical language</li> </ul>"},{"location":"Survival_Analysis/#foundations","title":"Foundations","text":"<ol> <li>Why Survival Analysis? (what makes time-to-event special)  </li> <li>Censoring and Follow-up (right censoring, informative censoring)  </li> <li>urvival and Hazard Functions (S(t), h(t), H(t), intuition)  </li> <li>Risk Sets and Event Times (the engine behind KM + Cox)</li> </ol>"},{"location":"Survival_Analysis/#kaplanmeier-hypothesis-testing","title":"Kaplan\u2013Meier + Hypothesis Testing","text":"<ol> <li>Kaplan\u2013Meier Estimator (step-by-step, manual + software)  </li> <li>KM Confidence Intervals + Median Survival </li> <li>Log-rank Test (observed vs expected events)</li> </ol>"},{"location":"Survival_Analysis/#regression-modeling-core","title":"Regression modeling (core)","text":"<ol> <li>Cox Proportional Hazards Model (HR interpretation, partial likelihood intuition)  </li> <li>Cox Diagnostics (PH checks, Schoenfeld residuals, functional form, influence)  </li> <li>Time-dependent Covariates (start\u2013stop format, avoid immortal time bias)</li> </ol>"},{"location":"Survival_Analysis/#beyond-cox","title":"Beyond Cox","text":"<ol> <li>Parametric Survival Models (Weibull, log-normal, AFT; AIC + overlays)  </li> <li>Competing Risks (CIF, cause-specific Cox, Fine\u2013Gray)  </li> <li>Frailty Models (clustering + unobserved heterogeneity)  </li> <li>Recurrent Events (Andersen\u2013Gill, PWP total-time/gap-time)</li> </ol>"},{"location":"Survival_Analysis/#putting-it-all-together","title":"Putting it all together","text":"<ol> <li>Reporting + Publication-Quality Plots/Tables (KM with risk table, Cox tables, Methods writing)</li> </ol>"},{"location":"Survival_Analysis/#a-note-on-interpretation","title":"A note on interpretation","text":"<p>In biomedical research, survival analysis is not just about \u201cstatistics\u201d\u2014it is about answering meaningful questions:</p> <ul> <li>How quickly do events occur?</li> <li>Does a treatment reduce risk?</li> <li>How do patient factors change prognosis?</li> <li>What is the absolute probability of an outcome by a clinically meaningful time?</li> <li>What biases (immortal time, competing risks) could distort conclusions?</li> </ul> <p>This module emphasizes interpretability, valid assumptions, and realistic workflows.</p>"},{"location":"Survival_Analysis/01-why-survival/","title":"Why Survival Analysis?","text":"<p>Survival analysis is the branch of statistics used when your outcome is time until an event happens and some subjects do not experience the event during follow-up (they are censored).</p> <p>In biostatistics, this appears constantly:</p> <ul> <li>Clinical trials: time to death, relapse, progression, adverse event</li> <li>Epidemiology: time to infection, disease onset, hospitalization</li> <li>Health services: time to readmission, ICU discharge</li> <li>Devices / reliability: time to implant failure</li> </ul> <p>What makes survival analysis different from ordinary regression is that it uses both: 1) the event indicator (did the event happen?), and 2) the follow-up time (when did it happen, or how long did we observe without it happening?).</p>"},{"location":"Survival_Analysis/01-why-survival/#1-the-survival-data-mindset","title":"1. The survival-data mindset","text":"<p>A survival study is like watching patients over time:</p> <ul> <li>Some have the event (e.g., death) during the study \u2192 we observe their event time.</li> <li>Some do not have the event before the study ends or they are lost \u2192 we only know they survived up to their last contact.</li> </ul> <p>This \u201cpartial information\u201d is not missing data. It is valid information that must be used correctly.</p>"},{"location":"Survival_Analysis/01-why-survival/#2-what-counts-as-an-event","title":"2. What counts as an \u201cevent\u201d?","text":"<p>An event is the endpoint you care about, defined precisely.</p> <p>Examples: - Death - Relapse - Hospital readmission - Infection - Device failure</p> <p>Your event must be unambiguous: - What exactly qualifies as relapse? - Is death from any cause counted, or only disease-specific death? - If someone has two readmissions, is it the first only (time-to-first-event) or recurrent events?</p> <p>(We cover competing risks and recurrent events later.)</p>"},{"location":"Survival_Analysis/01-why-survival/#3-what-is-censoring-and-why-is-it-normal","title":"3. What is censoring and why is it normal?","text":""},{"location":"Survival_Analysis/01-why-survival/#31-right-censoring-most-common","title":"3.1 Right censoring (most common)","text":"<p>A subject is right-censored if the event has not occurred by the last time we observe them.</p> <p>Common reasons: - Administrative censoring: study ends while subject is event-free - Lost to follow-up: subject stops coming, moves away, etc. - Withdrawal: subject leaves the study</p>"},{"location":"Survival_Analysis/01-why-survival/#32-what-censoring-means","title":"3.2 What censoring means","text":"<p>If a subject is censored at time 3 years, it means:</p> <p>They survived at least 3 years, but we do not know what happened after.</p> <p>This is useful information.</p>"},{"location":"Survival_Analysis/01-why-survival/#33-a-key-assumption-often-stated-in-papers","title":"3.3 A key assumption (often stated in papers)","text":"<p>Most standard survival methods assume non-informative censoring:</p> <p>Given the covariates in the model, censoring is independent of the event process.</p> <p>If sicker patients are more likely to drop out (informative censoring), naive survival analysis can be biased.</p>"},{"location":"Survival_Analysis/01-why-survival/#4-why-not-just-use-logistic-regression","title":"4. Why not just use logistic regression?","text":"<p>A common approach is to pick a time horizon (say 5 years) and define:</p> <ul> <li>Event by 5 years: yes/no</li> </ul> <p>Then use logistic regression.</p>"},{"location":"Survival_Analysis/01-why-survival/#41-logistic-regression-loses-timing","title":"4.1 Logistic regression loses timing","text":"<p>Consider two patients:</p> <ul> <li>Patient A dies at 1 month</li> <li>Patient B dies at 59 months</li> <li>Both are \u201cdead by 5 years\u201d</li> </ul> <p>Logistic regression treats them the same, but clinically they are very different.</p> <p>Survival analysis uses the full timing information.</p>"},{"location":"Survival_Analysis/01-why-survival/#42-logistic-regression-struggles-with-unequal-follow-up","title":"4.2 Logistic regression struggles with unequal follow-up","text":"<p>Suppose the study is 5 years, but a patient is only followed for 2 years and is alive at last contact.</p> <p>How do you label them for \u201cdead by 5 years\u201d?</p> <ul> <li>Exclude them \u2192 wastes data</li> <li>Label them \u201calive by 5 years\u201d \u2192 wrong (we don\u2019t know)</li> <li>Impute \u2192 adds strong assumptions</li> </ul> <p>Survival analysis handles this naturally through censoring.</p>"},{"location":"Survival_Analysis/01-why-survival/#5-why-not-compare-mean-time-to-event","title":"5. Why not compare mean time-to-event?","text":"<p>Another naive approach is to compare average survival times between groups.</p> <p>Problem: - Censored times are not true event times. - The mean becomes biased unless censoring is handled explicitly.</p> <p>Survival analysis methods are designed to incorporate censored follow-up properly.</p>"},{"location":"Survival_Analysis/01-why-survival/#6-what-survival-analysis-gives-you-biostat-deliverables","title":"6. What survival analysis gives you (biostat deliverables)","text":"<p>Survival analysis lets you estimate and report:</p>"},{"location":"Survival_Analysis/01-why-survival/#61-kaplanmeier-survival-curve","title":"6.1 Kaplan\u2013Meier survival curve","text":"<p>A nonparametric estimate of survival probability over time: - 1-year survival - 5-year survival - median survival - confidence intervals - tick marks for censoring</p>"},{"location":"Survival_Analysis/01-why-survival/#62-hypothesis-testing-log-rank-test","title":"6.2 Hypothesis testing: log-rank test","text":"<p>Compares entire survival curves between groups.</p>"},{"location":"Survival_Analysis/01-why-survival/#63-regression-modeling-cox-proportional-hazards","title":"6.3 Regression modeling: Cox proportional hazards","text":"<p>Estimates effects of predictors (age, treatment, biomarkers) on the hazard via hazard ratios.</p>"},{"location":"Survival_Analysis/01-why-survival/#64-extensions-for-real-medical-data","title":"6.4 Extensions for real medical data","text":"<ul> <li>Time-dependent covariates (treatment switching, biomarkers over time)</li> <li>Parametric models (Weibull, log-normal for extrapolation)</li> <li>Competing risks (death prevents relapse)</li> <li>Frailty (hospital/site clustering)</li> <li>Recurrent events (multiple infections/hospitalizations)</li> </ul>"},{"location":"Survival_Analysis/01-why-survival/#7-a-clear-visual-intuition","title":"7. A clear visual intuition","text":""},{"location":"Survival_Analysis/01-why-survival/#71-timeline-event-vs-censoring","title":"7.1 Timeline: event vs censoring","text":"<p>Here\u2019s the conceptual picture:</p> <ul> <li>\u201cX\u201d means event occurs</li> <li>\u201c|\u201d means censored</li> </ul> <pre><code>Patient 1: 0 ----------- X\nPatient 2: 0 ------------------ |\nPatient 3: 0 ----- X\nPatient 4: 0 ---------- |\n</code></pre> <p>Survival analysis uses all the information from each line.</p>"},{"location":"Survival_Analysis/01-why-survival/#72-diagram-mermaid","title":"7.2 Diagram (Mermaid)","text":"<pre><code>flowchart LR\nA[Start follow-up] --&gt; B[Event occurs]\nA --&gt; C[Censored: study ends]\nA --&gt; D[Censored: lost to follow-up]</code></pre>"},{"location":"Survival_Analysis/01-why-survival/#8-the-survival-data-structure-what-you-store","title":"8. The survival data structure (what you store)","text":"<p>A minimal survival dataset has:</p> <ul> <li><code>time</code>: follow-up time until event or censoring</li> <li><code>event</code>: 1 if event, 0 if censored</li> <li>plus predictors (age, sex, treatment, biomarker, etc.)</li> </ul> <p>Example:</p> id time event age trt 1 4.2 1 63 1 2 7.9 0 55 0 3 1.3 1 71 1"},{"location":"Survival_Analysis/01-why-survival/#9-simulation-build-survival-data-python-r","title":"9. Simulation: build survival data (Python + R)","text":"<p>This simulation shows how survival data are created from: - true event time \\(T\\) - censoring time \\(C\\) - observed time \\(Y = \\min(T, C)\\) - event indicator \\(\\delta = I(T \\le C)\\)</p>"},{"location":"Survival_Analysis/01-why-survival/#91-python-simulation","title":"9.1 Python simulation","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(101)\n\nn = 40\n\n# True event times (e.g., time to relapse)\nT = np.random.exponential(scale=10, size=n)\n\n# Censoring times (e.g., study end, dropout)\nC = np.random.uniform(2, 15, size=n)\n\n# Observed survival data\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\n    \"true_event_time_T\": T,\n    \"censor_time_C\": C,\n    \"observed_time\": time,\n    \"event\": event\n}).sort_values(\"observed_time\")\n\ndf.head(12)\n</code></pre> <p>What to look for - <code>event = 1</code> means you truly observed the event time. - <code>event = 0</code> means you only observed follow-up up to censoring time.</p> <p>Try changing censoring intensity: - More censoring: <code>C = np.random.uniform(2, 8, size=n)</code> - Less censoring: <code>C = np.random.uniform(2, 25, size=n)</code></p>"},{"location":"Survival_Analysis/01-why-survival/#92-r-simulation","title":"9.2 R simulation","text":"<p>R</p> <pre><code>set.seed(101)\n\nn &lt;- 40\n\n# True event times\nT &lt;- rexp(n, rate = 1/10)   # mean = 10\n\n# Censoring times\nC &lt;- runif(n, min = 2, max = 15)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(\n  true_event_time_T = T,\n  censor_time_C = C,\n  observed_time = time,\n  event = event\n)\n\ndf &lt;- df[order(df$observed_time), ]\nhead(df, 12)\n</code></pre> <p>Try - More censoring: <code>C &lt;- runif(n, 2, 8)</code> - Less censoring: <code>C &lt;- runif(n, 2, 25)</code></p>"},{"location":"Survival_Analysis/01-why-survival/#10-a-short-why-survival-analysis-example-clinical-reasoning","title":"10. A short \u201cwhy survival analysis\u201d example (clinical reasoning)","text":"<p>Imagine a cancer study:</p> <ul> <li>Some patients relapse early (month 3)</li> <li>Some relapse later (month 30)</li> <li>Some never relapse during the study (censored)</li> </ul> <p>A model that only uses \u201crelapse yes/no\u201d at a cutoff: - ignores early vs late relapse - mishandles different follow-up lengths</p> <p>Survival analysis uses: - exact timing when observed - partial follow-up when censored - and produces clinically interpretable curves and hazard ratios</p>"},{"location":"Survival_Analysis/01-why-survival/#11-key-takeaway","title":"11. Key takeaway","text":"<p>Use survival analysis when: - The outcome is time-to-event, and/or - There is censoring, and/or - Follow-up times vary across participants.</p> <p>Survival analysis is not just \u201canother model.\u201d It is the correct framework whenever time and censoring are part of the outcome.</p>"},{"location":"Survival_Analysis/01-why-survival/#12-quick-self-check-exercises","title":"12. Quick self-check exercises","text":"Click to try  1. Give two reasons logistic regression is not ideal for time-to-event data.   2. Explain censoring in one sentence, in plain language.   3. In the simulation, increase censoring and compute the proportion censored. What happens to information?   4. Give 3 biostat studies where the event is not death."},{"location":"Survival_Analysis/02-time-event-censoring/","title":"Time, Event, and Censoring (Survival Data Foundations)","text":"<p>This chapter builds the core foundations of survival analysis:</p> <ol> <li>Time \u2014 what exactly are we measuring?</li> <li>Event \u2014 what outcome ends follow-up?</li> <li>Censoring \u2014 why follow-up ends without the event</li> </ol> <p>If these three are not defined clearly, everything else (KM, Cox, log-rank) becomes wrong or misleading.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#1-what-is-time-in-survival-analysis","title":"1. What is \u201ctime\u201d in survival analysis?","text":""},{"location":"Survival_Analysis/02-time-event-censoring/#11-definition","title":"1.1 Definition","text":"<p>In survival analysis, time is:</p> <p>the duration from a clearly defined starting point (\u201ctime zero\u201d) until an event or censoring.</p> <p>We always measure time relative to a time origin.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#12-common-choices-of-time-zero-in-biostatistics","title":"1.2 Common choices of time zero in biostatistics","text":"Study type Time zero examples Clinical trial randomization date, treatment start Oncology cohort diagnosis date, surgery date Infection study enrollment date, discharge date Hospital study admission date, discharge date Device study implant date, installation date"},{"location":"Survival_Analysis/02-time-event-censoring/#13-important-rule-define-time-zero-consistently","title":"1.3 Important rule: define time zero consistently","text":"<p>If time zero differs across patients, estimates can become biased.</p> <p>Good: time zero is treatment initiation for everyone Bad: some start at diagnosis, others at surgery, others at drug start</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#2-what-is-an-event","title":"2. What is an event?","text":""},{"location":"Survival_Analysis/02-time-event-censoring/#21-definition","title":"2.1 Definition","text":"<p>An event is the outcome that ends survival follow-up for the endpoint of interest.</p> <p>It must be precisely defined.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#22-examples-of-events","title":"2.2 Examples of events","text":"<ul> <li>Death (all-cause or disease-specific)</li> <li>Relapse / recurrence</li> <li>Hospital readmission</li> <li>ICU admission</li> <li>Infection</li> <li>Recovery (yes, \u201cpositive outcomes\u201d can be events too)</li> <li>Device failure</li> </ul>"},{"location":"Survival_Analysis/02-time-event-censoring/#23-event-coding","title":"2.3 Event coding","text":"<p>We usually encode:</p> \\[ \\delta = \\begin{cases} 1 &amp; \\text{event occurred} \\\\ 0 &amp; \\text{censored} \\end{cases} \\] <p>So your dataset has: - <code>time</code> - <code>event</code></p>"},{"location":"Survival_Analysis/02-time-event-censoring/#3-what-is-censoring","title":"3. What is censoring?","text":""},{"location":"Survival_Analysis/02-time-event-censoring/#31-core-meaning","title":"3.1 Core meaning","text":"<p>Censoring happens when:</p> <p>we stop observing a subject before the event is observed.</p> <p>So we know:  - they survived up to last contact but we do not know what happens after.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#32-right-censoring-most-common","title":"3.2 Right censoring (most common)","text":"<p>Right censoring means the true event time is later than what we observe:</p> \\[ T &gt; C \\] <p>Examples: - study ends - patient withdraws - patient lost to follow-up - patient still alive at last contact</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#33-censoring-is-not-missingness","title":"3.3 Censoring is NOT missingness","text":"<p>Censored observations still contribute valuable information:</p> <p>If censored at time 4 years, we know:</p> <p>event did not occur for at least 4 years.</p> <p>Survival methods are built to use this information correctly.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#4-types-of-censoring-biostat-perspective","title":"4. Types of censoring (biostat perspective)","text":""},{"location":"Survival_Analysis/02-time-event-censoring/#41-right-censoring","title":"4.1 Right censoring","text":"<p>Most typical in clinical studies.</p> <pre><code>Start ----------- |  (event not observed)\n</code></pre>"},{"location":"Survival_Analysis/02-time-event-censoring/#42-left-censoring","title":"4.2 Left censoring","text":"<p>Event occurred before observation begins.</p> <p>Example: - infection occurred before first clinic visit, but we only detect later.</p> <p>Less common in standard time-to-event clinical trials.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#43-interval-censoring","title":"4.3 Interval censoring","text":"<p>Event is known to occur in an interval, but exact time unknown.</p> <p>Example: - patient tested negative at month 3 - positive at month 6 \u2192 infection occurred between 3 and 6 months</p> <p>Interval censoring requires specialized methods.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#5-non-informative-censoring-assumption-very-important","title":"5. Non-informative censoring assumption (very important)","text":"<p>Most KM and Cox analyses assume:</p> <p>Censoring is independent of the event process, given model covariates.</p> <p>If patients with severe disease are more likely to drop out, censoring can be informative and bias results.</p> <p>Practical hints to reduce bias:  - improve follow-up  - record reasons for dropout  - sensitivity analyses</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#6-the-survival-dataset-what-we-actually-observe","title":"6. The survival dataset: what we actually observe","text":"<p>Let: - \\(T\\) = true event time - \\(C\\) = censoring time</p> <p>We observe:</p> \\[ Y = \\min(T, C) \\] \\[ \\delta = \\mathbb{I}(T \\le C) \\] <p>This is the core survival data structure.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#7-risk-set-intuition-preview","title":"7. Risk set intuition (preview)","text":"<p>At any time \\(t\\), the risk set includes people who: - have not had event yet - are still under observation</p> <p>Censored subjects leave the risk set at censor time.</p> <p>This concept powers: - Kaplan\u2013Meier - log-rank test - Cox regression</p> <p>(We cover risk sets fully in a later chapter, but keep this intuition.)</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#8-visual-intuition-timelines","title":"8. Visual intuition: timelines","text":"<p>Legend: - X = event - | = censored</p> <pre><code>Patient 1: 0 -------- X\nPatient 2: 0 -------------- |\nPatient 3: 0 ----- X\nPatient 4: 0 ---------- |\n</code></pre> <p>At time = 6:  - patient 1 already had event  - patient 3 already had event  - patient 2 still at risk (if censor &gt; 6)  - patient 4 maybe censored earlier</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#9-interactive-simulation-building-survival-data-python-r","title":"9. Interactive simulation: building survival data (Python + R)","text":"<p>This section shows exactly how survival data are formed using: - event times - censoring times</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#91-python-simulate-event-censoring","title":"9.1 Python: simulate event + censoring","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\nn = 50\n\n# True event times\nT = np.random.exponential(scale=8, size=n)\n\n# Censoring times\nC = np.random.uniform(2, 12, size=n)\n\n# Observed\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\n    \"true_event_time_T\": T,\n    \"censor_time_C\": C,\n    \"time\": time,\n    \"event\": event\n}).sort_values(\"time\")\n\ndf.head(12)\n</code></pre> <p>Try: - Increase censoring: <code>C = np.random.uniform(2, 6, size=n)</code> - Decrease censoring: <code>C = np.random.uniform(2, 25, size=n)</code></p> <p>Then check censoring proportion:</p> <p>Python</p> <pre><code>censor_prop = 1 - df[\"event\"].mean()\ncensor_prop\n</code></pre>"},{"location":"Survival_Analysis/02-time-event-censoring/#92-r-simulate-event-censoring","title":"9.2 R: simulate event + censoring","text":"<p>R</p> <pre><code>set.seed(42)\n\nn &lt;- 50\n\n# True event times\nT &lt;- rexp(n, rate = 1/8)\n\n# Censoring times\nC &lt;- runif(n, min = 2, max = 12)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(\n  true_event_time_T = T,\n  censor_time_C = C,\n  time = time,\n  event = event\n)\n\ndf &lt;- df[order(df$time), ]\nhead(df, 12)\n</code></pre> <p>Censoring proportion:</p> <p>R</p> <pre><code>1 - mean(df$event)\n</code></pre>"},{"location":"Survival_Analysis/02-time-event-censoring/#10-a-concrete-clinical-example","title":"10. A concrete clinical example","text":"<p>Suppose:  - Study duration = 5 years  - Patient followed 3 years and then lost  - No relapse observed</p> <p>We record:  - time = 3  - event = 0</p> <p>We do NOT record:  - event = \u201cno relapse\u201d</p> <p>Because we don\u2019t know after 3 years.</p> <p>That is the key conceptual difference.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#11-common-mistakes","title":"11. Common mistakes","text":""},{"location":"Survival_Analysis/02-time-event-censoring/#mistake-1-treat-censored-as-event-free","title":"Mistake 1: treat censored as \u201cevent-free\u201d","text":"<p>Fix: censoring means unknown beyond last time.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#mistake-2-use-unequal-time-zero","title":"Mistake 2: use unequal time zero","text":"<p>Fix: define time origin consistently.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#mistake-3-mix-different-event-definitions","title":"Mistake 3: mix different event definitions","text":"<p>Fix: define event precisely and consistently.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#mistake-4-ignore-censoring-assumption","title":"Mistake 4: ignore censoring assumption","text":"<p>Fix: assess dropout reasons, consider sensitivity.</p>"},{"location":"Survival_Analysis/02-time-event-censoring/#12-key-takeaways","title":"12. Key takeaways","text":"<ul> <li>Survival data consists of time and event indicator.</li> <li>Censoring means partial follow-up, not missingness.</li> <li>Right censoring is most common in clinical research.</li> <li>We observe \\(Y=\\min(T,C)\\) and \\(\\delta=I(T\\le C)\\).</li> <li>Correct definitions of time zero and event are critical.</li> </ul>"},{"location":"Survival_Analysis/02-time-event-censoring/#13-exercises","title":"13. Exercises","text":"Click to try  1. Give 3 different valid choices of time zero in clinical studies and explain which is best in a trial.   2. Define right censoring in one sentence.   3. In the simulation, increase censoring and describe how analysis becomes harder.   4. Give a real example of interval censoring in medicine.   5. Explain non-informative censoring assumption in plain language."},{"location":"Survival_Analysis/03-survival-hazard/","title":"Survival Function, Hazard Function, and Their Relationship","text":"<p>This chapter introduces the two most important functions in survival analysis:</p> <ol> <li>Survival function \\(S(t)\\): \u201cHow many survive beyond time \\(t\\)?\u201d</li> <li>Hazard function \\(h(t)\\): \u201cHow risky is it to fail right now, given survival so far?\u201d</li> </ol> <p>Everything you will do later\u2014Kaplan\u2013Meier, log-rank, Cox regression, parametric survival\u2014can be understood through these two concepts.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#1-the-random-variable-t","title":"1. The random variable \\(T\\)","text":"<p>Let \\(T\\) be the true event time for a subject.</p> <ul> <li>\\(T\\) is random because different subjects experience the event at different times.</li> <li>In data, we often observe \\(Y = \\min(T,C)\\) plus an event indicator \\(\\delta\\).</li> </ul> <p>In this chapter, focus on the theoretical object \\(T\\).</p>"},{"location":"Survival_Analysis/03-survival-hazard/#2-survival-function-st","title":"2. Survival function \\(S(t)\\)","text":""},{"location":"Survival_Analysis/03-survival-hazard/#21-definition","title":"2.1 Definition","text":"\\[ S(t) = P(T &gt; t) \\] <p>Interpretation:</p> <p>Probability that the subject survives longer than time \\(t\\).</p>"},{"location":"Survival_Analysis/03-survival-hazard/#22-examples","title":"2.2 Examples","text":"<ul> <li>If \\(S(5)=0.80\\), then ~80% survive beyond time 5.</li> <li>If time unit is years, then 80% survive beyond 5 years.</li> </ul>"},{"location":"Survival_Analysis/03-survival-hazard/#23-properties-of-st","title":"2.3 Properties of \\(S(t)\\)","text":"<ol> <li> <p>Starts at 1: [ S(0)=1 ] (Everyone is alive at time zero)</p> </li> <li> <p>Non-increasing: [ S(t_2)\\le S(t_1)\\quad \\text{if } t_2&gt;t_1 ]</p> </li> <li> <p>Bounded: [ 0 \\le S(t)\\le 1 ]</p> </li> <li> <p>As \\(t\\to\\infty\\), \\(S(t)\\to 0\\) (often, but not always).</p> </li> </ol>"},{"location":"Survival_Analysis/03-survival-hazard/#3-cumulative-distribution-function-ft","title":"3. Cumulative distribution function \\(F(t)\\)","text":"<p>Another way to describe survival time is:</p> \\[ F(t)=P(T\\le t) \\] <p>This is the probability the event happens by time \\(t\\).</p> <p>Relationship:</p> \\[ F(t)=1-S(t) \\] <p>So survival and cumulative incidence are two sides of the same coin (when there is a single event type).</p>"},{"location":"Survival_Analysis/03-survival-hazard/#4-probability-density-and-hazard-intuition","title":"4. Probability density and hazard: intuition","text":"<p>In continuous time, the event does not occur at a single exact time with positive probability, so we often use:</p> <ul> <li>density \\(f(t)\\)</li> <li>hazard \\(h(t)\\)</li> </ul>"},{"location":"Survival_Analysis/03-survival-hazard/#5-hazard-function-ht","title":"5. Hazard function \\(h(t)\\)","text":""},{"location":"Survival_Analysis/03-survival-hazard/#51-definition-formal","title":"5.1 Definition (formal)","text":"\\[ h(t)=\\lim_{\\Delta t \\to 0}\\frac{P(t\\le T&lt;t+\\Delta t\\mid T\\ge t)}{\\Delta t} \\] <p>Interpretation:</p> <p>The instantaneous event rate at time \\(t\\), given survival up to time \\(t\\).</p>"},{"location":"Survival_Analysis/03-survival-hazard/#52-plain-language-interpretation","title":"5.2 Plain-language interpretation","text":"<p>If hazard is high at time \\(t\\):</p> <ul> <li>people who are alive at \\(t\\) are at high risk of failing immediately.</li> </ul> <p>If hazard is low:</p> <ul> <li>risk at that moment is small.</li> </ul>"},{"location":"Survival_Analysis/03-survival-hazard/#53-hazard-is-not-a-probability","title":"5.3 Hazard is NOT a probability","text":"<p>Hazard is a rate, and it can exceed 1 (depending on units).</p> <p>This is a common student confusion.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#6-relationship-between-st-ft-and-ht","title":"6. Relationship between \\(S(t)\\), \\(f(t)\\), and \\(h(t)\\)","text":""},{"location":"Survival_Analysis/03-survival-hazard/#61-density","title":"6.1 Density","text":"\\[ f(t) = \\frac{d}{dt}F(t) = -\\frac{d}{dt}S(t) \\]"},{"location":"Survival_Analysis/03-survival-hazard/#62-hazard-definition-in-terms-of-density-and-survival","title":"6.2 Hazard definition in terms of density and survival","text":"\\[ h(t)=\\frac{f(t)}{S(t)} \\] <p>This formula is extremely useful.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#63-the-cumulative-hazard-ht","title":"6.3 The cumulative hazard \\(H(t)\\)","text":"\\[ H(t)=\\int_0^t h(u)\\,du \\]"},{"location":"Survival_Analysis/03-survival-hazard/#64-the-key-survival-hazard-relationship","title":"6.4 The key survival-hazard relationship","text":"\\[ S(t)=\\exp(-H(t))=\\exp\\left(-\\int_0^t h(u)\\,du\\right) \\] <p>Interpretation:</p> <ul> <li>hazard accumulates over time</li> <li>higher cumulative hazard means lower survival</li> </ul> <p>This is foundational for Cox regression and parametric survival models.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#7-common-hazard-shapes","title":"7. Common hazard shapes","text":""},{"location":"Survival_Analysis/03-survival-hazard/#71-constant-hazard-exponential-model","title":"7.1 Constant hazard (Exponential model)","text":"<p>Examples: random failures (often unrealistic for humans)</p> <pre><code>hazard\n  |\n  |---------\n  |\n  +-------------- time\n</code></pre>"},{"location":"Survival_Analysis/03-survival-hazard/#72-increasing-hazard","title":"7.2 Increasing hazard","text":"<p>Examples: - aging mortality - chronic disease progression</p> <pre><code>hazard\n  |\n  |    /\n  |   /\n  |  /\n  +-------------- time\n</code></pre>"},{"location":"Survival_Analysis/03-survival-hazard/#73-decreasing-hazard","title":"7.3 Decreasing hazard","text":"<p>Examples: - post-surgery early risk then recovery</p> <pre><code>hazard\n  |\n  |\\ \n  | \\\n  |  \\\n  +-------------- time\n</code></pre>"},{"location":"Survival_Analysis/03-survival-hazard/#74-non-monotonic-rises-then-falls","title":"7.4 Non-monotonic (rises then falls)","text":"<p>Examples: - complications peak then decrease - infection risk after surgery</p> <pre><code>hazard\n  |\n  |   /\\\n  |  /  \\\n  | /    \\\n  +-------------- time\n</code></pre>"},{"location":"Survival_Analysis/03-survival-hazard/#8-connecting-hazard-ratios-to-hazards","title":"8. Connecting hazard ratios to hazards","text":"<p>Cox regression models hazard as:</p> \\[ h(t|X)=h_0(t)\\exp(\\beta X) \\] <p>If you compare two subjects with covariates \\(X_1\\) and \\(X_2\\):</p> \\[ \\frac{h(t|X_1)}{h(t|X_2)}=\\exp(\\beta (X_1-X_2)) \\] <p>This ratio is constant in \\(t\\) \u2192 the proportional hazards assumption.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#9-interactive-exploration-survival-from-hazard-python-r","title":"9. Interactive exploration: survival from hazard (Python + R)","text":"<p>We\u2019ll explore how different hazard shapes generate different survival curves.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#91-python-constant-hazard-exponential-survival","title":"9.1 Python: constant hazard \u2192 exponential survival","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0, 20, 400)\n\nlam = 0.15  # constant hazard\nH = lam * t\nS = np.exp(-H)\n\nplt.plot(t, S)\nplt.title(\"Survival curve from constant hazard (Exponential)\")\nplt.xlabel(\"time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre> <p>Try changing: - <code>lam = 0.05</code> (slower drop) - <code>lam = 0.30</code> (faster drop)</p>"},{"location":"Survival_Analysis/03-survival-hazard/#92-r-constant-hazard-exponential-survival","title":"9.2 R: constant hazard \u2192 exponential survival","text":"<p>R</p> <pre><code>t &lt;- seq(0, 20, length.out = 400)\n\nlam &lt;- 0.15\nH &lt;- lam * t\nS &lt;- exp(-H)\n\nplot(t, S, type=\"l\", main=\"Survival from constant hazard (Exponential)\",\n     xlab=\"time\", ylab=\"S(t)\")\n</code></pre> <p>Try: - <code>lam &lt;- 0.05</code> - <code>lam &lt;- 0.30</code></p>"},{"location":"Survival_Analysis/03-survival-hazard/#10-interactive-exploration-weibull-hazard-shapes-python-r","title":"10. Interactive exploration: Weibull hazard shapes (Python + R)","text":"<p>Weibull model is extremely useful because it can represent increasing or decreasing hazards.</p>"},{"location":"Survival_Analysis/03-survival-hazard/#weibull-survival","title":"Weibull survival:","text":"\\[ S(t)=\\exp\\left(-\\left(\\frac{t}{\\lambda}\\right)^k\\right) \\] <ul> <li>\\(k=1\\) \u2192 exponential (constant hazard)</li> <li>\\(k&gt;1\\) \u2192 increasing hazard</li> <li>\\(k&lt;1\\) \u2192 decreasing hazard</li> </ul>"},{"location":"Survival_Analysis/03-survival-hazard/#101-python-weibull-survival-curves-for-different-k","title":"10.1 Python: Weibull survival curves for different \\(k\\)","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0.01, 20, 500)\nlam = 8  # scale\n\nfor k in [0.6, 1.0, 2.0, 3.0]:\n    S = np.exp(- (t/lam)**k )\n    plt.plot(t, S, label=f\"k={k}\")\n\nplt.title(\"Weibull Survival Curves (different hazard shapes)\")\nplt.xlabel(\"time\")\nplt.ylabel(\"S(t)\")\nplt.legend()\nplt.show()\n</code></pre> <p>Observe: - when \\(k&lt;1\\), survival drops quickly early then slows - when \\(k&gt;1\\), survival drops slowly early then faster later</p>"},{"location":"Survival_Analysis/03-survival-hazard/#102-r-weibull-survival-curves-for-different-k","title":"10.2 R: Weibull survival curves for different \\(k\\)","text":"<p>R</p> <pre><code>t &lt;- seq(0.01, 20, length.out = 500)\nlam &lt;- 8\n\nks &lt;- c(0.6, 1.0, 2.0, 3.0)\n\nplot(t, exp(-(t/lam)^ks[1]), type=\"l\",\n     main=\"Weibull Survival Curves (different k)\",\n     xlab=\"time\", ylab=\"S(t)\", ylim=c(0,1))\n\nfor (k in ks[-1]) {\n  lines(t, exp(-(t/lam)^k))\n}\n\nlegend(\"topright\", legend=paste(\"k=\", ks), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/03-survival-hazard/#11-visualizing-hazard-directly-python-r","title":"11. Visualizing hazard directly (Python + R)","text":"<p>For Weibull:</p> \\[ h(t)=\\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1} \\]"},{"location":"Survival_Analysis/03-survival-hazard/#111-python-weibull-hazard-curves","title":"11.1 Python: Weibull hazard curves","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0.01, 20, 500)\nlam = 8\n\nfor k in [0.6, 1.0, 2.0, 3.0]:\n    h = (k/lam) * (t/lam)**(k-1)\n    plt.plot(t, h, label=f\"k={k}\")\n\nplt.title(\"Weibull Hazard Curves\")\nplt.xlabel(\"time\")\nplt.ylabel(\"h(t)\")\nplt.legend()\nplt.show()\n</code></pre> <p>Interpret: - \\(k&lt;1\\): high early hazard, decreasing - \\(k=1\\): constant - \\(k&gt;1\\): increasing</p>"},{"location":"Survival_Analysis/03-survival-hazard/#112-r-weibull-hazard-curves","title":"11.2 R: Weibull hazard curves","text":"<p>R</p> <pre><code>t &lt;- seq(0.01, 20, length.out = 500)\nlam &lt;- 8\nks &lt;- c(0.6, 1.0, 2.0, 3.0)\n\nh_weibull &lt;- function(t, k, lam) (k/lam) * (t/lam)^(k-1)\n\nplot(t, h_weibull(t, ks[1], lam), type=\"l\",\n     main=\"Weibull Hazard Curves\",\n     xlab=\"time\", ylab=\"h(t)\")\n\nfor (k in ks[-1]) {\n  lines(t, h_weibull(t, k, lam))\n}\n\nlegend(\"topleft\", legend=paste(\"k=\", ks), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/03-survival-hazard/#12-practical-interpretation-for-biostatistics","title":"12. Practical interpretation for biostatistics","text":"<p>When you see a survival curve: - it tells you probability of surviving beyond time t - it is easy to interpret clinically</p> <p>When you see a hazard ratio: - it tells you relative instantaneous risk - it is the main output of Cox regression</p> <p>Remember: - Survival is about probability - Hazard is about rate</p>"},{"location":"Survival_Analysis/03-survival-hazard/#13-key-takeaways","title":"13. Key takeaways","text":"<ul> <li>\\(S(t)=P(T&gt;t)\\) is the survival probability beyond time \\(t\\).</li> <li>\\(h(t)\\) is instantaneous risk rate given survival up to time \\(t\\).</li> <li>They are linked by:   [   S(t)=\\exp\\left(-\\int_0^t h(u)\\,du\\right)   ]</li> <li>Different hazard shapes lead to different survival curve shapes.</li> <li>Cox regression is built on modeling hazard and hazard ratios.</li> </ul>"},{"location":"Survival_Analysis/03-survival-hazard/#14-exercises","title":"14. Exercises","text":"Click to try  1. If \\(S(3)=0.9\\), interpret it in plain language.   2. Explain why hazard is not a probability.   3. Which Weibull shape parameter \\(k\\) produces increasing hazard?   4. For Weibull with \\(k&lt;1\\), describe the clinical scenario this could represent.   5. Simulate survival curves for different hazards and describe their differences."},{"location":"Survival_Analysis/04-risk-sets/","title":"Risk Sets and Event Times (The Engine Behind KM, Log-rank, and Cox)","text":"<p>If survival analysis had one \u201cengine\u201d that powers everything, it would be:</p>"},{"location":"Survival_Analysis/04-risk-sets/#risk-sets","title":"Risk Sets","text":"<p>Kaplan\u2013Meier, log-rank tests, and Cox regression all work by repeatedly asking:</p> <p>\u201cAmong the people still at risk right now, who experienced the event?\u201d</p> <p>This chapter makes that idea crystal clear and shows how risk sets are computed in both Python and R.</p>"},{"location":"Survival_Analysis/04-risk-sets/#1-what-is-a-risk-set","title":"1. What is a risk set?","text":""},{"location":"Survival_Analysis/04-risk-sets/#11-definition","title":"1.1 Definition","text":"<p>At an event time \\(t\\), the risk set \\(R(t)\\) is the set of individuals who:</p> <ul> <li>have not had the event before time \\(t\\), AND</li> <li>are still under observation just before \\(t\\) (not censored earlier)</li> </ul> <p>So:</p> \\[ R(t) = \\{ i : Y_i \\ge t \\} \\] <p>(where \\(Y_i\\) is observed follow-up time)</p>"},{"location":"Survival_Analysis/04-risk-sets/#12-plain-language","title":"1.2 Plain language","text":"<p>At time \\(t\\):</p> <p>\u201cWho could possibly experience the event at time \\(t\\)?\u201d</p> <p>Those people are the risk set.</p>"},{"location":"Survival_Analysis/04-risk-sets/#2-events-vs-censoring-how-they-affect-risk-sets","title":"2. Events vs censoring: how they affect risk sets","text":""},{"location":"Survival_Analysis/04-risk-sets/#21-event-at-time-t","title":"2.1 Event at time \\(t\\)","text":"<ul> <li>Counted as event</li> <li>Removed from risk set after that time</li> </ul>"},{"location":"Survival_Analysis/04-risk-sets/#22-censoring-at-time-t","title":"2.2 Censoring at time \\(t\\)","text":"<ul> <li>NOT counted as event</li> <li>Removed from risk set after that time</li> </ul> <p>Key point:</p> <p>Censoring does not cause a drop in survival probability, but it does shrink the risk set, which affects future estimates.</p>"},{"location":"Survival_Analysis/04-risk-sets/#3-a-fully-worked-example","title":"3. A fully worked example","text":"<p>Consider 5 patients:</p> Patient Time Status A 2 Event B 4 Event C 5 Censored D 7 Event E 8 Censored <p>Let\u2019s compute the risk sets at each unique time.</p>"},{"location":"Survival_Analysis/04-risk-sets/#31-timeline-view","title":"3.1 Timeline view","text":"<p>Legend: - X = event - | = censoring</p> <pre><code>A: 0 -- X\nB: 0 ---- X\nC: 0 ----- |\nD: 0 ------- X\nE: 0 -------- |\n</code></pre>"},{"location":"Survival_Analysis/04-risk-sets/#32-risk-sets-step-by-step","title":"3.2 Risk sets step-by-step","text":""},{"location":"Survival_Analysis/04-risk-sets/#just-before-time-2","title":"Just before time 2","text":"<p>Everyone is at risk:</p> \\[ R(2) = \\{A,B,C,D,E\\}, \\quad n_1 = 5 \\] <p>Event occurs (A), so after time 2:</p> \\[ R(2^+) = \\{B,C,D,E\\} \\]"},{"location":"Survival_Analysis/04-risk-sets/#just-before-time-4","title":"Just before time 4","text":"\\[ R(4) = \\{B,C,D,E\\}, \\quad n_2 = 4 \\] <p>Event occurs (B), so after time 4:</p> \\[ R(4^+) = \\{C,D,E\\} \\]"},{"location":"Survival_Analysis/04-risk-sets/#just-before-time-5","title":"Just before time 5","text":"\\[ R(5) = \\{C,D,E\\}, \\quad n_3 = 3 \\] <p>C is censored at 5, so after time 5:</p> \\[ R(5^+) = \\{D,E\\} \\]"},{"location":"Survival_Analysis/04-risk-sets/#just-before-time-7","title":"Just before time 7","text":"\\[ R(7) = \\{D,E\\}, \\quad n_4 = 2 \\] <p>Event occurs (D), so after time 7:</p> \\[ R(7^+) = \\{E\\} \\]"},{"location":"Survival_Analysis/04-risk-sets/#just-before-time-8","title":"Just before time 8","text":"\\[ R(8) = \\{E\\}, \\quad n_5 = 1 \\] <p>E is censored, then risk set becomes empty.</p>"},{"location":"Survival_Analysis/04-risk-sets/#4-why-risk-sets-matter-big-picture","title":"4. Why risk sets matter (big picture)","text":""},{"location":"Survival_Analysis/04-risk-sets/#41-kaplanmeier-uses-risk-sets","title":"4.1 Kaplan\u2013Meier uses risk sets","text":"<p>Kaplan\u2013Meier estimator:</p> \\[ \\hat S(t)=\\prod_{t_j\\le t}\\left(1-\\frac{d_j}{n_j}\\right) \\] <p>Where:  - \\(n_j\\) = size of risk set at event time \\(t_j\\)  - \\(d_j\\) = number of events at that time</p> <p>So the denominator in KM is always:  - the risk set at that time, NOT the original sample size.</p>"},{"location":"Survival_Analysis/04-risk-sets/#42-log-rank-test-uses-risk-sets","title":"4.2 Log-rank test uses risk sets","text":"<p>At each event time, log-rank compares:</p> <ul> <li>observed events vs expected events</li> <li>expected is computed based on risk set proportions</li> </ul>"},{"location":"Survival_Analysis/04-risk-sets/#43-cox-regression-uses-risk-sets","title":"4.3 Cox regression uses risk sets","text":"<p>The Cox partial likelihood at each event time uses:</p> \\[ \\sum_{k \\in R(t_j)}\\exp(\\beta X_k) \\] <p>It literally sums over the risk set.</p> <p>So Cox cannot exist without risk sets.</p>"},{"location":"Survival_Analysis/04-risk-sets/#5-ties-at-event-times","title":"5. Ties at event times","text":"<p>Sometimes multiple events occur at exactly the same recorded time:</p> <ul> <li>3 patients die on day 10</li> </ul> <p>This is called ties.</p> <p>Different tie-handling methods: - Breslow - Efron (common default) - Exact</p> <p>Software handles this automatically, but it\u2019s good to know why output may differ slightly between packages.</p>"},{"location":"Survival_Analysis/04-risk-sets/#6-interactive-calculation-of-risk-sets-python-r","title":"6. Interactive calculation of risk sets (Python + R)","text":"<p>We\u2019ll compute:</p> <ul> <li>number at risk at each unique time</li> <li>number of events</li> <li>number censored</li> </ul> <p>using code.</p>"},{"location":"Survival_Analysis/04-risk-sets/#61-python-risk-set-table","title":"6.1 Python: risk set table","text":"<p>Python</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    \"id\": [\"A\",\"B\",\"C\",\"D\",\"E\"],\n    \"time\": [2,4,5,7,8],\n    \"event\": [1,1,0,1,0]\n}).sort_values(\"time\")\n\nunique_times = df[\"time\"].unique()\n\nprint(\"time | at_risk | events | censored\")\nprint(\"-----------------------------------\")\n\nfor t in unique_times:\n    at_risk = (df[\"time\"] &gt;= t).sum()\n    events = ((df[\"time\"] == t) &amp; (df[\"event\"] == 1)).sum()\n    cens   = ((df[\"time\"] == t) &amp; (df[\"event\"] == 0)).sum()\n    print(f\"{t:&gt;4} | {at_risk:&gt;7} | {events:&gt;6} | {cens:&gt;8}\")\n</code></pre> <p>Interpretation - <code>at_risk</code> is the size of the risk set just before time <code>t</code> - <code>events</code> is number of events at time <code>t</code> - <code>censored</code> is number censored at time <code>t</code></p>"},{"location":"Survival_Analysis/04-risk-sets/#62-r-risk-set-table","title":"6.2 R: risk set table","text":"<p>R</p> <pre><code>df &lt;- data.frame(\n  id = c(\"A\",\"B\",\"C\",\"D\",\"E\"),\n  time = c(2,4,5,7,8),\n  event = c(1,1,0,1,0)\n)\n\ndf &lt;- df[order(df$time), ]\n\nunique_times &lt;- unique(df$time)\n\ncat(\"time | at_risk | events | censored\\n\")\ncat(\"-----------------------------------\\n\")\n\nfor (t in unique_times) {\n  at_risk &lt;- sum(df$time &gt;= t)\n  events  &lt;- sum(df$time == t &amp; df$event == 1)\n  cens    &lt;- sum(df$time == t &amp; df$event == 0)\n  cat(sprintf(\"%4d | %7d | %6d | %8d\\n\", t, at_risk, events, cens))\n}\n</code></pre>"},{"location":"Survival_Analysis/04-risk-sets/#7-visualizing-risk-set-size-over-time-python-r","title":"7. Visualizing risk set size over time (Python + R)","text":"<p>Risk sets shrink over time; this helps build intuition.</p>"},{"location":"Survival_Analysis/04-risk-sets/#71-python-step-plot-of-risk-set-size","title":"7.1 Python: step plot of risk set size","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\ntimes = df[\"time\"].values\nrisk_sizes = [(df[\"time\"] &gt;= t).sum() for t in times]\n\nplt.step(times, risk_sizes, where=\"post\")\nplt.title(\"Risk Set Size Over Time\")\nplt.xlabel(\"time\")\nplt.ylabel(\"number at risk\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/04-risk-sets/#72-r-step-plot-of-risk-set-size","title":"7.2 R: step plot of risk set size","text":"<p>R</p> <pre><code>times &lt;- df$time\nrisk_sizes &lt;- sapply(times, function(t) sum(df$time &gt;= t))\n\nplot(times, risk_sizes, type=\"s\", main=\"Risk Set Size Over Time\",\n     xlab=\"time\", ylab=\"number at risk\")\n</code></pre>"},{"location":"Survival_Analysis/04-risk-sets/#8-clinical-intuition","title":"8. Clinical intuition","text":"<p>At each event time, survival analysis compares:</p> <p>\u201cThe person who failed\u201d vs \u201ceveryone who could have failed at that time.\u201d</p> <p>That comparison group is the risk set.</p> <p>This is why:  - censoring affects denominators  - late estimates are less precise (risk sets small)  - Kaplan\u2013Meier and Cox are fundamentally conditional methods</p>"},{"location":"Survival_Analysis/04-risk-sets/#9-common-mistakes","title":"9. Common mistakes","text":""},{"location":"Survival_Analysis/04-risk-sets/#mistake-1-using-original-n-in-denominator","title":"Mistake 1: using original N in denominator","text":"<p>Fix: always use risk set size.</p>"},{"location":"Survival_Analysis/04-risk-sets/#mistake-2-leaving-censored-people-in-the-risk-set","title":"Mistake 2: leaving censored people in the risk set","text":"<p>Fix: remove them after censoring time.</p>"},{"location":"Survival_Analysis/04-risk-sets/#mistake-3-mis-ordering-events-and-censoring-at-same-time","title":"Mistake 3: mis-ordering events and censoring at same time","text":"<p>Fix: software uses a convention; usually events are counted before censoring at the same time.</p>"},{"location":"Survival_Analysis/04-risk-sets/#10-key-takeaways","title":"10. Key takeaways","text":"<ul> <li>Risk set \\(R(t)\\) = those still event-free and observed at time \\(t\\).</li> <li>KM, log-rank, and Cox all depend on risk sets.</li> <li>Censoring does not count as event, but removes people from future risk sets.</li> <li>As risk sets shrink, estimates become less stable.</li> </ul>"},{"location":"Survival_Analysis/04-risk-sets/#11-exercises","title":"11. Exercises","text":"Click to try  1. For the sample data, write out \\(R(4)\\) explicitly.   2. Explain why censoring affects future KM steps even though it doesn\u2019t cause survival drops.   3. Create a dataset where two events happen at the same time. How do risk sets work then?   4. Simulate 20 subjects with random censoring and compute risk sets at each event time.   5. Explain in plain language why Cox regression is built on risk sets."},{"location":"Survival_Analysis/05-kaplan-meier/","title":"Kaplan\u2013Meier Estimator (KM)","text":"<p>Kaplan\u2013Meier (KM) is the standard nonparametric method to estimate the survival function:</p> \\[ S(t)=P(T&gt;t) \\] <p>KM is the first survival method you should learn because it is:</p> <ul> <li>intuitive</li> <li>clinically interpretable</li> <li>handles censoring correctly</li> <li>the foundation for log-rank tests and Cox models</li> </ul> <p>In most medical papers, KM curves are the first survival result shown.</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#1-what-kaplanmeier-estimates","title":"1. What Kaplan\u2013Meier estimates","text":"<p>KM estimates survival probability over time:</p> \\[ \\hat S(t) \\approx P(\\text{survive beyond } t) \\] <p>Typical reported outputs: - 1-year survival probability - 5-year survival probability - median survival time - survival curves by treatment group</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#2-key-idea-conditional-survival-at-each-event-time","title":"2. Key idea: conditional survival at each event time","text":"<p>KM does NOT compute \u201csurvival at time \\(t\\) directly.\u201d</p> <p>Instead, it breaks survival into steps at each event time:</p> <p>At each event time \\(t_j\\): - \\(n_j\\) = number at risk just before \\(t_j\\) - \\(d_j\\) = number of events at \\(t_j\\)</p> <p>Conditional probability of surviving that step:</p> \\[ P(\\text{survive past } t_j \\mid \\text{alive just before } t_j) = 1 - \\frac{d_j}{n_j} \\] <p>Then multiply across event times:</p> \\[ \\hat S(t) = \\prod_{t_j \\le t}\\left(1-\\frac{d_j}{n_j}\\right) \\] <p>This is called the product-limit estimator.</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#3-how-censoring-affects-km","title":"3. How censoring affects KM","text":"<p>Censoring:  - does not create a drop in \\(\\hat S(t)\\)  - but it reduces the risk set size \\(n_j\\) at later times</p> <p>So censoring changes future steps indirectly.</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#4-km-curve-shape-why-its-a-step-function","title":"4. KM curve shape: why it\u2019s a step function","text":"<p>KM curve:  - starts at 1.0  - drops only at event times  - stays flat between events  - shows censoring as tick marks</p> <p>Sketch:</p> <pre><code>S(t)\n1.0 |---------\n    |        |\n    |        |____\n    |             |___\n    |\n    +-------------------- time\n         event times\n</code></pre>"},{"location":"Survival_Analysis/05-kaplan-meier/#5-example","title":"5. Example","text":"<p>Dataset:</p> Subject time event 1 2 1 2 4 1 3 5 0 4 7 1 5 8 0 <p>Event times are: 2, 4, 7</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#step-at-time-2","title":"Step at time 2","text":"<p>Risk set just before 2 includes all 5:</p> <ul> <li>\\(n_1=5\\)</li> <li>\\(d_1=1\\)</li> </ul> \\[ \\hat S(2)=1\\cdot\\left(1-\\frac{1}{5}\\right)=0.8 \\]"},{"location":"Survival_Analysis/05-kaplan-meier/#step-at-time-4","title":"Step at time 4","text":"<p>After event at 2, 4 subjects remain at risk:</p> <ul> <li>\\(n_2=4\\)</li> <li>\\(d_2=1\\)</li> </ul> \\[ \\hat S(4)=0.8\\cdot\\left(1-\\frac{1}{4}\\right)=0.8\\cdot0.75=0.6 \\]"},{"location":"Survival_Analysis/05-kaplan-meier/#time-5-is-censoring","title":"Time 5 is censoring","text":"<p>No survival drop at 5. But risk set shrinks for later times.</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#step-at-time-7","title":"Step at time 7","text":"<p>At time 7, two subjects are at risk (the one censored at 5 is removed):</p> <ul> <li>\\(n_3=2\\)</li> <li>\\(d_3=1\\)</li> </ul> \\[ \\hat S(7)=0.6\\cdot\\left(1-\\frac{1}{2}\\right)=0.3 \\] <p>KM estimates:</p> time \\(\\hat S(t)\\) 0 1.0 2 0.8 4 0.6 7 0.3"},{"location":"Survival_Analysis/05-kaplan-meier/#6-implementing-km-by-hand-python-r","title":"6. Implementing KM by hand (Python + R)","text":""},{"location":"Survival_Analysis/05-kaplan-meier/#61-python-manual-km-calculation","title":"6.1 Python: manual KM calculation","text":"<p>Python</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\n    \"time\":[2,4,5,7,8],\n    \"event\":[1,1,0,1,0]\n}).sort_values(\"time\")\n\nsurvival = 1.0\nprint(\"time | at_risk | events | S(t)\")\nprint(\"------------------------------\")\n\nfor t in df[\"time\"].unique():\n    at_risk = (df[\"time\"] &gt;= t).sum()\n    events  = ((df[\"time\"] == t) &amp; (df[\"event\"] == 1)).sum()\n\n    if events &gt; 0:\n        survival *= (1 - events/at_risk)\n\n    print(f\"{t:&gt;4} | {at_risk:&gt;7} | {events:&gt;6} | {survival:.3f}\")\n</code></pre> <p>This shows:  - risk set size  - event count  - updated KM survival</p>"},{"location":"Survival_Analysis/05-kaplan-meier/#62-r-manual-km-calculation","title":"6.2 R: manual KM calculation","text":"<p>R</p> <pre><code>df &lt;- data.frame(\n  time = c(2,4,5,7,8),\n  event = c(1,1,0,1,0)\n)\n\ndf &lt;- df[order(df$time), ]\n\nsurvival &lt;- 1\n\ncat(\"time | at_risk | events | S(t)\\n\")\ncat(\"------------------------------\\n\")\n\nfor (t in unique(df$time)) {\n  at_risk &lt;- sum(df$time &gt;= t)\n  events  &lt;- sum(df$time == t &amp; df$event == 1)\n\n  if (events &gt; 0) {\n    survival &lt;- survival * (1 - events/at_risk)\n  }\n\n  cat(sprintf(\"%4d | %7d | %6d | %.3f\\n\", t, at_risk, events, survival))\n}\n</code></pre>"},{"location":"Survival_Analysis/05-kaplan-meier/#7-km-using-standard-survival-libraries-python-r","title":"7. KM using standard survival libraries (Python + R)","text":""},{"location":"Survival_Analysis/05-kaplan-meier/#71-python-lifelines-kaplanmeierfitter","title":"7.1 Python: lifelines KaplanMeierFitter","text":"<p>Python</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nnp.random.seed(1)\n\nn = 200\nT = np.random.exponential(10, n)\nC = np.random.uniform(2, 15, n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\nkm = KaplanMeierFitter()\nkm.fit(time, event, label=\"KM estimate\")\n\nkm.plot()\nplt.title(\"Kaplan\u2013Meier Survival Curve\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/05-kaplan-meier/#72-r-survival-package-survfit","title":"7.2 R: survival package (survfit)","text":"<p>R</p> <pre><code>set.seed(1)\n\nn &lt;- 200\nT &lt;- rexp(n, rate = 1/10)\nC &lt;- runif(n, min=2, max=15)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\nlibrary(survival)\n\nfit &lt;- survfit(Surv(time, event) ~ 1)\n\nplot(fit, xlab=\"Time\", ylab=\"S(t)\", main=\"Kaplan\u2013Meier Survival Curve\")\n</code></pre>"},{"location":"Survival_Analysis/05-kaplan-meier/#8-km-curves-for-groups-treatment-vs-control","title":"8. KM curves for groups (treatment vs control)","text":""},{"location":"Survival_Analysis/05-kaplan-meier/#81-python-group-km-curves","title":"8.1 Python: group KM curves","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nnp.random.seed(2)\n\nn = 300\ngroup = np.random.binomial(1, 0.5, n)  # 0=control,1=treatment\n\n# Treatment has longer survival\nT0 = np.random.exponential(9, (group==0).sum())\nT1 = np.random.exponential(13, (group==1).sum())\nT = np.concatenate([T0, T1])\n\nC = np.random.uniform(2, 16, n)\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\nkm0 = KaplanMeierFitter()\nkm1 = KaplanMeierFitter()\n\nax = plt.subplot(111)\n\nkm0.fit(time[group==0], event[group==0], label=\"Control\").plot(ax=ax)\nkm1.fit(time[group==1], event[group==1], label=\"Treatment\").plot(ax=ax)\n\nplt.title(\"KM Curves by Group\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/05-kaplan-meier/#82-r-group-km-curves","title":"8.2 R: group KM curves","text":"<p>R</p> <pre><code>set.seed(2)\n\nn &lt;- 300\ngroup &lt;- rbinom(n, 1, 0.5)\n\nT0 &lt;- rexp(sum(group==0), rate = 1/9)\nT1 &lt;- rexp(sum(group==1), rate = 1/13)\nT &lt;- c(T0, T1)\n\nC &lt;- runif(n, 2, 16)\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\nlibrary(survival)\n\nfit &lt;- survfit(Surv(time, event) ~ group)\n\nplot(fit, col=c(\"black\",\"red\"), lty=1,\n     xlab=\"Time\", ylab=\"S(t)\",\n     main=\"KM Curves by Group\")\nlegend(\"topright\", legend=c(\"Control\",\"Treatment\"),\n       col=c(\"black\",\"red\"), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/05-kaplan-meier/#9-what-km-can-and-cannot-do","title":"9. What KM can and cannot do","text":""},{"location":"Survival_Analysis/05-kaplan-meier/#km-can","title":"KM CAN:","text":"<ul> <li>estimate survival probabilities over time  </li> <li>handle right censoring  </li> <li>visualize group differences  </li> <li>estimate median survival</li> </ul>"},{"location":"Survival_Analysis/05-kaplan-meier/#km-cannot","title":"KM CANNOT:","text":"<ul> <li>adjust for covariates (use Cox)  </li> <li>handle competing risks correctly (use CIF)</li> <li>model time-varying covariates directly  </li> <li>provide causal inference alone</li> </ul>"},{"location":"Survival_Analysis/05-kaplan-meier/#10-key-takeaways","title":"10. Key takeaways","text":"<ul> <li>KM estimates \\(\\hat S(t)\\) as a product of conditional survival probabilities.</li> <li>KM curve drops only at event times.</li> <li>Censoring reduces future risk sets but does not create drops.</li> <li>KM is foundational to survival analysis and is widely used in biostat papers.</li> </ul>"},{"location":"Survival_Analysis/05-kaplan-meier/#11-exercises","title":"11. Exercises","text":"Click to try  1. Manually compute KM for a dataset of 6 subjects with 2 censored values.   2. Explain in plain language why KM multiplies conditional probabilities.   3. Simulate heavy censoring and see how KM curve becomes less stable late.   4. Plot KM curves for two groups and interpret differences clinically.   5. What is the difference between \u201csurvival probability\u201d and \u201chazard\u201d?"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/","title":"Kaplan\u2013Meier Confidence Intervals and Median Survival","text":"<p>Kaplan\u2013Meier gives an estimate of survival:</p> \\[ \\hat S(t) \\] <p>But in biostatistics, we never report an estimate without uncertainty.</p> <p>So in real papers you will see results like:</p> <ul> <li>\u201c5-year survival = 0.72 (95% CI: 0.64\u20130.80)\u201d</li> <li>\u201cMedian survival = 18.3 months (95% CI: 15.1\u201322.7)\u201d</li> <li>\u201cMedian not reached\u201d</li> </ul> <p>This chapter teaches you how to compute and interpret with both Python and R.:</p> <ul> <li>standard errors  </li> <li>Greenwood variance  </li> <li>confidence intervals (with proper transformation)  </li> <li>median survival and its CI  </li> <li>reporting standards in clinical papers  </li> </ul>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#1-why-we-need-confidence-intervals","title":"1. Why we need confidence intervals","text":"<p>Suppose your KM estimate at 5 years is:</p> \\[ \\hat S(5)=0.72 \\] <p>This is a sample estimate. If you repeated the study, you would not get exactly 0.72 again.</p> <p>Confidence intervals quantify uncertainty:</p> \\[ \\hat S(5)=0.72,\\quad 95\\%\\,CI=(0.64,0.80) \\] <p>Clinical interpretation:</p> <p>Based on the observed data, the true 5-year survival is plausibly between 64% and 80%.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#2-standard-error-and-greenwoods-formula","title":"2. Standard error and Greenwood\u2019s formula","text":""},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#21-km-estimator-reminder","title":"2.1 KM estimator reminder","text":"<p>At event times \\(t_1, t_2, \\dots\\):</p> \\[ \\hat S(t)=\\prod_{t_j \\le t}\\left(1-\\frac{d_j}{n_j}\\right) \\] <p>where: - \\(n_j\\) = number at risk just before \\(t_j\\) - \\(d_j\\) = number of events at \\(t_j\\)</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#22-greenwood-variance","title":"2.2 Greenwood variance","text":"<p>The classic large-sample variance estimator for KM is:</p> \\[ \\mathrm{Var}(\\hat S(t)) = \\hat S(t)^2 \\sum_{t_j \\le t}\\frac{d_j}{n_j(n_j-d_j)} \\] <p>Standard error:</p> \\[ SE(\\hat S(t))=\\sqrt{\\mathrm{Var}(\\hat S(t))} \\]"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#23-intuition","title":"2.3 Intuition","text":"<p>Greenwood shows why uncertainty increases late in follow-up:</p> <ul> <li>As time increases, fewer people remain at risk \u2192 \\(n_j\\) becomes small  </li> <li>Small \\(n_j\\) makes \\(\\frac{1}{n_j(n_j-d_j)}\\) large  </li> <li>So variance accumulates faster</li> </ul> <p>Therefore:  - early CI is narrow  - late CI is wide (often very wide)</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#3-why-naive-ci-can-be-wrong","title":"3. Why naive CI can be wrong","text":"<p>A naive CI might be:</p> \\[ \\hat S(t) \\pm 1.96\\,SE(\\hat S(t)) \\] <p>Problem: - It can go below 0 or above 1 - Survival probabilities must stay in \\([0,1]\\)</p> <p>So we typically use a transformation that keeps CI within [0,1].</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#4-loglog-confidence-intervals","title":"4. Log\u2013log confidence intervals","text":"<p>A widely used approach is log\u2013log transformed CI (often default in software).</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#41-idea","title":"4.1 Idea","text":"<p>Transform KM to a scale where normal approximation works better, compute CI, then transform back.</p> <p>A common form:</p> \\[ CI_{\\text{lower}}(t)=\\left[\\hat S(t)\\right]^{\\exp\\!\\left(z\\,SE^{*}(t)\\right)} \\] \\[ CI_{\\text{upper}}(t)=\\left[\\hat S(t)\\right]^{\\exp\\!\\left(-z\\,SE^{*}(t)\\right)} \\] <p>where \\(z=1.96\\) for 95% CI and \\(SE^*(t)\\) is a standard error on the transformed scale.</p> <p>You do NOT need to memorize the exact formula\u2014know why we transform: - to keep CI within [0,1] - to improve coverage when survival is near 0 or 1</p> <p>Software handles it.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#5-median-survival-time","title":"5. Median survival time","text":""},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#51-definition","title":"5.1 Definition","text":"<p>Median survival is the time when survival drops to 0.5:</p> \\[ t_{0.5}=\\inf\\{t: \\hat S(t)\\le 0.5\\} \\] <p>Interpretation:</p> <p>The time by which 50% of subjects have experienced the event.</p> <p>This is a standard clinical summary because it\u2019s robust and meaningful.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#52-why-median-is-preferred-over-mean-survival","title":"5.2 Why median is preferred over mean survival","text":"<p>Mean survival is hard because: - censoring may prevent observing long tail - mean may not exist / may be unstable - with heavy censoring, mean is biased without strong assumptions</p> <p>Median is robust and is the standard in oncology/clinical trials.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#53-median-not-reached","title":"5.3 \u201cMedian not reached\u201d","text":"<p>If \\(\\hat S(t)\\) never drops below 0.5 during follow-up, then median survival is not estimable.</p> <p>In papers:</p> <p>\u201cMedian survival not reached.\u201d</p> <p>This often happens when: - follow-up is short - event rate is low - treatment is highly effective  </p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#6-visual-intuition-ci-and-median","title":"6. Visual intuition: CI and median","text":"<pre><code>S(t)\n1.0 |---------\n    |   \\    (CI narrow early)\n0.5 |----\\-----------------  \u2190 median where curve crosses 0.5\n    |      \\__ (CI widens late)\n0.0 +------------------------- time\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#7-compute-km-ci-median-in-python-lifelines","title":"7. Compute KM + CI + median in Python (lifelines)","text":""},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#71-simulate-survival-data-same-dataset-used-in-later-sections","title":"7.1 Simulate survival data (same dataset used in later sections)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 250\n\n# True event times\nT = np.random.exponential(scale=10, size=n)\n\n# Censoring times\nC = np.random.uniform(2, 18, size=n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event})\ndf.head()\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#72-fit-kaplanmeier-and-plot-ci","title":"7.2 Fit Kaplan\u2013Meier and plot CI","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nkm = KaplanMeierFitter()\nkm.fit(df[\"time\"], df[\"event\"], label=\"KM\")\n\nax = km.plot_survival_function(ci_show=True)\nplt.title(\"Kaplan\u2013Meier Survival with 95% CI\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#73-extract-survival-at-specific-times-1-5-10-units","title":"7.3 Extract survival at specific times (1, 5, 10 units)","text":"<p>Python</p> <pre><code>times_of_interest = [1, 5, 10]\n\n# lifelines provides survival function values at times\nsurv = km.survival_function_at_times(times_of_interest)\n\n# confidence intervals at those times\nci = km.confidence_interval_at_times(times_of_interest)\n\nprint(\"Survival estimates:\")\nprint(surv)\n\nprint(\"\\n95% CI:\")\nprint(ci)\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#74-median-survival-time","title":"7.4 Median survival time","text":"<p>Python</p> <pre><code>km.median_survival_time_\n</code></pre> <p>If this returns <code>inf</code> or <code>None</code>, that often indicates median was not reached.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#75-a-publication-style-summary-table-in-python","title":"7.5 A \u201cpublication-style\u201d summary table in Python","text":"<p>Python</p> <pre><code>summary = pd.DataFrame({\n    \"time\": times_of_interest,\n    \"S(t)\": km.survival_function_at_times(times_of_interest).values\n})\n\nci = km.confidence_interval_at_times(times_of_interest)\nsummary[\"CI_lower\"] = ci.iloc[:, 0].values\nsummary[\"CI_upper\"] = ci.iloc[:, 1].values\n\nsummary\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#8-compute-km-ci-median-in-r-survival-survminer","title":"8. Compute KM + CI + median in R (survival + survminer)","text":""},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#81-simulate-data-in-r","title":"8.1 Simulate data in R","text":"<p>R</p> <pre><code>set.seed(123)\n\nn &lt;- 250\nT &lt;- rexp(n, rate = 1/10)      # mean 10\nC &lt;- runif(n, min = 2, max = 18)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event)\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#82-fit-kaplanmeier-and-plot-with-ci","title":"8.2 Fit Kaplan\u2013Meier and plot with CI","text":"<p>R</p> <pre><code>library(survival)\n\nfit &lt;- survfit(Surv(time, event) ~ 1, data=df)\n\nplot(fit, conf.int=TRUE,\n     xlab=\"Time\", ylab=\"S(t)\",\n     main=\"Kaplan\u2013Meier Survival with 95% CI\")\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#83-extract-survival-estimates-at-specific-times","title":"8.3 Extract survival estimates at specific times","text":"<p>In base <code>survival</code>, use <code>summary(fit, times=...)</code>.</p> <p>R</p> <pre><code>times_of_interest &lt;- c(1, 5, 10)\n\ns &lt;- summary(fit, times = times_of_interest)\n\nout &lt;- data.frame(\n  time = s$time,\n  surv = s$surv,\n  lower = s$lower,\n  upper = s$upper\n)\n\nout\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#84-median-survival-and-its-ci-in-r","title":"8.4 Median survival and its CI in R","text":"<p><code>survfit</code> stores median in the printed output. A standard way is:</p> <p>R</p> <pre><code># Median survival time:\nfit\n\n# A direct extraction (often works):\nfit$table[\"median\"]\n</code></pre> <p>For median CI, many users rely on <code>survminer::surv_median()</code>:</p> <p>R</p> <pre><code># install.packages(\"survminer\")  # if needed\nlibrary(survminer)\n\nsurv_median(fit)\n</code></pre> <p>If median not reached, it will show NA or similar outputs.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#9-group-specific-median-survival-and-ci-python-r","title":"9. Group-specific median survival and CI (Python + R)","text":"<p>Many clinical studies compare groups.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#91-python-treatment-vs-control-km-median","title":"9.1 Python: treatment vs control KM + median","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nnp.random.seed(7)\n\nn = 300\ngroup = np.random.binomial(1, 0.5, n)  # 0=control,1=treatment\n\n# Treatment has longer mean survival\nT0 = np.random.exponential(9, (group==0).sum())\nT1 = np.random.exponential(13, (group==1).sum())\nT = np.concatenate([T0, T1])\n\nC = np.random.uniform(2, 16, n)\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf2 = pd.DataFrame({\"time\": time, \"event\": event, \"group\": group})\n\nkm0 = KaplanMeierFitter()\nkm1 = KaplanMeierFitter()\n\nax = plt.subplot(111)\nkm0.fit(df2.loc[df2.group==0, \"time\"], df2.loc[df2.group==0, \"event\"], label=\"Control\").plot(ax=ax, ci_show=True)\nkm1.fit(df2.loc[df2.group==1, \"time\"], df2.loc[df2.group==1, \"event\"], label=\"Treatment\").plot(ax=ax, ci_show=True)\n\nplt.title(\"KM Curves with 95% CI by Group\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n\nprint(\"Median (Control):\", km0.median_survival_time_)\nprint(\"Median (Treatment):\", km1.median_survival_time_)\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#92-r-treatment-vs-control-km-median","title":"9.2 R: treatment vs control KM + median","text":"<p>R</p> <pre><code>set.seed(7)\n\nn &lt;- 300\ngroup &lt;- rbinom(n, 1, 0.5)\n\nT0 &lt;- rexp(sum(group==0), rate = 1/9)\nT1 &lt;- rexp(sum(group==1), rate = 1/13)\nT &lt;- c(T0, T1)\n\nC &lt;- runif(n, 2, 16)\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf2 &lt;- data.frame(time=time, event=event, group=factor(group, labels=c(\"Control\",\"Treatment\")))\n\nlibrary(survival)\n\nfit_g &lt;- survfit(Surv(time, event) ~ group, data=df2)\n\nplot(fit_g, col=c(\"black\",\"red\"), lty=1, conf.int=TRUE,\n     xlab=\"Time\", ylab=\"S(t)\",\n     main=\"KM Curves with 95% CI by Group\")\nlegend(\"topright\", legend=levels(df2$group), col=c(\"black\",\"red\"), lty=1)\n\n# Median by group\nfit_g$table[,\"median\"]\n</code></pre>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#10-how-to-report-results","title":"10. How to report results","text":""},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#101-survival-probability-at-fixed-time","title":"10.1 Survival probability at fixed time","text":"<p>Example:</p> <p>\u201cFive-year survival was 0.72 (95% CI: 0.64\u20130.80).\u201d</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#102-median-survival","title":"10.2 Median survival","text":"<p>Example:</p> <p>\u201cMedian survival was 18.3 months (95% CI: 15.1\u201322.7).\u201d</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#103-median-not-reached","title":"10.3 Median not reached","text":"<p>Example:</p> <p>\u201cMedian survival was not reached during follow-up.\u201d</p> <p>Always specify:  - time unit (months/years)  - method (Kaplan\u2013Meier)  - CI level (usually 95%)</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#11-common-mistakes-and-how-to-avoid-them","title":"11. Common mistakes and how to avoid them","text":""},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#mistake-1-ci-outside-01","title":"Mistake 1: CI outside [0,1]","text":"<p>Fix: use log\u2013log CI (software default).</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#mistake-2-interpreting-ci-overlap-as-hypothesis-test","title":"Mistake 2: interpreting CI overlap as hypothesis test","text":"<p>CI overlap is not a formal test for group differences.  Use log-rank or Cox for testing.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#mistake-3-reporting-mean-survival-without-justification","title":"Mistake 3: reporting mean survival without justification","text":"<p>Mean requires strong assumptions; median is standard.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#mistake-4-reporting-late-survival-estimates-with-tiny-risk-set","title":"Mistake 4: reporting late survival estimates with tiny risk set","text":"<p>Late tail can be unstable; always check number at risk.</p>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#12-key-takeaways","title":"12. Key takeaways","text":"<ul> <li>Greenwood\u2019s formula gives variance/SE for KM.</li> <li>CI should be constructed on a transformed scale (log\u2013log) to stay within [0,1].</li> <li>Median survival is time where \\(\\hat S(t)\\le 0.5\\).</li> <li>If \\(\\hat S(t)\\) never drops below 0.5, median is \u201cnot reached.\u201d</li> <li>Always report survival estimates with CI in medical research.</li> </ul>"},{"location":"Survival_Analysis/06-km-confidence-intervals-median/#13-exercises","title":"13. Exercises","text":"Click to try  1. Simulate a dataset with very heavy censoring and plot KM with CI. How does CI width change?   2. Compute \\(\\hat S(5)\\) and its CI in Python and in R. Confirm results are similar.   3. Create data where median is not reached and explain how you would report it.   4. Why does Greenwood variance increase late in follow-up?   5. In group comparison, why can\u2019t CI overlap be used as a test?"},{"location":"Survival_Analysis/07-logrank-test/","title":"Log-Rank Test (Comparing Survival Curves)","text":"<p>Kaplan\u2013Meier curves give a visual comparison between groups.</p> <p>But in biostatistics, we must answer:</p> <p>Are these survival curves statistically different, or is the difference due to chance?</p> <p>The standard hypothesis test for comparing entire survival curves is:</p>"},{"location":"Survival_Analysis/07-logrank-test/#log-rank-test","title":"Log-rank test","text":"<p>This chapter explains:  - intuition (observed vs expected)  - full formulas  - what the p-value means clinically  - assumptions and limitations  - implementation in Python and R</p>"},{"location":"Survival_Analysis/07-logrank-test/#1-problem-setup","title":"1. Problem setup","text":"<p>Suppose we have two groups:</p> <ul> <li>Group 0: Control</li> <li>Group 1: Treatment</li> </ul> <p>We observe:  - follow-up time  - event indicator - group membership</p> <p>We want to test:</p> <p>Do the groups have the same survival experience over time?</p>"},{"location":"Survival_Analysis/07-logrank-test/#2-hypotheses","title":"2. Hypotheses","text":""},{"location":"Survival_Analysis/07-logrank-test/#null-hypothesis","title":"Null hypothesis","text":"\\[ H_0: S_0(t)=S_1(t)\\ \\text{for all } t \\] <p>Meaning: - no difference in survival curves</p>"},{"location":"Survival_Analysis/07-logrank-test/#alternative-hypothesis","title":"Alternative hypothesis","text":"\\[ H_A: S_0(t)\\ne S_1(t) \\] <p>Meaning: - survival differs at some point in time</p>"},{"location":"Survival_Analysis/07-logrank-test/#3-the-core-intuition-observed-vs-expected","title":"3. The core intuition: observed vs expected","text":"<p>At each event time, consider the risk set:</p> <ul> <li>how many people are at risk in each group?</li> <li>how many events occur overall?</li> <li>how many events should occur in each group if \\(H_0\\) were true?</li> </ul> <p>If the observed events differ strongly from expected events across time, we reject \\(H_0\\).</p>"},{"location":"Survival_Analysis/07-logrank-test/#4-notation-at-an-event-time-t_j","title":"4. Notation at an event time \\(t_j\\)","text":"<p>At event time \\(t_j\\):</p> <ul> <li>\\(n_j\\) = total number at risk just before \\(t_j\\)</li> <li>\\(n_{0j}\\), \\(n_{1j}\\) = at risk in group 0 and group 1</li> <li>\\(d_j\\) = total events at \\(t_j\\)</li> <li>\\(d_{0j}\\), \\(d_{1j}\\) = observed events in each group</li> </ul>"},{"location":"Survival_Analysis/07-logrank-test/#5-expected-events-under-the-null","title":"5. Expected events under the null","text":"<p>If the groups are identical (null hypothesis true), events should be split according to risk set proportions.</p> <p>Expected events in group 1:</p> \\[ E_{1j}=d_j\\frac{n_{1j}}{n_j} \\] <p>Expected events in group 0:</p> \\[ E_{0j}=d_j\\frac{n_{0j}}{n_j} \\]"},{"location":"Survival_Analysis/07-logrank-test/#6-log-rank-test-statistic","title":"6. Log-rank test statistic","text":"<p>Define the difference:</p> \\[ O_1 - E_1 = \\sum_j (d_{1j}-E_{1j}) \\] <p>Variance of \\(O_1-E_1\\) is approximately:</p> \\[ Var(O_1-E_1)=\\sum_j \\frac{n_{0j}n_{1j}d_j(n_j-d_j)}{n_j^2(n_j-1)} \\] <p>The test statistic:</p> \\[ Z=\\frac{O_1-E_1}{\\sqrt{Var(O_1-E_1)}} \\] <p>Often reported as chi-square:</p> \\[ \\chi^2 = Z^2 \\sim \\chi^2_1 \\] <p>So we compute: - \\(p\\)-value from \\(\\chi^2_1\\)</p>"},{"location":"Survival_Analysis/07-logrank-test/#7-how-to-interpret-the-p-value-clinically","title":"7. How to interpret the p-value clinically","text":""},{"location":"Survival_Analysis/07-logrank-test/#if-p-005","title":"If p &lt; 0.05","text":"<p>We have evidence that survival differs between groups.</p> <p>Clinical writing example:</p> <p>\u201cSurvival curves differed significantly (log-rank p = 0.01).\u201d</p>"},{"location":"Survival_Analysis/07-logrank-test/#if-p-005_1","title":"If p \u2265 0.05","text":"<p>No evidence of difference.</p> <p>Example:</p> <p>\u201cNo significant difference was observed (log-rank p = 0.42).\u201d</p> <p>Important: - A non-significant p-value does NOT prove curves are equal. - It may mean sample size is small or censoring is heavy.</p>"},{"location":"Survival_Analysis/07-logrank-test/#8-what-log-rank-is-sensitive-to","title":"8. What log-rank is sensitive to","text":"<p>Log-rank is most powerful when:</p> <ul> <li>hazard ratio is roughly constant over time (i.e., proportional hazards holds approximately)</li> <li>If curves cross strongly, log-rank can lose power.</li> </ul>"},{"location":"Survival_Analysis/07-logrank-test/#9-limitations-and-special-cases","title":"9. Limitations and special cases","text":""},{"location":"Survival_Analysis/07-logrank-test/#91-crossing-survival-curves-non-proportional-hazards","title":"9.1 Crossing survival curves (non-proportional hazards)","text":"<p>If treatment helps early but harms later, curves may cross. Log-rank (which weights all times equally) can become misleading.</p> <p>In such cases consider:  - weighted log-rank tests  - Cox models with time interaction  - restricted mean survival time (RMST)</p>"},{"location":"Survival_Analysis/07-logrank-test/#92-heavy-censoring-late-in-follow-up","title":"9.2 Heavy censoring late in follow-up","text":"<p>Risk sets become tiny; late information is unstable. Always check \u201cnumber at risk\u201d tables.</p>"},{"location":"Survival_Analysis/07-logrank-test/#93-ties","title":"9.3 Ties","text":"<p>Multiple events at the same time: - handled in software (Efron/Breslow methods)</p>"},{"location":"Survival_Analysis/07-logrank-test/#10-example-conceptual","title":"10. Example (conceptual)","text":"<p>Suppose at one event time:</p> <ul> <li>risk set: 60 treated, 40 control (total 100)</li> <li>total events at this time: 10</li> </ul> <p>Expected treated events:</p> \\[ E = 10 \\cdot \\frac{60}{100} = 6 \\] <p>If observed treated events are 2, then:</p> \\[ O - E = 2 - 6 = -4 \\] <p>This indicates treatment may reduce event risk at that time.</p> <p>Log-rank repeats this at all event times and sums.</p>"},{"location":"Survival_Analysis/07-logrank-test/#11-implementation-in-python-lifelines","title":"11. Implementation in Python (lifelines)","text":"<p>We will:  1) simulate two-group survival data  2) plot KM curves  3) run log-rank test  </p>"},{"location":"Survival_Analysis/07-logrank-test/#111-python-simulation-km-curves","title":"11.1 Python simulation + KM curves","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.statistics import logrank_test\n\nnp.random.seed(202)\n\nn = 400\ngroup = np.random.binomial(1, 0.5, n)  # 0=control, 1=treatment\n\n# Control has shorter mean survival\nT0 = np.random.exponential(8, (group==0).sum())\n# Treatment has longer mean survival\nT1 = np.random.exponential(12, (group==1).sum())\n\nT = np.concatenate([T0, T1])\n\n# Censoring\nC = np.random.uniform(2, 15, n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event, \"group\": group})\n\nkm0 = KaplanMeierFitter()\nkm1 = KaplanMeierFitter()\n\nax = plt.subplot(111)\nkm0.fit(df.loc[df.group==0, \"time\"], df.loc[df.group==0, \"event\"], label=\"Control\").plot(ax=ax)\nkm1.fit(df.loc[df.group==1, \"time\"], df.loc[df.group==1, \"event\"], label=\"Treatment\").plot(ax=ax)\n\nplt.title(\"KM Curves (Control vs Treatment)\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/07-logrank-test/#112-python-log-rank-test","title":"11.2 Python: log-rank test","text":"<p>Python</p> <pre><code>result = logrank_test(\n    df.loc[df.group==0, \"time\"],\n    df.loc[df.group==1, \"time\"],\n    event_observed_A=df.loc[df.group==0, \"event\"],\n    event_observed_B=df.loc[df.group==1, \"event\"]\n)\n\nprint(result.summary)\n</code></pre> <p>Output includes: - test statistic - p-value</p>"},{"location":"Survival_Analysis/07-logrank-test/#113-sensitivity-experiments-recommended","title":"11.3 Sensitivity experiments (recommended)","text":"<p>Try:  - Make group means equal \u2192 p-value should be large  - Make treatment much better \u2192 p-value should be tiny  - Increase censoring \u2192 test loses power</p>"},{"location":"Survival_Analysis/07-logrank-test/#12-implementation-in-r-survival-package","title":"12. Implementation in R (survival package)","text":"<p>We will:  1) simulate data  2) fit KM curves  3) run log-rank test via <code>survdiff()</code> </p>"},{"location":"Survival_Analysis/07-logrank-test/#121-r-simulation-km-curves","title":"12.1 R simulation + KM curves","text":"<p>R</p> <pre><code>set.seed(202)\n\nn &lt;- 400\ngroup &lt;- rbinom(n, 1, 0.5)\n\nT0 &lt;- rexp(sum(group==0), rate = 1/8)\nT1 &lt;- rexp(sum(group==1), rate = 1/12)\nT &lt;- c(T0, T1)\n\nC &lt;- runif(n, 2, 15)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event, group=factor(group, labels=c(\"Control\",\"Treatment\")))\n\nlibrary(survival)\n\nfit &lt;- survfit(Surv(time, event) ~ group, data=df)\n\nplot(fit, col=c(\"black\",\"red\"), lty=1,\n     xlab=\"Time\", ylab=\"S(t)\",\n     main=\"KM Curves (Control vs Treatment)\")\nlegend(\"topright\", legend=levels(df$group), col=c(\"black\",\"red\"), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/07-logrank-test/#122-r-log-rank-test","title":"12.2 R: log-rank test","text":"<p>In R, log-rank is:</p> <p><code>survdiff(Surv(time, event) ~ group)</code></p> <p>R</p> <pre><code>lr &lt;- survdiff(Surv(time, event) ~ group, data=df)\nlr\n</code></pre> <p>To compute p-value:</p> <p>R</p> <pre><code>pval &lt;- 1 - pchisq(lr$chisq, df=1)\npval\n</code></pre>"},{"location":"Survival_Analysis/07-logrank-test/#13-log-rank-vs-cox-whats-the-difference","title":"13. Log-rank vs Cox: what\u2019s the difference?","text":""},{"location":"Survival_Analysis/07-logrank-test/#log-rank-test_1","title":"Log-rank test","text":"<ul> <li>compares groups only</li> <li>gives p-value only</li> <li>does NOT adjust for covariates</li> </ul>"},{"location":"Survival_Analysis/07-logrank-test/#cox-regression","title":"Cox regression","text":"<ul> <li>gives hazard ratio (effect size)</li> <li>adjusts for covariates (age, sex, biomarkers)</li> <li>provides CI, p-values, model building</li> </ul> <p>Workflow in medical papers:  1. KM plot  2. log-rank p-value  3. Cox hazard ratio (adjusted)</p>"},{"location":"Survival_Analysis/07-logrank-test/#14-key-takeaways","title":"14. Key takeaways","text":"<ul> <li>Log-rank tests whether survival curves differ across the entire follow-up.</li> <li>At each event time, compare observed vs expected events using risk sets.</li> <li>Test statistic is approximately chi-square with 1 df for two groups.</li> <li>Works best when proportional hazards roughly holds.</li> <li>Use Cox regression for adjusted hazard ratios and effect size.</li> </ul>"},{"location":"Survival_Analysis/07-logrank-test/#15-exercises","title":"15. Exercises","text":"Click to try   1. Explain why log-rank uses risk sets rather than full sample size.    2. Simulate data where two groups have equal hazards. What p-value do you get?    3. Simulate crossing survival curves (early benefit, late harm). What happens to log-rank?    4. Why is log-rank not a substitute for Cox regression?    5. Fit KM in R and Python and confirm log-rank p-values agree."},{"location":"Survival_Analysis/08-cox-proportional-hazards/","title":"Cox Proportional Hazards Model (Cox PH)","text":"<p>Kaplan\u2013Meier and log-rank help you describe and compare survival curves.</p> <p>But in real biostatistics, we almost always need to answer:</p> <ul> <li>How does treatment affect survival after adjusting for age/sex/stage?</li> <li>What is the effect size (hazard ratio) with confidence intervals?</li> <li>How do multiple predictors jointly influence risk?</li> </ul> <p>That is exactly what the Cox proportional hazards model does.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#cox-ph-is-the-workhorse-model-of-survival-analysis","title":"Cox PH is the workhorse model of survival analysis.","text":""},{"location":"Survival_Analysis/08-cox-proportional-hazards/#1-what-cox-regression-models-the-hazard","title":"1. What Cox regression models (the hazard)","text":"<p>Cox models the hazard function:</p> \\[ h(t \\mid X) = h_0(t)\\exp(\\beta_1X_1+\\cdots+\\beta_pX_p) \\] <p>Where:</p> <ul> <li>\\(h(t \\mid X)\\): hazard at time \\(t\\) for covariate vector \\(X\\)</li> <li>\\(h_0(t)\\): baseline hazard (unknown function of time)</li> <li>\\(\\exp(\\beta^TX)\\): multiplicative effect of covariates</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#11-key-idea-multiplicative-risk","title":"1.1 Key idea: multiplicative risk","text":"<p>Covariates scale risk multiplicatively:</p> <ul> <li>If \\(\\exp(\\beta)=1.5\\), hazard is 1.5\u00d7 higher (50% higher risk rate).</li> <li>If \\(\\exp(\\beta)=0.7\\), hazard is 0.7\u00d7 (30% lower risk rate).</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#2-why-cox-is-called-semi-parametric","title":"2. Why Cox is called \u201csemi-parametric\u201d","text":"<p>Cox does not assume a parametric form for survival times (like exponential or Weibull).</p> <ul> <li>It leaves \\(h_0(t)\\) unspecified.</li> <li>It estimates \\(\\beta\\) without needing to specify \\(h_0(t)\\).</li> </ul> <p>So it\u2019s: - parametric in covariates (linear predictor \\(\\beta^TX\\)) - nonparametric in baseline hazard (\\(h_0(t)\\))</p> <p>This is why Cox is flexible and widely used.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#3-the-hazard-ratio-hr-the-main-output","title":"3. The hazard ratio (HR) \u2014 the main output","text":"<p>For a 1-unit increase in predictor \\(X_j\\):</p> \\[ HR = \\exp(\\beta_j) \\]"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#31-clinical-interpretation","title":"3.1 Clinical interpretation","text":"<ul> <li>\\(HR = 1\\): no difference in hazard</li> <li>\\(HR &gt; 1\\): higher hazard \u2192 worse survival (typically)</li> <li>\\(HR &lt; 1\\): lower hazard \u2192 better survival (typically)</li> </ul> <p>Examples: - HR = 1.20: 20% higher instantaneous risk - HR = 0.65: 35% lower instantaneous risk</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#32-continuous-predictors-age","title":"3.2 Continuous predictors (age)","text":"<p>If HR for age is 1.04:</p> <p>Each extra year of age increases hazard by ~4% (assuming linear effect).</p> <p>For a 10-year increase: [ HR_{10} = 1.04^{10}\\approx 1.48 ] So ~48% higher hazard.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#4-the-proportional-hazards-ph-assumption-critical","title":"4. The proportional hazards (PH) assumption (critical)","text":"<p>Cox assumes hazard ratios are constant over time:</p> \\[ \\frac{h(t\\mid X_a)}{h(t\\mid X_b)} = \\exp(\\beta(X_a-X_b)) \\] <p>No \\(t\\) in the ratio \u21d2 constant over time.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#41-what-ph-means-in-plain-language","title":"4.1 What PH means in plain language","text":"<p>If treatment HR = 0.70, then:</p> <p>Treatment reduces hazard by 30% at all times (early, middle, late).</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#42-what-ph-does-not-allow","title":"4.2 What PH does NOT allow","text":"<p>If treatment helps early but harms later (curves cross):</p> <ul> <li>PH is violated</li> <li>Cox HR becomes difficult to interpret</li> </ul> <p>We handle this later using: - time interactions - stratified Cox - time-varying effects</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#5-where-cox-comes-from-partial-likelihood-intuition","title":"5. Where Cox comes from: partial likelihood (intuition)","text":"<p>At each event time \\(t_j\\), Cox compares:</p> <ul> <li>the subject who had the event at \\(t_j\\)</li> <li>to everyone in the risk set \\(R(t_j)\\) (those who could have had the event at that time)</li> </ul> <p>The probability that subject \\(i\\) fails at \\(t_j\\) given one event occurs then:</p> \\[ \\frac{\\exp(\\beta^TX_i)}{\\sum_{k\\in R(t_j)}\\exp(\\beta^TX_k)} \\] <p>Multiply over event times:</p> \\[ L(\\beta)=\\prod_j \\frac{\\exp(\\beta^TX_{(j)})}{\\sum_{k\\in R(t_j)}\\exp(\\beta^TX_k)} \\] <p>This is the partial likelihood.</p> <p>Key insight:</p> <p>We estimate \\(\\beta\\) without ever specifying \\(h_0(t)\\).</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#6-data-structure-for-cox","title":"6. Data structure for Cox","text":"<p>Minimum variables:</p> <ul> <li><code>time</code>: observed follow-up time (event or censor)</li> <li><code>event</code>: 1 if event, 0 if censored</li> <li>predictors: age, sex, treatment, stage, etc.</li> </ul> <p>Example:</p> time event age trt 4.2 1 63 1 7.9 0 55 0 2.1 1 71 1"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7-a-complete-simulation-with-known-truth-python-r","title":"7. A complete simulation with known truth (Python + R)","text":"<p>We simulate a study where: - age increases hazard - treatment reduces hazard - censoring occurs</p> <p>Then we fit Cox and see if we recover the true effects.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7a-python-lifelines-cox-ph-in-practice","title":"7A. Python (lifelines) \u2014 Cox PH in practice","text":""},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7a1-simulate-survival-data","title":"7A.1 Simulate survival data","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(2026)\n\nn = 400\n\n# Covariates\nage = np.random.normal(60, 10, n)          # continuous predictor\ntrt = np.random.binomial(1, 0.5, n)        # 0=control, 1=treatment\n\n# True coefficients (we will try to recover these)\nbeta_age = 0.03        # HR per year ~ exp(0.03)=1.030\nbeta_trt = -0.50       # HR treatment vs control ~ exp(-0.50)=0.607\n\n# Baseline hazard scale (controls overall event rate)\nbase = 0.04\n\n# Individual hazard rates (proportional hazards)\nhazard = base * np.exp(beta_age*age + beta_trt*trt)\n\n# True event times from exponential with individual hazards\nT = np.random.exponential(1/hazard)\n\n# Random censoring times\nC = np.random.uniform(2, 25, n)\n\n# Observed data\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event, \"age\": age, \"treatment\": trt})\ndf.head()\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7a2-fit-cox-ph-model","title":"7A.2 Fit Cox PH model","text":"<p>Python</p> <pre><code>from lifelines import CoxPHFitter\n\ncph = CoxPHFitter()\ncph.fit(df, duration_col=\"time\", event_col=\"event\")\n\ncph.print_summary()\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#what-to-look-for","title":"What to look for","text":"<ul> <li><code>coef</code> \u2248 true beta</li> <li><code>exp(coef)</code> \u2248 true hazard ratio</li> <li>p-values often significant if effect is strong and sample size decent</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7a3-interpret-output-common-columns","title":"7A.3 Interpret output (common columns)","text":"<p>Typical Cox output includes:</p> <ul> <li><code>coef</code> = \\(\\beta\\)</li> <li><code>exp(coef)</code> = hazard ratio</li> <li><code>se(coef)</code> = standard error</li> <li><code>p</code> = p-value testing \\(\\beta=0\\)</li> <li>CI for HR</li> </ul> <p>Interpretation example: - exp(coef) = 0.61 for treatment \u2192 ~39% hazard reduction</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7a4-predict-survival-curves-for-profiles","title":"7A.4 Predict survival curves for profiles","text":"<p>Cox can produce predicted survival curves using estimated baseline + covariates.</p> <p>Python</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\nprofile_control = pd.DataFrame({\"age\":[60], \"treatment\":[0]})\nprofile_treated = pd.DataFrame({\"age\":[60], \"treatment\":[1]})\n\ns0 = cph.predict_survival_function(profile_control)\ns1 = cph.predict_survival_function(profile_treated)\n\nplt.plot(s0, label=\"Control (age=60)\")\nplt.plot(s1, label=\"Treatment (age=60)\")\nplt.legend()\nplt.title(\"Predicted Survival Curves from Cox PH\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7a5-multivariable-cox-example-add-more-covariates","title":"7A.5 Multivariable Cox example (add more covariates)","text":"<p>Python</p> <pre><code>np.random.seed(7)\n\ndf2 = df.copy()\ndf2[\"sex\"] = np.random.binomial(1, 0.5, len(df2))  # 0=female,1=male\ndf2[\"bmi\"] = np.random.normal(27, 4, len(df2))\n\ncph2 = CoxPHFitter()\ncph2.fit(df2, duration_col=\"time\", event_col=\"event\")\n\ncph2.print_summary()\n</code></pre> <p>Interpretation: - Each coefficient is adjusted for the others.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7b-r-survival-cox-ph-in-practice","title":"7B. R (survival) \u2014 Cox PH in practice","text":""},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7b1-simulate-survival-data-in-r","title":"7B.1 Simulate survival data in R","text":"<p>R</p> <pre><code>set.seed(2026)\n\nn &lt;- 400\n\nage &lt;- rnorm(n, mean=60, sd=10)\ntrt &lt;- rbinom(n, 1, 0.5)\n\nbeta_age &lt;- 0.03\nbeta_trt &lt;- -0.50\nbase &lt;- 0.04\n\nhazard &lt;- base * exp(beta_age*age + beta_trt*trt)\n\n# event times\nT &lt;- rexp(n, rate = hazard)\n\n# censoring times\nC &lt;- runif(n, min=2, max=25)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event, age=age, treatment=trt)\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7b2-fit-cox-model-in-r","title":"7B.2 Fit Cox model in R","text":"<p>R</p> <pre><code>library(survival)\n\nfit &lt;- coxph(Surv(time, event) ~ age + treatment, data=df)\nsummary(fit)\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#what-to-look-for-in-summaryfit","title":"What to look for in <code>summary(fit)</code>","text":"<ul> <li><code>coef</code> = \\(\\beta\\)</li> <li><code>exp(coef)</code> = hazard ratio</li> <li><code>se(coef)</code> = standard error</li> <li>Wald test p-values</li> <li>95% CI for HR</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7b3-predicted-survival-curves-in-r-for-profiles","title":"7B.3 Predicted survival curves in R (for profiles)","text":"<p>In R, prediction is typically done using <code>survfit()</code> on a Cox model:</p> <p>R</p> <pre><code>newdata &lt;- data.frame(age=c(60,60), treatment=c(0,1))\n\nsf &lt;- survfit(fit, newdata=newdata)\n\nplot(sf, col=c(\"black\",\"red\"), lty=1,\n     xlab=\"Time\", ylab=\"S(t)\",\n     main=\"Predicted Survival Curves from Cox PH\")\nlegend(\"topright\", legend=c(\"Control age=60\",\"Treatment age=60\"),\n       col=c(\"black\",\"red\"), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#7b4-multivariable-cox-example-in-r","title":"7B.4 Multivariable Cox example in R","text":"<p>R</p> <pre><code>set.seed(7)\ndf$sex &lt;- rbinom(nrow(df), 1, 0.5)\ndf$bmi &lt;- rnorm(nrow(df), 27, 4)\n\nfit2 &lt;- coxph(Surv(time, event) ~ age + treatment + sex + bmi, data=df)\nsummary(fit2)\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#8-model-interpretation-what-cox-answers-and-what-it-doesnt","title":"8. Model interpretation: what Cox answers (and what it doesn\u2019t)","text":""},{"location":"Survival_Analysis/08-cox-proportional-hazards/#cox-does-answer","title":"Cox DOES answer:","text":"<ul> <li>association between covariates and hazard  </li> <li>adjusted hazard ratios  </li> <li>hypothesis tests for covariates  </li> <li>predicted survival curves for profiles (with baseline estimation)</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#cox-does-not-automatically-answer","title":"Cox DOES NOT automatically answer:","text":"<ul> <li>causal effect unless design/assumptions justify causality  </li> <li>what happens when hazards are non-proportional  </li> <li>competing risks probabilities (need CIF)  </li> <li>repeated events without special modeling</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#9-checking-proportional-hazards-preview","title":"9. Checking proportional hazards (preview)","text":"<p>You must check PH assumption before reporting results.</p> <p>In later chapters we will do this deeply using:</p> <ul> <li>Schoenfeld residuals</li> <li>PH tests</li> <li>plots</li> </ul> <p>Quick preview:</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#python-lifelines","title":"Python (lifelines)","text":"<p>Python</p> <pre><code>cph.check_assumptions(df, show_plots=False)\n</code></pre>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#r-survival","title":"R (survival)","text":"<p>R</p> <pre><code>cox.zph(fit)\n</code></pre> <p>Interpretation: - Small p-value suggests PH violation.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#10-how-to-report-cox-results","title":"10. How to report Cox results","text":"<p>A standard reporting sentence:</p> <p>\u201cIn a multivariable Cox proportional hazards model adjusting for age and sex, treatment was associated with improved survival (HR 0.61, 95% CI 0.48\u20130.77, p &lt; 0.001).\u201d</p> <p>Key elements:  - model type (Cox PH)  - adjusted covariates  - HR, CI, p-value  - direction and clinical interpretation</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#11-common-mistakes","title":"11. Common mistakes","text":""},{"location":"Survival_Analysis/08-cox-proportional-hazards/#mistake-1-interpreting-hr-as-a-probability","title":"Mistake 1: interpreting HR as a probability","text":"<p>HR is a ratio of hazard rates, not survival probability.</p> <p>Fix: interpret as instantaneous risk rate ratio.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#mistake-2-ignoring-ph-assumption","title":"Mistake 2: ignoring PH assumption","text":"<p>If PH violated, HR may change over time and \u201cone HR\u201d can mislead.</p> <p>Fix: check PH; use time-varying effects if needed.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#mistake-3-using-cox-for-competing-risks-outcome","title":"Mistake 3: using Cox for competing risks outcome","text":"<p>If competing risks present, standard Cox does not directly estimate cumulative incidence.</p> <p>Fix: use competing risks methods (CIF, Fine\u2013Gray).</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#mistake-4-nonlinear-continuous-covariates","title":"Mistake 4: nonlinear continuous covariates","text":"<p>Age effect might not be linear in log-hazard.</p> <p>Fix: consider splines / transformations.</p>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#12-key-takeaways","title":"12. Key takeaways","text":"<ul> <li>Cox PH models hazard: \\(h(t|X)=h_0(t)\\exp(\\beta^TX)\\).</li> <li>Main output: hazard ratio \\(\\exp(\\beta)\\).</li> <li>Proportional hazards assumption: HR constant over time.</li> <li>Cox estimates \\(\\beta\\) using partial likelihood and risk sets.</li> <li>Always check PH before interpreting results.</li> <li>Cox is the standard regression tool for survival analysis.</li> </ul>"},{"location":"Survival_Analysis/08-cox-proportional-hazards/#13-exercises","title":"13. Exercises","text":"Click to try   1. Simulate data where treatment has no effect (set beta_trt = 0). Fit Cox. What HR do you estimate?    2. Interpret HR = 1.25 in plain language.    3. Compute HR for a 10-year age increase when HR per year is 1.04.    4. Fit Cox in both Python and R and compare coefficients/HR.    5. Simulate a scenario where treatment effect changes over time (early benefit, late harm) and check PH diagnostics (preview with cox.zph / check_assumptions)."},{"location":"Survival_Analysis/09-cox-diagnostics/","title":"Cox Model Diagnostics and Assumption Checking","text":"<p>A Cox model is not complete when you fit it.</p> <p>In real biostatistical work, the correct workflow is:</p> <p>Fit Cox \u2192 Check assumptions \u2192 Fix violations \u2192 Interpret HRs</p> <p>If you skip diagnostics, your hazard ratios (HRs) may be:  - biased  - uninterpretable  - misleading (especially under non-proportional hazards)</p> <p>This chapter is a complete diagnostic toolkit for Cox regression in biostatistics, with both Python and R.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#1-what-assumptions-does-cox-ph-rely-on","title":"1. What assumptions does Cox PH rely on?","text":"<p>The Cox proportional hazards model is:</p> \\[ h(t|X)=h_0(t)\\exp(\\beta^TX) \\] <p>Main assumptions you must check:</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#a1-proportional-hazards-ph-most-important","title":"A1) Proportional hazards (PH) most important","text":"<p>Hazard ratios are constant over time:</p> \\[ \\frac{h(t \\mid X_a)}{h(t \\mid X_b)} = \\exp\\!\\left(\\beta^{\\mathsf T}(X_a - X_b)\\right) \\quad \\text{does not depend on } t \\]"},{"location":"Survival_Analysis/09-cox-diagnostics/#a2-correct-functional-form-for-continuous-predictors","title":"A2) Correct functional form for continuous predictors","text":"<p>Cox assumes a linear relationship in the log-hazard: $$ \\log h(t \\mid X) = \\log h_0(t) + \\beta_1 X_1 + \\cdots $$</p> <p>So a continuous predictor effect is assumed linear on log-hazard scale unless you model nonlinearity.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#a3-independent-observations-or-correctly-handled-clustering","title":"A3) Independent observations (or correctly handled clustering)","text":"<p>Patients in same hospital/site/family may be correlated.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#a4-no-extreme-outliers-or-overly-influential-observations","title":"A4) No extreme outliers or overly influential observations","text":"<p>One or two subjects shouldn\u2019t dominate your HR estimates.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#2-a-practical-diagnostic-checklist","title":"2. A practical diagnostic checklist","text":"<p>After fitting Cox:</p> <p>1) KM curves / visual check  2) PH test + Schoenfeld residual plots  3) Log(-log) survival plots (group PH check)  4) Functional form check for continuous predictors  5) Influential observations (dfbeta, deviance residuals)  6) Overall fit (concordance / C-index)  7) Robust SE / clustering check  8) Sensitivity analyses (alternative models if needed)</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#3-setup-create-a-working-dataset-python-r","title":"3. Setup: create a working dataset (Python + R)","text":"<p>We will simulate data with: - age (continuous) - treatment (binary) - optional PH violation example later</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#31-python-simulate-data","title":"3.1 Python: simulate data","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(2026)\n\nn = 500\nage = np.random.normal(60, 10, n)\ntrt = np.random.binomial(1, 0.5, n)\n\nbeta_age = 0.03\nbeta_trt = -0.50\nbase = 0.04\n\nhazard = base * np.exp(beta_age*age + beta_trt*trt)\nT = np.random.exponential(1/hazard)\nC = np.random.uniform(2, 25, n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event, \"age\": age, \"treatment\": trt})\ndf.head()\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#32-r-simulate-the-same-idea","title":"3.2 R: simulate the same idea","text":"<p>R</p> <pre><code>set.seed(2026)\n\nn &lt;- 500\nage &lt;- rnorm(n, mean=60, sd=10)\ntrt &lt;- rbinom(n, 1, 0.5)\n\nbeta_age &lt;- 0.03\nbeta_trt &lt;- -0.50\nbase &lt;- 0.04\n\nhazard &lt;- base * exp(beta_age*age + beta_trt*trt)\nT &lt;- rexp(n, rate = hazard)\nC &lt;- runif(n, min=2, max=25)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event, age=age, treatment=trt)\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#4-fit-cox-model-baseline-step","title":"4. Fit Cox model (baseline step)","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#41-python-fit-cox-lifelines","title":"4.1 Python: fit Cox (lifelines)","text":"<p>Python</p> <pre><code>from lifelines import CoxPHFitter\n\ncph = CoxPHFitter()\ncph.fit(df, duration_col=\"time\", event_col=\"event\")\ncph.print_summary()\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#42-r-fit-cox-survival","title":"4.2 R: fit Cox (survival)","text":"<p>R</p> <pre><code>library(survival)\n\nfit &lt;- coxph(Surv(time, event) ~ age + treatment, data=df)\nsummary(fit)\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#5-ph-assumption-checks","title":"5. PH assumption checks","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#51-visual-pre-check-km-curves-group-separation-and-crossing","title":"5.1 Visual pre-check: KM curves (group separation and crossing)","text":"<p>If curves strongly cross \u2192 PH likely violated.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python-km-curves","title":"Python (KM curves)","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nkm0 = KaplanMeierFitter()\nkm1 = KaplanMeierFitter()\n\nax = plt.subplot(111)\nkm0.fit(df.loc[df.treatment==0, \"time\"], df.loc[df.treatment==0, \"event\"], label=\"Control\").plot(ax=ax)\nkm1.fit(df.loc[df.treatment==1, \"time\"], df.loc[df.treatment==1, \"event\"], label=\"Treatment\").plot(ax=ax)\n\nplt.title(\"KM Curves by Treatment (quick PH visual)\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#r-km-curves","title":"R (KM curves)","text":"<p>R</p> <pre><code>fit_km &lt;- survfit(Surv(time, event) ~ factor(treatment), data=df)\n\nplot(fit_km, col=c(\"black\",\"red\"), lty=1,\n     xlab=\"Time\", ylab=\"S(t)\", main=\"KM Curves by Treatment\")\nlegend(\"topright\", legend=c(\"Control\",\"Treatment\"), col=c(\"black\",\"red\"), lty=1)\n</code></pre> <ul> <li>If curves are roughly separated without major crossing, PH is plausible.  </li> <li>If curves cross substantially, investigate PH violation formally.</li> </ul>"},{"location":"Survival_Analysis/09-cox-diagnostics/#52-schoenfeld-residual-test-formal-ph-test","title":"5.2 Schoenfeld residual test (formal PH test)","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#r-coxzph-gold-standard","title":"R: <code>cox.zph()</code> (gold standard)","text":"<p>R</p> <pre><code>z &lt;- cox.zph(fit)\nz\nplot(z)\n</code></pre> <p>Interpretation: - Each covariate gets a test. - Global test also reported. - Small p-value (&lt;0.05) \u2192 evidence PH violation.</p> <p>The plot shows residual trend over time: - Flat trend around 0 \u2192 good - Clear slope / curve \u2192 violation</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python-lifelines-check_assumptions","title":"Python: lifelines <code>check_assumptions()</code>","text":"<p>Python</p> <pre><code>cph.check_assumptions(df, show_plots=True)\n</code></pre> <p>Interpretation:  - lifelines prints warnings when PH is violated  - shows plots (Schoenfeld-type diagnostics)</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#53-log-log-survival-plots-classic-ph-visual-check-for-groups","title":"5.3 Log(-log) survival plots (classic PH visual check for groups)","text":"<p>If PH holds, log(-log(S(t))) curves for groups should be roughly parallel.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#r-log-log-plot","title":"R: log(-log) plot","text":"<p>R</p> <pre><code>library(survival)\n\nfit_km &lt;- survfit(Surv(time, event) ~ factor(treatment), data=df)\n\n# Extract survival curves\ns &lt;- summary(fit_km)\n\n# Compute log(-log(S))\nlls &lt;- log(-log(s$surv))\n\nplot(s$time, lls, type=\"n\",\n     xlab=\"Time\", ylab=\"log(-log(S(t)))\",\n     main=\"Log(-log) Survival Plot (PH visual check)\")\n\n# Two groups are stored sequentially; split by strata\nstrata_lengths &lt;- s$strata\n# A simpler approach: use survminer if available:\n</code></pre> <p>If you have <code>survminer</code>, this is easier:</p> <p>R</p> <pre><code>library(survminer)\n\nggsurvplot(fit_km, fun=\"cloglog\", conf.int=FALSE,\n           ggtheme=theme_minimal(),\n           title=\"Cloglog plot: log(-log(S(t)))\")\n</code></pre> <p>Interpretation:  - Parallel lines \u2192 PH plausible  - Non-parallel / crossing \u2192 PH questionable</p> <p>Python doesn\u2019t have a one-liner in lifelines for cloglog plots, but you can approximate by extracting survival estimates and plotting <code>np.log(-np.log(S))</code>.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#6-what-to-do-if-ph-is-violated","title":"6. What to do if PH is violated","text":"<p>PH violation is common. You have multiple solutions depending on the situation.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#option-1-add-time-interaction-time-varying-effect","title":"Option 1: Add time interaction (time-varying effect)","text":"<p>If treatment effect changes over time:</p> \\[ h(t)=h_0(t)\\exp(\\beta_1X + \\beta_2 X\\cdot g(t)) \\] <p>A simple choice: \\(g(t)=\\log(t)\\).</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#r-example-time-interaction-with-tt","title":"R example: time interaction with <code>tt()</code>","text":"<p>R</p> <pre><code>fit_tv &lt;- coxph(\n  Surv(time, event) ~ age + treatment + tt(treatment),\n  data=df,\n  tt = function(x, t, ...) x * log(t + 1)\n)\nsummary(fit_tv)\n</code></pre> <p>Interpretation: - Now treatment effect depends on time. - You don\u2019t report \u201cone HR\u201d; you interpret HR as a function of time.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python-approach","title":"Python approach","text":"<p>lifelines can do time-varying covariates using start\u2013stop format (covered in the time-dependent chapter). For PH violation, you can create an interaction variable such as <code>treatment * log(time)</code> and refit, but that is less principled unless properly formatted.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#option-2-stratified-cox","title":"Option 2: Stratified Cox","text":"<p>If a variable violates PH but you do NOT need its HR, stratify by it.</p> \\[ h(t|X)=h_{0,stratum}(t)\\exp(\\beta X) \\] <p>This allows different baseline hazards per stratum.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#r-stratification","title":"R: stratification","text":"<p>R</p> <pre><code># Example: stratify by treatment if you don't need HR for it\nfit_strat &lt;- coxph(Surv(time, event) ~ age + strata(treatment), data=df)\nsummary(fit_strat)\n</code></pre> <p>You lose HR estimate for the stratified variable, but PH becomes less problematic.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#option-3-use-alternative-summaries-rmst-or-parametric-models","title":"Option 3: Use alternative summaries (RMST) or parametric models","text":"<p>If PH is badly violated:  - Consider restricted mean survival time (RMST) (time-based effect)  - Consider parametric models that allow more flexible hazards</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#7-checking-functional-form-linearity-for-continuous-predictors","title":"7. Checking functional form (linearity) for continuous predictors","text":"<p>Cox assumes: $$ \\log h(t \\mid X) \\text{ is linear in } X $$</p> <p>If age effect is nonlinear (common!), a linear age term is wrong.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#71-martingale-residual-plots-classic-approach","title":"7.1 Martingale residual plots (classic approach)","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#r-martingale-residual-vs-age","title":"R: martingale residual vs age","text":"<p>R</p> <pre><code>mart &lt;- residuals(fit, type=\"martingale\")\n\nplot(df$age, mart,\n     xlab=\"Age\", ylab=\"Martingale residual\",\n     main=\"Martingale Residuals vs Age\")\nlines(lowess(df$age, mart), col=\"red\", lwd=2)\n</code></pre> <p>Interpretation: - random scatter around 0 \u2192 linear okay - curved LOWESS trend \u2192 nonlinearity</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python-lifelines-martingale-residuals","title":"Python (lifelines): martingale residuals","text":"<p>Python</p> <pre><code>mart = cph.compute_residuals(df, kind=\"martingale\")\n\nimport matplotlib.pyplot as plt\nplt.scatter(df[\"age\"], mart, alpha=0.6)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Martingale residual\")\nplt.title(\"Martingale Residuals vs Age\")\nplt.show()\n</code></pre> <p>(If your lifelines version returns a DataFrame, you may need <code>mart.values</code>.)</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#72-fixing-nonlinearity-splines-or-categories","title":"7.2 Fixing nonlinearity: splines or categories","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#r-natural-spline-with-splines","title":"R: natural spline with <code>splines</code>","text":"<p>R</p> <pre><code>library(splines)\n\nfit_spline &lt;- coxph(Surv(time, event) ~ ns(age, df=4) + treatment, data=df)\nsummary(fit_spline)\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python-transform-age-using-piecewise-terms-or-spline-libraries","title":"Python: transform age using piecewise terms or spline libraries","text":"<p>In pure lifelines, easiest is to: - create polynomial terms (<code>age</code>, <code>age^2</code>) - or bin age categories For full spline modeling, many analysts use <code>patsy</code> or <code>statsmodels</code> to build spline basis and then feed columns to lifelines.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#8-outliers-and-influential-observations","title":"8. Outliers and influential observations","text":"<p>Even if PH holds, a few subjects can dominate the model.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#81-deviance-residuals-outlier-detection","title":"8.1 Deviance residuals (outlier detection)","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#r","title":"R","text":"<p>R</p> <pre><code>dev &lt;- residuals(fit, type=\"deviance\")\n\nhist(dev, breaks=30, main=\"Deviance residuals\", xlab=\"Deviance residual\")\n</code></pre> <p>Large absolute values indicate potential outliers.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python","title":"Python","text":"<p>Python</p> <pre><code>dev = cph.compute_residuals(df, kind=\"deviance\")\n\nimport matplotlib.pyplot as plt\nplt.hist(dev, bins=30)\nplt.title(\"Deviance residuals\")\nplt.xlabel(\"Deviance residual\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#82-influence-dfbeta-how-much-each-subject-changes-coefficients","title":"8.2 Influence: dfbeta (how much each subject changes coefficients)","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#r-dfbeta","title":"R: dfbeta","text":"<p>R</p> <pre><code>dfb &lt;- residuals(fit, type=\"dfbeta\")\n\n# dfbeta is a matrix with one column per covariate\nmatplot(dfb, type=\"p\", pch=20, cex=0.6,\n        main=\"DFBETA by covariate\", ylab=\"DFBETA\")\nabline(h=0, col=\"grey\")\n</code></pre> <p>Subjects with extreme DFBETA values may have high influence.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python-influence-is-less-standardized-in-lifelines","title":"Python: influence is less standardized in lifelines","text":"<p>lifelines doesn\u2019t offer a perfect <code>dfbeta</code> equivalent in all versions. A practical approach: - fit model - refit leaving-one-out for suspected points (expensive but possible) - or inspect deviance residual extremes and investigate those IDs</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#9-overall-model-fit-and-predictive-ability-c-index","title":"9. Overall model fit and predictive ability (C-index)","text":"<p>Cox does not have an R\u00b2 like linear regression. Instead, common measure is:</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#concordance-index-c-index","title":"Concordance index (C-index)","text":"<ul> <li>0.5 = random prediction</li> <li>1.0 = perfect discrimination</li> </ul>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python_1","title":"Python","text":"<p>Python</p> <pre><code>cph.concordance_index_\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#r_1","title":"R","text":"<p><code>summary(fit)</code> reports concordance. Or extract:</p> <p>R</p> <pre><code>summary(fit)$concordance\n</code></pre> <p>Interpretation: - Higher is better, but values around 0.60\u20130.75 are common in medical data.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#10-robust-standard-errors-and-clustering","title":"10. Robust standard errors and clustering","text":"<p>If you have clustering (hospital/site/family), independence fails.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#101-robust-se-sandwich-quick-fix","title":"10.1 Robust SE (sandwich) \u2014 quick fix","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#r_2","title":"R","text":"<p>Use <code>cluster()</code> to get robust SE for clustered IDs.</p> <p>R</p> <pre><code># Suppose we have a cluster variable (e.g., hospital)\nset.seed(1)\ndf$hospital &lt;- sample(1:10, nrow(df), replace=TRUE)\n\nfit_cluster &lt;- coxph(Surv(time, event) ~ age + treatment + cluster(hospital), data=df)\nsummary(fit_cluster)\n</code></pre>"},{"location":"Survival_Analysis/09-cox-diagnostics/#python_2","title":"Python","text":"<p>lifelines supports <code>robust=True</code>:</p> <p>Python</p> <pre><code>cph_robust = CoxPHFitter()\ncph_robust.fit(df, duration_col=\"time\", event_col=\"event\", robust=True)\ncph_robust.print_summary()\n</code></pre> <p>Robust SE corrects inference (SE, CI), but does not model heterogeneity explicitly (frailty models do).</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#11-practical-ph-violation-simulation","title":"11. Practical \u201cPH violation\u201d simulation","text":"<p>To understand PH diagnostics, it helps to simulate data where treatment effect changes over time.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#111-r-simulate-crossing-hazards-and-test-ph","title":"11.1 R: simulate crossing hazards and test PH","text":"<p>R</p> <pre><code>set.seed(99)\nn &lt;- 400\ntrt &lt;- rbinom(n, 1, 0.5)\n\n# Create time-varying effect: treatment helps early, harms late\n# We'll simulate piecewise hazards:\n# early hazard: treatment reduces\n# late hazard: treatment increases\nt_change &lt;- 8\n\nbase1 &lt;- 0.06\nbase2 &lt;- 0.03\n\n# generate event time using simple rejection / piecewise approx\nT &lt;- rep(NA, n)\nfor (i in 1:n) {\n  # simulate early time\n  h1 &lt;- base1 * ifelse(trt[i]==1, 0.6, 1.0)\n  t1 &lt;- rexp(1, rate=h1)\n  if (t1 &lt; t_change) {\n    T[i] &lt;- t1\n  } else {\n    # survive past change point\n    h2 &lt;- base2 * ifelse(trt[i]==1, 1.6, 1.0)\n    t2 &lt;- rexp(1, rate=h2)\n    T[i] &lt;- t_change + t2\n  }\n}\n\nC &lt;- runif(n, 2, 20)\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\nd &lt;- data.frame(time=time, event=event, trt=trt)\n\nfit_np &lt;- coxph(Surv(time, event) ~ trt, data=d)\nsummary(fit_np)\n\nz &lt;- cox.zph(fit_np)\nz\nplot(z)\n</code></pre> <p>You should often see PH violation for <code>trt</code>.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#112-python-simulate-similar-idea-and-run-check_assumptions","title":"11.2 Python: simulate similar idea and run check_assumptions","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom lifelines import CoxPHFitter\n\nnp.random.seed(99)\nn = 400\ntrt = np.random.binomial(1, 0.5, n)\n\nt_change = 8.0\nbase1 = 0.06\nbase2 = 0.03\n\nT = np.zeros(n)\n\nfor i in range(n):\n    h1 = base1 * (0.6 if trt[i]==1 else 1.0)\n    t1 = np.random.exponential(1/h1)\n    if t1 &lt; t_change:\n        T[i] = t1\n    else:\n        h2 = base2 * (1.6 if trt[i]==1 else 1.0)\n        t2 = np.random.exponential(1/h2)\n        T[i] = t_change + t2\n\nC = np.random.uniform(2, 20, n)\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\nd = pd.DataFrame({\"time\": time, \"event\": event, \"treatment\": trt})\n\ncph_bad = CoxPHFitter()\ncph_bad.fit(d, duration_col=\"time\", event_col=\"event\")\ncph_bad.print_summary()\n\ncph_bad.check_assumptions(d, show_plots=True)\n</code></pre> <p>You should observe warnings/plots indicating PH violation.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#12-reporting-diagnostics-in-a-paper","title":"12. Reporting diagnostics in a paper","text":"<p>Examples of correct writing:</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#if-ph-holds","title":"If PH holds","text":"<p>\u201cProportional hazards assumption was assessed using Schoenfeld residuals and was not violated.\u201d</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#if-ph-violated-and-fixed","title":"If PH violated and fixed","text":"<p>\u201cThe proportional hazards assumption was violated for treatment (Schoenfeld p &lt; 0.05). A time-varying treatment effect was modeled using an interaction with log(time).\u201d</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#if-stratified","title":"If stratified","text":"<p>\u201cDue to PH violation for sex, models were stratified by sex.\u201d</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#13-common-mistakes","title":"13. Common mistakes","text":""},{"location":"Survival_Analysis/09-cox-diagnostics/#mistake-1-interpret-hr-without-checking-ph","title":"Mistake 1: Interpret HR without checking PH","text":"<p>Fix: Always run <code>cox.zph()</code> (R) or <code>check_assumptions()</code> (Python).</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#mistake-2-assume-linear-age-effect-automatically","title":"Mistake 2: Assume linear age effect automatically","text":"<p>Fix: martingale residual check, use splines if needed.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#mistake-3-ignore-clustering","title":"Mistake 3: Ignore clustering","text":"<p>Fix: robust SE or frailty.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#mistake-4-trust-extreme-late-follow-up","title":"Mistake 4: Trust extreme late follow-up","text":"<p>Fix: check number at risk and consider truncating analysis window.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#14-key-takeaway-summary","title":"14. Key takeaway summary","text":"<p>Cox diagnostics ensure:</p> <ul> <li>HRs are interpretable (PH)</li> <li>continuous covariates are modeled correctly (linearity)</li> <li>inference is valid (robust SE/clustering)</li> <li>results are not dominated by a few subjects (influence)</li> <li>model has acceptable predictive performance (C-index)</li> </ul> <p>If you remember only one thing:</p> <p># Fit Cox \u2192 always check PH \u2192 then interpret.</p>"},{"location":"Survival_Analysis/09-cox-diagnostics/#15-exercises-high-value-practice","title":"15. Exercises (high-value practice)","text":"Click to try   1. Fit Cox model in R and run `cox.zph()`. Which variables violate PH (if any)?    2. Make a dataset where treatment effect changes over time and confirm PH violation.    3. Use martingale residual plot to detect nonlinearity in age. Then refit with spline.    4. Create clustering (hospital variable) and compare standard SE vs robust SE.    5. Identify influential points via deviance residuals/dfbeta and refit after removing a few. Compare HR changes."},{"location":"Survival_Analysis/10-time-dependent-covariates/","title":"Time-Dependent Covariates (Extended Cox Model)","text":"<p>In many real clinical and epidemiological studies, covariates change over time.</p> <p>Examples:  - treatment starts later or changes dose  - biomarkers change (CD4 count, blood pressure, viral load)  - smoking status changes  - a patient becomes infected or vaccinated during follow-up  - hospital discharge changes risk of in-hospital outcomes</p> <p>Standard Cox assumes covariates are fixed:</p> \\[ X_i \\text{ is constant for the entire follow-up} \\] <p>When this is false, standard Cox can become biased\u2014sometimes severely.</p> <p>This chapter covers:</p> <ul> <li>what time-dependent covariates are  </li> <li>how to structure data correctly (start\u2013stop / counting process)  </li> <li>how to fit models in Python and R </li> <li>classic bias: immortal time bias </li> <li>how to interpret results correctly  </li> </ul>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#1-what-is-a-time-dependent-covariate","title":"1. What is a time-dependent covariate?","text":"<p>A time-dependent covariate is a covariate that depends on time:</p> \\[ X_i(t) \\] <p>Cox becomes:</p> \\[ h(t|X(t))=h_0(t)\\exp(\\beta^T X(t)) \\] <p>The model is still Cox PH\u2014same idea\u2014but covariates can update.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#2-two-concepts","title":"2. Two concepts","text":""},{"location":"Survival_Analysis/10-time-dependent-covariates/#21-time-dependent-covariate","title":"2.1 Time-dependent covariate","text":"<p>The covariate value changes over time.  Example:   - treatment: 0 before drug starts, 1 after drug starts</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#22-time-varying-effect-non-ph","title":"2.2 Time-varying effect (non-PH)","text":"<p>The effect of a covariate changes over time (PH violation).  Example:   - treatment HR = 0.6 early but 1.1 late</p> <p>These are different:  - Time-dependent covariate is about X(t)  - Time-varying effect is about \u03b2(t)</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#3-why-time-dependent-covariates-matter","title":"3. Why time-dependent covariates matter","text":""},{"location":"Survival_Analysis/10-time-dependent-covariates/#31-treatment-initiation-happens-after-baseline","title":"3.1 Treatment initiation happens after baseline","text":"<p>Example: observational study of statin use.</p> <p>If a patient starts statin at month 6, and we code:</p> <ul> <li><code>statin = 1</code> from time 0</li> </ul> <p>Then we falsely give the drug credit for survival during months 0\u20136 even though they weren\u2019t on it.</p> <p>This creates a major bias.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#4-immortal-time-bias","title":"4. Immortal time bias","text":"<p>Immortal time bias occurs when:</p> <p>to be classified as \u201ctreated\u201d, the subject must survive long enough to receive treatment.</p> <p>So early time becomes \u201cimmortal\u201d (event cannot occur before treatment starts if you require survival to receive it).</p> <p>If you label them as treated from baseline, you inflate treatment benefit.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#41-example","title":"4.1 Example","text":"<ul> <li>surgery at day 60</li> <li> <p>patient must survive 60 days to have surgery If you label surgery group at day 0:</p> </li> <li> <p>they appear to have better survival, partly because they had to survive long enough.</p> </li> </ul> <p>Correct fix: treat surgery status as time-dependent.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#5-correct-data-structure-startstop-counting-process","title":"5. Correct data structure: start\u2013stop (counting process)","text":"<p>Instead of one row per subject:</p> <p>| id | time | event | treatment |</p> <p>We use multiple rows:</p> <p>| id | start | stop | event | treatment |</p> <p>Each row represents a time interval where covariates are constant.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#6example-delayed-treatment","title":"6.Example: delayed treatment","text":"<p>A patient:  - enters at time 0  - starts treatment at time 5  - experiences event at time 10</p> <p>Correct representation:</p> id start stop event trt 1 0 5 0 0 1 5 10 1 1 <p>Now the model knows:  - untreated from 0 to 5  - treated from 5 to 10</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#7-practical-steps-to-build-time-dependent-dataset","title":"7. Practical steps to build time-dependent dataset","text":""},{"location":"Survival_Analysis/10-time-dependent-covariates/#step-1","title":"Step 1","text":"<p>Identify covariates that change (treatment start, biomarker measurement times)</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#step-2","title":"Step 2","text":"<p>Split each subject\u2019s follow-up into intervals</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#step-3","title":"Step 3","text":"<p>Create start\u2013stop rows with updated covariates</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#step-4","title":"Step 4","text":"<p>Fit extended Cox using start\u2013stop format</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#part-a-python-lifelines","title":"PART A \u2014 PYTHON (lifelines)","text":"<p>Python survival modeling with time-dependent covariates is typically done using:</p> <ul> <li><code>CoxTimeVaryingFitter</code> from lifelines</li> </ul>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#8a-simulate-a-delayed-treatment-dataset-python","title":"8A. Simulate a delayed treatment dataset (Python)","text":"<p>We simulate: - each subject has a treatment start time - before that they are untreated - after that they are treated - treatment reduces hazard</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(777)\n\nn = 200\n\n# Treatment start time (some start late, some early)\nt_start = np.random.uniform(1, 8, size=n)\n\n# baseline covariate\nage = np.random.normal(60, 10, n)\n\n# true effects\nbeta_age = 0.03\nbeta_trt = -0.60\n\nbase = 0.05\n\nrows = []\n\nfor i in range(n):\n    # hazard before treatment\n    h0 = base * np.exp(beta_age*age[i] + beta_trt*0)\n\n    # hazard after treatment\n    h1 = base * np.exp(beta_age*age[i] + beta_trt*1)\n\n    # simulate event time in two-stage piecewise exponential\n    t1 = np.random.exponential(1/h0)\n\n    if t1 &lt; t_start[i]:\n        # event occurs before treatment begins\n        event_time = t1\n        # one interval only: untreated\n        rows.append([i, 0, event_time, 1, 0, age[i]])\n    else:\n        # survived untreated period\n        # then simulate time after treatment\n        t2 = np.random.exponential(1/h1)\n        event_time = t_start[i] + t2\n\n        # censoring\n        censor = np.random.uniform(3, 15)\n\n        if event_time &lt;= censor:\n            # two intervals: untreated then treated; event in second\n            rows.append([i, 0, t_start[i], 0, 0, age[i]])\n            rows.append([i, t_start[i], event_time, 1, 1, age[i]])\n        else:\n            # censored in second interval\n            rows.append([i, 0, t_start[i], 0, 0, age[i]])\n            rows.append([i, t_start[i], censor, 0, 1, age[i]])\n\ntv = pd.DataFrame(rows, columns=[\"id\",\"start\",\"stop\",\"event\",\"treatment\",\"age\"])\ntv.head(10)\n</code></pre> <p>This is start\u2013stop format.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#9a-fit-time-dependent-cox-in-python","title":"9A. Fit time-dependent Cox in Python","text":"<p>Python</p> <pre><code>from lifelines import CoxTimeVaryingFitter\n\nctv = CoxTimeVaryingFitter()\nctv.fit(tv, id_col=\"id\", start_col=\"start\", stop_col=\"stop\", event_col=\"event\")\n\nctv.print_summary()\n</code></pre> <p>Interpretation: - <code>exp(coef)</code> for treatment is the hazard ratio comparing treated vs untreated at the same time.</p> <p>Expected: - HR &lt; 1 (protective)</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#10a-what-happens-if-we-do-it-wrong-baseline-treatment-only","title":"10A. What happens if we do it WRONG (baseline treatment only)","text":"<p>Wrong approach: - label treated if they ever got treatment - then fit standard Cox</p> <p>This creates immortal time bias.</p> <p>Python</p> <pre><code># Collapse to one row per person\nbaseline = tv.groupby(\"id\").agg(\n    time=(\"stop\",\"max\"),\n    event=(\"event\",\"max\"),\n    age=(\"age\",\"first\"),\n    ever_treated=(\"treatment\",\"max\")\n).reset_index()\n\nfrom lifelines import CoxPHFitter\ncph_wrong = CoxPHFitter()\ncph_wrong.fit(baseline[[\"time\",\"event\",\"age\",\"ever_treated\"]], duration_col=\"time\", event_col=\"event\")\n\ncph_wrong.print_summary()\n</code></pre> <p>Compare HR from: - time-dependent model (correct) - baseline ever-treated Cox (wrong)</p> <p>You will usually see the wrong model make treatment look more protective than it truly is.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#part-b-r-survival","title":"PART B \u2014 R (survival)","text":"<p>In R, time-dependent covariates are handled using:</p> <ul> <li><code>coxph()</code> with <code>Surv(start, stop, event)</code> form (i.e., counting-process notation)</li> </ul>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#11b-simulate-delayed-treatment-dataset-in-r","title":"11B. Simulate delayed treatment dataset in R","text":"<p>R</p> <pre><code>set.seed(777)\n\nn &lt;- 200\n\nt_start &lt;- runif(n, 1, 8)\nage &lt;- rnorm(n, 60, 10)\n\nbeta_age &lt;- 0.03\nbeta_trt &lt;- -0.60\nbase &lt;- 0.05\n\nrows &lt;- list()\nidx &lt;- 1\n\nfor (i in 1:n) {\n\n  h0 &lt;- base * exp(beta_age*age[i] + beta_trt*0)\n  h1 &lt;- base * exp(beta_age*age[i] + beta_trt*1)\n\n  t1 &lt;- rexp(1, rate = h0)\n\n  if (t1 &lt; t_start[i]) {\n    event_time &lt;- t1\n    rows[[idx]] &lt;- data.frame(id=i, start=0, stop=event_time, event=1,\n                              treatment=0, age=age[i])\n    idx &lt;- idx + 1\n  } else {\n\n    t2 &lt;- rexp(1, rate = h1)\n    event_time &lt;- t_start[i] + t2\n    censor &lt;- runif(1, 3, 15)\n\n    if (event_time &lt;= censor) {\n      rows[[idx]] &lt;- data.frame(id=i, start=0, stop=t_start[i], event=0,\n                                treatment=0, age=age[i]); idx &lt;- idx + 1\n      rows[[idx]] &lt;- data.frame(id=i, start=t_start[i], stop=event_time, event=1,\n                                treatment=1, age=age[i]); idx &lt;- idx + 1\n    } else {\n      rows[[idx]] &lt;- data.frame(id=i, start=0, stop=t_start[i], event=0,\n                                treatment=0, age=age[i]); idx &lt;- idx + 1\n      rows[[idx]] &lt;- data.frame(id=i, start=t_start[i], stop=censor, event=0,\n                                treatment=1, age=age[i]); idx &lt;- idx + 1\n    }\n  }\n}\n\ntv &lt;- do.call(rbind, rows)\nhead(tv, 10)\n</code></pre>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#12b-fit-time-dependent-cox-in-r","title":"12B. Fit time-dependent Cox in R","text":"<p>Use:</p> \\[ Surv(start, stop, event) \\] <p>R</p> <pre><code>library(survival)\n\nfit_td &lt;- coxph(Surv(start, stop, event) ~ age + treatment, data=tv)\nsummary(fit_td)\n</code></pre> <p>Interpretation: - <code>exp(coef)</code> for treatment is HR comparing treated vs untreated intervals.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#13b-wrong-baseline-ever-treated-model-in-r","title":"13B. WRONG baseline ever-treated model in R","text":"<p>R</p> <pre><code>baseline &lt;- aggregate(cbind(stop, event, treatment, age) ~ id, data=tv,\n                      FUN=function(x) x[1])\n\n# baseline time is max stop per id\ntime_max &lt;- aggregate(stop ~ id, data=tv, FUN=max)\n\nbaseline$time &lt;- time_max$stop\nbaseline$event &lt;- aggregate(event ~ id, data=tv, FUN=max)$event\nbaseline$ever_treated &lt;- aggregate(treatment ~ id, data=tv, FUN=max)$treatment\n\nfit_wrong &lt;- coxph(Surv(time, event) ~ age + ever_treated, data=baseline)\nsummary(fit_wrong)\n</code></pre> <p>Compare: - <code>fit_td</code> (correct) - <code>fit_wrong</code> (biased)</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#14-interpretation-rules","title":"14. Interpretation rules","text":""},{"location":"Survival_Analysis/10-time-dependent-covariates/#141-treatment-hr-in-time-dependent-cox","title":"14.1 Treatment HR in time-dependent Cox","text":"<p>HR compares: - hazard when currently treated vs - hazard when currently untreated</p> <p>It does NOT compare \u201cever treated\u201d vs \u201cnever treated\u201d.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#142-time-dependent-biomarker-eg-cd4-count","title":"14.2 Time-dependent biomarker (e.g., CD4 count)","text":"<p>If CD4 changes over time, you model:</p> \\[ h(t)=h_0(t)\\exp(\\beta \\cdot CD4(t)) \\] <p>Interpretation: - at time t, higher CD4 is associated with lower/higher hazard.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#15-common-scenarios","title":"15. Common scenarios","text":""},{"location":"Survival_Analysis/10-time-dependent-covariates/#151-treatment-switching","title":"15.1 Treatment switching","text":"<p>Patients may:  - stop drug  - start new drug  - change dose</p> <p>Time-dependent Cox handles this by updating treatment status across intervals.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#152-longitudinal-biomarkers","title":"15.2 Longitudinal biomarkers","text":"<p>If measurements occur at repeated visits:  - split follow-up at visit times  - carry-forward biomarker value until next measurement</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#16-common-mistakes","title":"16. Common mistakes","text":""},{"location":"Survival_Analysis/10-time-dependent-covariates/#mistake-1-coding-ever-treated-as-baseline","title":"Mistake 1: coding \u201cever treated\u201d as baseline","text":"<p>\u2192 immortal time bias</p> <p>Fix: use start\u2013stop data and time-dependent treatment variable.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#mistake-2-using-event-time-itself-to-define-covariate-reverse-causality","title":"Mistake 2: using event time itself to define covariate (reverse causality)","text":"<p>Example:  - covariate measured after event  This can create bias.</p> <p>Fix: ensure covariate values are known BEFORE each interval.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#mistake-3-too-many-splits-without-reason","title":"Mistake 3: too many splits without reason","text":"<p>Very fine splitting can become heavy computationally.</p> <p>Fix: split only when covariates change or at visit times.</p>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#17-key-takeaways","title":"17. Key takeaways","text":"<ul> <li>Time-dependent covariates are covariates \\(X(t)\\) that change over time.</li> <li>Use start\u2013stop (counting-process) format.</li> <li>Extended Cox handles delayed treatment and longitudinal predictors correctly.</li> <li>Avoid immortal time bias by not using baseline \u201cever treated.\u201d</li> <li>Interpretation is about current covariate value at time t.</li> </ul>"},{"location":"Survival_Analysis/10-time-dependent-covariates/#18-exercises","title":"18. Exercises","text":"Click to try   1. Simulate delayed treatment and compare HR from correct time-dependent Cox vs wrong baseline ever-treated Cox.    2. Add a biomarker measured every 3 months; create start\u2013stop intervals and fit model.    3. Create treatment switching (0\u21921\u21920) and model it.    4. In R, fit time-dependent Cox with `Surv(start, stop, event)`. Confirm matches Python results.    5. Explain immortal time bias in one paragraph with a real clinical example."},{"location":"Survival_Analysis/11-parametric-survival-models/","title":"Parametric Survival Models (Exponential, Weibull, Log-normal, AFT)","text":"<p>So far you\u2019ve learned:</p> <ul> <li>Kaplan\u2013Meier (nonparametric)</li> <li>Cox regression (semi-parametric)</li> </ul> <p>Both are powerful, but sometimes we need:</p> <ul> <li>smooth survival curves  </li> <li>explicit survival formulas  </li> <li>extrapolation beyond observed follow-up  </li> <li>simulation and prediction  </li> <li>health-economic modeling  </li> </ul> <p>For these, we use:</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#parametric-survival-models","title":"Parametric Survival Models","text":"<p>Parametric survival models assume survival times follow a known distribution:</p> \\[ T \\sim \\text{some distribution} \\] <p>Examples: - Exponential - Weibull - Log-normal - Log-logistic</p> <p>This chapter gives maximum clarity + interactive code in Python and R.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#1-big-picture-why-parametric-models","title":"1. Big picture: why parametric models?","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#11-limitations-of-cox","title":"1.1 Limitations of Cox","text":"<p>Cox does not specify \\(h_0(t)\\), so:</p> <ul> <li>baseline hazard unknown</li> <li>extrapolation beyond observed time is unreliable</li> <li>simulations require extra steps</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#12-advantages-of-parametric-models","title":"1.2 Advantages of parametric models","text":"<p>Parametric models give:</p> <ul> <li>closed-form \\(S(t)\\) and \\(h(t)\\) </li> <li>smoother and more stable estimates  </li> <li>extrapolation (common in HTA, cost-effectiveness)  </li> <li>efficient estimation when distribution fits well  </li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#13-trade-off","title":"1.3 Trade-off","text":"<p>You gain structure but lose flexibility:</p> <ul> <li>If distribution is wrong \u2192 bias</li> <li>Must check fit carefully</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#2-two-modeling-frameworks-ph-vs-aft","title":"2. Two modeling frameworks: PH vs AFT","text":"<p>Many parametric models can be expressed as:</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#21-proportional-hazards-ph-form","title":"2.1 Proportional Hazards (PH) form","text":"<p>Similar interpretation to Cox:</p> \\[ h(t|X)=h_0(t)\\exp(\\beta^TX) \\] <p>Hazard ratio is constant over time.</p> <p>Common PH parametric models: - Exponential PH - Weibull PH</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#22-accelerated-failure-time-aft-form","title":"2.2 Accelerated Failure Time (AFT) form","text":"<p>Models time directly:</p> \\[ \\log(T)=\\beta^TX+\\epsilon \\] <p>Effect is interpreted using time ratios:</p> \\[ TR=\\exp(\\beta) \\] <p>Meaning: - TR &gt; 1 \u2192 longer survival time - TR &lt; 1 \u2192 shorter survival time</p> <p>Common AFT models: - Weibull AFT - Log-normal AFT - Log-logistic AFT</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#3-exponential-model","title":"3. Exponential model","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#31-assumption","title":"3.1 Assumption","text":"<p>Hazard is constant:</p> \\[ h(t)=\\lambda \\]"},{"location":"Survival_Analysis/11-parametric-survival-models/#32-survival-function","title":"3.2 Survival function","text":"\\[ S(t)=\\exp(-\\lambda t) \\]"},{"location":"Survival_Analysis/11-parametric-survival-models/#33-interpretation","title":"3.3 Interpretation","text":"<ul> <li>risk does not change over time</li> <li>often unrealistic in humans</li> </ul> <p>Clinical contexts where exponential might be plausible:  - device failure with constant rate  - short follow-up where hazard seems flat</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#4-weibull-model","title":"4. Weibull model","text":"<p>Weibull is the survival distribution you will see most often in biostatistics.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#41-weibull-survival","title":"4.1 Weibull survival","text":"\\[ S(t)=\\exp\\left(-\\left(\\frac{t}{\\lambda}\\right)^k\\right) \\] <ul> <li>\\(k\\) = shape</li> <li>\\(\\lambda\\) = scale</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#42-weibull-hazard","title":"4.2 Weibull hazard","text":"\\[ h(t)=\\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1} \\]"},{"location":"Survival_Analysis/11-parametric-survival-models/#43-why-weibull-is-special","title":"4.3 Why Weibull is special","text":"<p>Weibull can model different hazard shapes:</p> <ul> <li>\\(k=1\\) \u2192 constant hazard (exponential)</li> <li>\\(k&gt;1\\) \u2192 increasing hazard</li> <li>\\(k&lt;1\\) \u2192 decreasing hazard</li> </ul> <p>So Weibull is flexible and extremely useful.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#5-log-normal-model","title":"5. Log-normal model","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#51-assumption","title":"5.1 Assumption","text":"\\[ \\log(T)\\sim N(\\mu,\\sigma^2) \\]"},{"location":"Survival_Analysis/11-parametric-survival-models/#52-hazard-shape","title":"5.2 Hazard shape","text":"<p>Log-normal hazard is non-monotonic:</p> <ul> <li>rises early</li> <li>peaks</li> <li>declines</li> </ul> <p>Useful when:  - early risk is high (post-surgery) - later risk declines</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#6-log-logistic-model","title":"6. Log-logistic model","text":"<p>Similar to log-normal but with heavier tails.</p> <ul> <li>non-monotonic hazard</li> <li>sometimes better for very long survivors</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#7-choosing-among-parametric-models-practical-approach","title":"7. Choosing among parametric models (practical approach)","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#71-fit-multiple-models-and-compare","title":"7.1 Fit multiple models and compare","text":"<p>Common criteria:  - AIC  - BIC  - likelihood  - visual fit to KM</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#72-general-rule-of-thumb","title":"7.2 General rule of thumb","text":"<ul> <li>start with Weibull</li> <li>compare with log-normal/log-logistic</li> <li>consider exponential only if hazard looks flat</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#part-a-python-lifelines","title":"PART A \u2014 PYTHON (lifelines)","text":"<p>Python parametric survival modeling is commonly done using <code>lifelines</code>.</p> <p>We will:  1) simulate survival data  2) fit exponential / Weibull / log-normal  3) compare AIC  4) plot model fits against KM  5) fit AFT regression model  </p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#8a-simulate-survival-data-python","title":"8A. Simulate survival data (Python)","text":"<p>We simulate Weibull survival with covariate effect:</p> <ul> <li>age increases hazard</li> <li>treatment improves survival</li> </ul> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(44)\n\nn = 400\nage = np.random.normal(60, 10, n)\ntrt = np.random.binomial(1, 0.5, n)\n\n# True AFT-type generation (log-time shift)\n# We'll create baseline Weibull event times then accelerate by covariates\nshape_k = 1.7\nscale_lam = 12.0\n\n# Generate baseline Weibull times\nU = np.random.uniform(size=n)\nT0 = scale_lam * (-np.log(U))**(1/shape_k)\n\n# Covariate effects on log-time (AFT): treatment increases time, age decreases\nbeta_trt = 0.35   # TR = exp(0.35)=1.42\nbeta_age = -0.01  # per year TR = exp(-0.01)=0.99\n\nT = T0 * np.exp(beta_trt*trt + beta_age*(age-60))\n\n# Censoring\nC = np.random.uniform(3, 20, n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event, \"age\": age, \"treatment\": trt})\ndf.head()\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#9a-fit-nonparametric-km-reference-curve","title":"9A. Fit nonparametric KM (reference curve)","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nkm = KaplanMeierFitter().fit(df[\"time\"], df[\"event\"], label=\"KM\")\n\nax = km.plot(ci_show=False)\nplt.title(\"KM Curve (Reference)\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#10a-fit-parametric-models-python","title":"10A. Fit parametric models (Python)","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#10a1-exponential-weibull-log-normal","title":"10A.1 Exponential, Weibull, Log-normal","text":"<p>Python</p> <pre><code>from lifelines import ExponentialFitter, WeibullFitter, LogNormalFitter\n\nexpf = ExponentialFitter().fit(df[\"time\"], df[\"event\"])\nwf   = WeibullFitter().fit(df[\"time\"], df[\"event\"])\nlnf  = LogNormalFitter().fit(df[\"time\"], df[\"event\"])\n\nprint(\"AIC comparison (lower is better):\")\nprint(\"Exponential AIC:\", expf.AIC_)\nprint(\"Weibull AIC    :\", wf.AIC_)\nprint(\"LogNormal AIC  :\", lnf.AIC_)\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#10a2-plot-fitted-curves-vs-km","title":"10A.2 Plot fitted curves vs KM","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\n\nax = km.plot(ci_show=False)\n\nexpf.plot_survival_function(ax=ax, ci_show=False)\nwf.plot_survival_function(ax=ax, ci_show=False)\nlnf.plot_survival_function(ax=ax, ci_show=False)\n\nplt.title(\"KM vs Parametric Fits\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.show()\n</code></pre> <p>Interpretation:  - Best-fitting model tends to track KM curve more closely.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#11a-regression-weibull-aft-model-python","title":"11A. Regression: Weibull AFT model (Python)","text":"<p>Lifelines supports AFT regression models.</p> <p>Python</p> <pre><code>from lifelines import WeibullAFTFitter\n\naft = WeibullAFTFitter()\naft.fit(df, duration_col=\"time\", event_col=\"event\")\naft.print_summary()\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#11a1-interpretation-time-ratios","title":"11A.1 Interpretation: Time Ratios","text":"<p>In AFT models, exponentiated coefficients are time ratios:</p> <ul> <li>TR &gt; 1 \u2192 longer survival time</li> <li>TR &lt; 1 \u2192 shorter survival time</li> </ul> <p>Example:  - TR = 1.40 for treatment \u2192 treated survive 40% longer (on average, depending on model)</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#12a-predicted-survival-curves-for-profiles-python","title":"12A. Predicted survival curves for profiles (Python)","text":"<p>Python</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\np_control = pd.DataFrame({\"age\":[60], \"treatment\":[0]})\np_treated = pd.DataFrame({\"age\":[60], \"treatment\":[1]})\n\ns0 = aft.predict_survival_function(p_control)\ns1 = aft.predict_survival_function(p_treated)\n\nplt.plot(s0, label=\"Control (age=60)\")\nplt.plot(s1, label=\"Treatment (age=60)\")\nplt.title(\"Predicted Survival (Weibull AFT)\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"S(t)\")\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#part-b-r-survival-flexsurv","title":"PART B \u2014 R (survival + flexsurv)","text":"<p>In R, parametric survival models are commonly fit using:</p> <ul> <li><code>survreg()</code> (AFT models)</li> <li><code>flexsurv</code> package (highly recommended for multiple distributions + AIC comparison)</li> </ul> <p>We provide both.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#13b-simulate-data-in-r-same-structure","title":"13B. Simulate data in R (same structure)","text":"<p>R</p> <pre><code>set.seed(44)\n\nn &lt;- 400\nage &lt;- rnorm(n, 60, 10)\ntrt &lt;- rbinom(n, 1, 0.5)\n\nshape_k &lt;- 1.7\nscale_lam &lt;- 12\n\nU &lt;- runif(n)\nT0 &lt;- scale_lam * (-log(U))^(1/shape_k)\n\nbeta_trt &lt;- 0.35\nbeta_age &lt;- -0.01\n\nT &lt;- T0 * exp(beta_trt*trt + beta_age*(age-60))\n\nC &lt;- runif(n, 3, 20)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event, age=age, treatment=trt)\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#14b-km-curve-in-r-reference","title":"14B. KM curve in R (reference)","text":"<p>R</p> <pre><code>library(survival)\n\nkm &lt;- survfit(Surv(time, event) ~ 1, data=df)\nplot(km, xlab=\"Time\", ylab=\"S(t)\", main=\"KM Curve (Reference)\")\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#15b-aft-regression-models-using-survreg","title":"15B. AFT regression models using survreg()","text":"<p><code>survreg()</code> fits AFT models.</p> <p>Common distributions: - Weibull - lognormal - loglogistic</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#15b1-weibull-aft","title":"15B.1 Weibull AFT","text":"<p>R</p> <pre><code>fit_weib &lt;- survreg(Surv(time, event) ~ age + treatment, data=df, dist=\"weibull\")\nsummary(fit_weib)\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#interpretation-in-survreg","title":"Interpretation in survreg","text":"<p><code>survreg()</code> uses a different parameterization:</p> <ul> <li>coefficients relate to log(time) directly</li> <li>sign interpretation can be reversed compared to hazard models</li> </ul> <p>A simple practical interpretation:  - Positive coefficient \u2192 increases survival time  - Negative coefficient \u2192 decreases survival time</p> <p>To compute time ratio: $$ TR = \\exp(\\beta) $$</p> <p>R</p> <pre><code>exp(coef(fit_weib))\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#15b2-log-normal-aft","title":"15B.2 Log-normal AFT","text":"<p>R</p> <pre><code>fit_logn &lt;- survreg(Surv(time, event) ~ age + treatment, data=df, dist=\"lognormal\")\nsummary(fit_logn)\nexp(coef(fit_logn))\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#15b3-log-logistic-aft","title":"15B.3 Log-logistic AFT","text":"<p>R</p> <pre><code>fit_loglog &lt;- survreg(Surv(time, event) ~ age + treatment, data=df, dist=\"loglogistic\")\nsummary(fit_loglog)\nexp(coef(fit_loglog))\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#16b-model-comparison-using-aic-r","title":"16B. Model comparison using AIC (R)","text":"<p>R</p> <pre><code>AIC(fit_weib, fit_logn, fit_loglog)\n</code></pre> <p>Lower AIC = better tradeoff between fit and complexity.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#17b-using-flexsurv-for-many-distributions","title":"17B. Using flexsurv for many distributions","text":"<p><code>flexsurvreg()</code> gives access to:  - exponential  - Weibull  - lognormal  - loglogistic  - Gompertz, etc.</p> <p>R</p> <pre><code># install.packages(\"flexsurv\") # if needed\nlibrary(flexsurv)\n\nf_exp &lt;- flexsurvreg(Surv(time, event) ~ age + treatment, data=df, dist=\"exp\")\nf_weib &lt;- flexsurvreg(Surv(time, event) ~ age + treatment, data=df, dist=\"weibull\")\nf_logn &lt;- flexsurvreg(Surv(time, event) ~ age + treatment, data=df, dist=\"lognormal\")\nf_llog &lt;- flexsurvreg(Surv(time, event) ~ age + treatment, data=df, dist=\"llogis\")\n\nAIC(f_exp, f_weib, f_logn, f_llog)\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#18b-plot-fitted-parametric-curves-vs-km-r","title":"18B. Plot fitted parametric curves vs KM (R)","text":"<p>With <code>flexsurv</code>, easiest is to overlay predicted survival.</p> <p>R</p> <pre><code>plot(km, xlab=\"Time\", ylab=\"S(t)\", main=\"KM vs Parametric Fits\", col=\"black\")\n\n# Overlay parametric fit for \"average\" covariate profile:\nnd &lt;- data.frame(age=60, treatment=0)\n\nlines(f_exp, newdata=nd, type=\"survival\", col=\"blue\")\nlines(f_weib, newdata=nd, type=\"survival\", col=\"red\")\nlines(f_logn, newdata=nd, type=\"survival\", col=\"green\")\nlines(f_llog, newdata=nd, type=\"survival\", col=\"purple\")\n\nlegend(\"topright\",\n       legend=c(\"KM\",\"Exp\",\"Weibull\",\"LogNormal\",\"LogLogistic\"),\n       col=c(\"black\",\"blue\",\"red\",\"green\",\"purple\"), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/11-parametric-survival-models/#19-how-to-interpret-outputs","title":"19. How to interpret outputs","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#191-ph-hazard-ratio-interpretation","title":"19.1 PH (hazard ratio) interpretation","text":"<p>If using PH form (e.g., Weibull PH):</p> <ul> <li>HR &lt; 1 \u2192 lower hazard</li> <li>HR &gt; 1 \u2192 higher hazard</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#192-aft-interpretation-time-ratio","title":"19.2 AFT interpretation (time ratio)","text":"<p>If using AFT form:</p> <ul> <li>TR = 1.40 \u2192 40% longer survival time</li> <li>TR = 0.80 \u2192 20% shorter survival time</li> </ul> <p>AFT is often easier to interpret for clinicians.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#20-when-to-use-parametric-models","title":"20. When to use parametric models","text":"<p>Use parametric models when you need:</p> <ul> <li>extrapolation beyond follow-up  </li> <li>smooth survival curve + clear formula  </li> <li>simulation / risk prediction  </li> <li>cost-effectiveness modeling  </li> </ul> <p>Avoid if:  - hazard shape unknown and complex  - strong non-PH patterns and poor fit</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#21-reporting-in-biostat-papers","title":"21. Reporting in biostat papers","text":"<p>Example parametric report:</p> <p>\u201cA Weibull AFT model adjusting for age showed that treatment prolonged survival (time ratio 1.42, 95% CI \u2026). Model fit was assessed by AIC and visual comparison to Kaplan\u2013Meier curves.\u201d</p> <p>Or PH form:</p> <p>\u201cA Weibull proportional hazards model estimated treatment HR 0.68 (95% CI \u2026).\u201d</p> <p>Always specify:  - distribution used  - model form (PH or AFT)  - interpretation (HR or TR)  - fit assessment method (AIC, plots)</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#22-common-mistakes","title":"22. Common mistakes","text":""},{"location":"Survival_Analysis/11-parametric-survival-models/#mistake-1-assuming-exponential-without-checking","title":"Mistake 1: assuming exponential without checking","text":"<p>Exponential assumes constant hazard\u2014often wrong.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#mistake-2-choosing-distribution-only-by-aic","title":"Mistake 2: choosing distribution only by AIC","text":"<p>Also check:  - KM overlay fit  - clinical plausibility of hazard shape</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#mistake-3-interpreting-aft-coefficient-as-hazard-ratio","title":"Mistake 3: interpreting AFT coefficient as hazard ratio","text":"<p>AFT outputs time ratios, not HR.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#mistake-4-extrapolating-too-far","title":"Mistake 4: extrapolating too far","text":"<p>Even parametric extrapolation can be unrealistic.  Always justify extrapolation window.</p>"},{"location":"Survival_Analysis/11-parametric-survival-models/#23-key-takeaways","title":"23. Key takeaways","text":"<ul> <li>Parametric survival models assume a distribution for \\(T\\).</li> <li>Exponential = constant hazard.</li> <li>Weibull = flexible hazard (increasing/decreasing).</li> <li>Log-normal/log-logistic = non-monotonic hazards.</li> <li>Model selection via AIC + visual KM overlay.</li> <li>Regression can be PH or AFT; interpret HR vs TR correctly.</li> </ul>"},{"location":"Survival_Analysis/11-parametric-survival-models/#24-exercises","title":"24. Exercises","text":"Click to try   1. Fit exponential and Weibull models and compare AIC. Which fits better?    2. Overlay fitted curves with KM and discuss which curve matches best.    3. Fit Weibull AFT regression and interpret treatment as a time ratio.    4. In R, fit log-normal and log-logistic and compare AIC.    5. Simulate data with decreasing hazard (\\(k&lt;1\\)) and see which parametric model fits best."},{"location":"Survival_Analysis/12-competing-risks/","title":"Competing Risks (CIF, Cause-Specific Hazards, Fine\u2013Gray)","text":"<p>In many medical studies, subjects can fail from different causes.</p> <p>Example (oncology):  - Event of interest: relapse  - Competing event: death before relapse</p> <p>If a patient dies, they can no longer relapse.</p> <p>So death competes with relapse.</p> <p>This changes the meaning of \u201crisk\u201d and breaks naive Kaplan\u2013Meier.</p> <p>This chapter gives maximum clarity on:</p> <ul> <li>why KM is wrong under competing risks  </li> <li>cumulative incidence function (CIF)  </li> <li>cause-specific hazard models  </li> <li>Fine\u2013Gray subdistribution hazard model  </li> <li>interpretation and reporting  </li> <li>Python + R code with plots  </li> </ul>"},{"location":"Survival_Analysis/12-competing-risks/#1-what-is-a-competing-risk","title":"1. What is a competing risk?","text":"<p>A competing risk is an event that:</p> <p>1) prevents the event of interest from happening, and  2) is not just censoring.</p>"},{"location":"Survival_Analysis/12-competing-risks/#11-example","title":"1.1 Example","text":"<p>Event of interest: relapse Competing event: death</p> <p>If death happens, relapse can never occur afterwards.</p> <p>So death is not \u201ccensoring\u201d \u2014 it is a different event that removes the possibility of relapse.</p>"},{"location":"Survival_Analysis/12-competing-risks/#2-why-kaplanmeier-is-wrong-for-competing-risks","title":"2. Why Kaplan\u2013Meier is wrong for competing risks","text":"<p>KM assumes that censoring is non-informative:</p> <p>censored subjects are like those still at risk</p> <p>But in competing risks:</p> <ul> <li>a competing event is not \u201clike censoring\u201d</li> <li>it changes the probability structure</li> </ul> <p>If you treat competing events as censored:</p> <ul> <li>KM overestimates probability of event of interest.</li> </ul> <p>Because KM assumes those who died could still relapse later, which is impossible.</p>"},{"location":"Survival_Analysis/12-competing-risks/#3-the-correct-probability-cumulative-incidence-function-cif","title":"3. The correct probability: cumulative incidence function (CIF)","text":""},{"location":"Survival_Analysis/12-competing-risks/#31-definition","title":"3.1 Definition","text":"<p>For event type \\(k\\):</p> \\[ F_k(t) = P(T \\le t,\\ \\text{event}=k) \\] <p>Interpretation:</p> <p>Probability of experiencing event type \\(k\\) by time \\(t\\), accounting for competing events.</p> <p>This is the correct function to report when competing risks exist.</p>"},{"location":"Survival_Analysis/12-competing-risks/#32-relationship","title":"3.2 Relationship","text":"<p>If there are K event types:</p> \\[ S(t) + \\sum_{k=1}^K F_k(t) = 1 \\] <p>Where:  - \\(S(t)\\) = probability of no event yet  - \\(F_k(t)\\) = probability of event k by time t</p>"},{"location":"Survival_Analysis/12-competing-risks/#4-two-ways-to-model-competing-risks","title":"4. Two ways to model competing risks","text":""},{"location":"Survival_Analysis/12-competing-risks/#41-cause-specific-hazards-csh","title":"4.1 Cause-specific hazards (CSH)","text":"<p>Model hazard of event k while treating other causes as censored.</p> <p>This answers:</p> <p>\u201cAmong those currently event-free, what is the instantaneous hazard of event k?\u201d</p> <p>Good for etiologic questions and mechanisms.</p>"},{"location":"Survival_Analysis/12-competing-risks/#42-finegray-subdistribution-hazard-sdh","title":"4.2 Fine\u2013Gray subdistribution hazard (SDH)","text":"<p>Models the hazard of the CIF directly.</p> <p>This answers:</p> <p>\u201cHow do covariates affect the cumulative incidence probability of event k over time?\u201d</p> <p>Good for prognosis and absolute risk prediction.</p>"},{"location":"Survival_Analysis/12-competing-risks/#5-cause-specific-hazard-model-csh","title":"5. Cause-specific hazard model (CSH)","text":"<p>For event type k:</p> \\[ h_k(t|X)=h_{0k}(t)\\exp(\\beta_k^TX) \\] <p>Interpretation of HR:</p> <p>HR compares instantaneous hazard of cause k among those still event-free.</p> <p>Important:  - This HR is NOT directly a HR on CIF probability.  - HR on cause-specific hazard and Fine\u2013Gray can differ.</p>"},{"location":"Survival_Analysis/12-competing-risks/#6-finegray-model-subdistribution-hazard","title":"6. Fine\u2013Gray model (subdistribution hazard)","text":"<p>Fine\u2013Gray models subdistribution hazard:</p> \\[ \\tilde h_k(t|X)=\\tilde h_{0k}(t)\\exp(\\gamma^TX) \\] <p>Interpretation:</p> <p>HR describes relative rate of accumulating event-k incidence over time, accounting for competing events.</p> <p>This is often interpreted as:</p> <ul> <li>covariate increases/decreases cumulative incidence probability.</li> </ul>"},{"location":"Survival_Analysis/12-competing-risks/#7-when-to-use-which-model","title":"7. When to use which model?","text":""},{"location":"Survival_Analysis/12-competing-risks/#use-cause-specific-cox-when","title":"Use cause-specific Cox when:","text":"<ul> <li>scientific question is about biological mechanism</li> <li>\u201cdoes treatment reduce relapse hazard among those alive?\u201d</li> <li>you want hazard-based interpretation</li> </ul>"},{"location":"Survival_Analysis/12-competing-risks/#use-finegray-when","title":"Use Fine\u2013Gray when:","text":"<ul> <li>scientific question is about absolute risk prediction</li> <li>\u201cwhat is probability of relapse by 5 years accounting for death?\u201d</li> <li>clinical decision-making and prognosis</li> </ul> <p>Many papers report BOTH.</p>"},{"location":"Survival_Analysis/12-competing-risks/#part-a-python","title":"PART A \u2014 PYTHON","text":"<p>Python has limited built-in competing risks support compared to R. But we can still do CIF estimation and cause-specific Cox in Python.</p> <p>For Fine\u2013Gray regression, R is much stronger (cmprsk, riskRegression).</p> <p>We will still provide best-possible Python workflow.</p>"},{"location":"Survival_Analysis/12-competing-risks/#8a-simulate-competing-risks-data-python","title":"8A. Simulate competing risks data (Python)","text":"<p>We simulate two event types:</p> <ul> <li>1 = relapse (event of interest)</li> <li>2 = death (competing event)</li> </ul> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(1234)\n\nn = 500\nage = np.random.normal(60, 10, n)\ntrt = np.random.binomial(1, 0.5, n)\n\n# Cause-specific hazards depend on covariates\n# Relapse hazard: treatment reduces, age increases\nbase_relapse = 0.04\nbase_death   = 0.03\n\nbeta_age_relapse = 0.02\nbeta_trt_relapse = -0.50\n\nbeta_age_death = 0.04\nbeta_trt_death = 0.00  # assume treatment does not affect death\n\nh_relapse = base_relapse * np.exp(beta_age_relapse*age + beta_trt_relapse*trt)\nh_death   = base_death   * np.exp(beta_age_death*age   + beta_trt_death*trt)\n\n# Simulate event times for each cause (exponential here for simplicity)\nT1 = np.random.exponential(1/h_relapse)  # relapse time\nT2 = np.random.exponential(1/h_death)    # death time\n\n# Observed event = whichever happens first\nT = np.minimum(T1, T2)\nevent_type = np.where(T1 &lt; T2, 1, 2)\n\n# Add censoring\nC = np.random.uniform(2, 25, n)\ntime = np.minimum(T, C)\nstatus = np.where(T &lt;= C, event_type, 0)  # 0=censored, 1=relapse, 2=death\n\ndf = pd.DataFrame({\"time\": time, \"status\": status, \"age\": age, \"treatment\": trt})\ndf.head()\n</code></pre> <p>Status meanings:  - 0 = censored  - 1 = relapse  - 2 = death (competing)</p>"},{"location":"Survival_Analysis/12-competing-risks/#9a-estimate-cif-in-python-nonparametric","title":"9A. Estimate CIF in Python (nonparametric)","text":"<p>We\u2019ll estimate CIF using a simple Aalen\u2013Johansen style approach.</p> <p>This code computes CIF by: - estimating overall survival - estimating cause-specific increments</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\ndef cif_aalen_johansen(time, status, cause=1):\n    # time: observed times\n    # status: 0=censor, 1..K causes\n    df = pd.DataFrame({\"time\": time, \"status\": status}).sort_values(\"time\")\n\n    unique_times = np.sort(df.loc[df.status &gt; 0, \"time\"].unique())\n\n    S = 1.0\n    cif = 0.0\n    out = []\n\n    for t in unique_times:\n        at_risk = (df[\"time\"] &gt;= t).sum()\n        d_all   = ((df[\"time\"] == t) &amp; (df[\"status\"] &gt; 0)).sum()\n        d_cause = ((df[\"time\"] == t) &amp; (df[\"status\"] == cause)).sum()\n\n        # increment in CIF for this cause\n        if at_risk &gt; 0:\n            cif += S * (d_cause / at_risk)\n            # update survival after all events at time t\n            S *= (1 - d_all / at_risk)\n\n        out.append((t, cif))\n\n    return pd.DataFrame(out, columns=[\"time\", f\"CIF_cause{cause}\"])\n\ncif1 = cif_aalen_johansen(df[\"time\"], df[\"status\"], cause=1)\ncif2 = cif_aalen_johansen(df[\"time\"], df[\"status\"], cause=2)\n\ncif1.head(), cif2.head()\n</code></pre>"},{"location":"Survival_Analysis/12-competing-risks/#10a-plot-cif-curves-in-python","title":"10A. Plot CIF curves in Python","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\n\nplt.plot(cif1[\"time\"], cif1[\"CIF_cause1\"], label=\"Relapse CIF\")\nplt.plot(cif2[\"time\"], cif2[\"CIF_cause2\"], label=\"Death CIF\")\n\nplt.title(\"Cumulative Incidence Functions (Competing Risks)\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"CIF\")\nplt.legend()\nplt.show()\n</code></pre> <p>Interpretation:  - CIF(t) is probability of event by time t.  - These curves typically add up with survival probability.</p>"},{"location":"Survival_Analysis/12-competing-risks/#11a-cause-specific-cox-models-in-python-lifelines","title":"11A. Cause-specific Cox models in Python (lifelines)","text":""},{"location":"Survival_Analysis/12-competing-risks/#11a1-relapse-model-treat-death-as-censored","title":"11A.1 Relapse model (treat death as censored)","text":"<p>Create event indicator:  - event=1 if relapse  - event=0 if death or censoring</p> <p>Python</p> <pre><code>from lifelines import CoxPHFitter\n\ndf_relapse = df.copy()\ndf_relapse[\"event_relapse\"] = (df_relapse[\"status\"] == 1).astype(int)\n\ncph_relapse = CoxPHFitter()\ncph_relapse.fit(df_relapse[[\"time\",\"event_relapse\",\"age\",\"treatment\"]],\n                duration_col=\"time\", event_col=\"event_relapse\")\n\ncph_relapse.print_summary()\n</code></pre> <p>Interpretation:  - HR applies to relapse hazard among those event-free.</p>"},{"location":"Survival_Analysis/12-competing-risks/#11a2-death-model-treat-relapse-as-censored","title":"11A.2 Death model (treat relapse as censored)","text":"<p>Python</p> <pre><code>df_death = df.copy()\ndf_death[\"event_death\"] = (df_death[\"status\"] == 2).astype(int)\n\ncph_death = CoxPHFitter()\ncph_death.fit(df_death[[\"time\",\"event_death\",\"age\",\"treatment\"]],\n              duration_col=\"time\", event_col=\"event_death\")\n\ncph_death.print_summary()\n</code></pre>"},{"location":"Survival_Analysis/12-competing-risks/#12a-why-finegray-is-harder-in-python","title":"12A. Why Fine\u2013Gray is harder in Python","text":"<p>Fine\u2013Gray regression is not fully supported in standard lifelines workflows. You can:  - estimate CIF nonparametrically   - fit cause-specific Cox  But for Fine\u2013Gray regression, R is recommended.</p>"},{"location":"Survival_Analysis/12-competing-risks/#part-b-r-best-tool-for-competing-risks","title":"PART B \u2014 R (best tool for competing risks)","text":"<p>In R, competing risks is commonly handled with:</p> <ul> <li><code>cmprsk</code> (Fine\u2013Gray)  </li> <li><code>survival</code> (cause-specific Cox)  </li> <li><code>riskRegression</code> (CIF prediction / model comparison)  </li> </ul>"},{"location":"Survival_Analysis/12-competing-risks/#13b-simulate-competing-risks-data-in-r","title":"13B. Simulate competing risks data in R","text":"<p>R</p> <pre><code>set.seed(1234)\n\nn &lt;- 500\nage &lt;- rnorm(n, 60, 10)\ntrt &lt;- rbinom(n, 1, 0.5)\n\nbase_relapse &lt;- 0.04\nbase_death   &lt;- 0.03\n\nbeta_age_relapse &lt;- 0.02\nbeta_trt_relapse &lt;- -0.50\n\nbeta_age_death &lt;- 0.04\nbeta_trt_death &lt;- 0.00\n\nh_relapse &lt;- base_relapse * exp(beta_age_relapse*age + beta_trt_relapse*trt)\nh_death   &lt;- base_death   * exp(beta_age_death*age   + beta_trt_death*trt)\n\nT1 &lt;- rexp(n, rate=h_relapse)\nT2 &lt;- rexp(n, rate=h_death)\n\nT &lt;- pmin(T1, T2)\nstatus &lt;- ifelse(T1 &lt; T2, 1, 2)\n\nC &lt;- runif(n, 2, 25)\ntime &lt;- pmin(T, C)\nstatus_obs &lt;- ifelse(T &lt;= C, status, 0)\n\ndf &lt;- data.frame(time=time, status=status_obs, age=age, treatment=trt)\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/12-competing-risks/#14b-cif-estimation-in-r-cmprsk","title":"14B. CIF estimation in R (cmprsk)","text":"<p>R</p> <pre><code># install.packages(\"cmprsk\") # if needed\nlibrary(cmprsk)\n\n# status: 0=censored, 1=relapse, 2=death\ncif &lt;- cuminc(ftime=df$time, fstatus=df$status)\n\ncif\nplot(cif, lty=1, col=c(\"red\",\"blue\"),\n     xlab=\"Time\", ylab=\"CIF\",\n     main=\"Cumulative Incidence Functions (Competing Risks)\")\nlegend(\"topleft\", legend=c(\"Relapse\",\"Death\"), col=c(\"red\",\"blue\"), lty=1)\n</code></pre>"},{"location":"Survival_Analysis/12-competing-risks/#15b-cif-by-treatment-group","title":"15B. CIF by treatment group","text":"<p>R</p> <pre><code>cif_g &lt;- cuminc(ftime=df$time, fstatus=df$status, group=df$treatment)\ncif_g\nplot(cif_g, lty=1, xlab=\"Time\", ylab=\"CIF\",\n     main=\"CIF by Treatment Group\")\n</code></pre> <p>Interpretation:  - This shows relapse probability over time accounting for death, separately by treatment group.</p>"},{"location":"Survival_Analysis/12-competing-risks/#16b-cause-specific-cox-models-in-r","title":"16B. Cause-specific Cox models in R","text":""},{"location":"Survival_Analysis/12-competing-risks/#16b1-relapse-cause-specific-cox","title":"16B.1 Relapse cause-specific Cox","text":"<p>Treat death as censored:</p> <p>R</p> <pre><code>library(survival)\n\nevent_relapse &lt;- as.integer(df$status == 1)\nfit_relapse &lt;- coxph(Surv(df$time, event_relapse) ~ age + treatment, data=df)\nsummary(fit_relapse)\n</code></pre>"},{"location":"Survival_Analysis/12-competing-risks/#16b2-death-cause-specific-cox","title":"16B.2 Death cause-specific Cox","text":"<p>Treat relapse as censored:</p> <p>R</p> <pre><code>event_death &lt;- as.integer(df$status == 2)\nfit_death &lt;- coxph(Surv(df$time, event_death) ~ age + treatment, data=df)\nsummary(fit_death)\n</code></pre>"},{"location":"Survival_Analysis/12-competing-risks/#17b-finegray-model-in-r-subdistribution-hazard","title":"17B. Fine\u2013Gray model in R (subdistribution hazard)","text":"<p>Fine\u2013Gray models the CIF directly.</p> <p>Use <code>crr()</code> from cmprsk:</p> <p>R</p> <pre><code># Fine\u2013Gray for relapse (cause=1)\nfg &lt;- crr(ftime=df$time, fstatus=df$status, cov1=df[,c(\"age\",\"treatment\")], failcode=1)\nfg\n</code></pre> <p>Interpretation: - exponentiated coefficients are subdistribution HRs - relate to CIF probability over time</p>"},{"location":"Survival_Analysis/12-competing-risks/#18-interpretation-cause-specific-hr-vs-finegray-hr","title":"18. Interpretation: cause-specific HR vs Fine\u2013Gray HR","text":""},{"location":"Survival_Analysis/12-competing-risks/#cause-specific-hr-answers","title":"Cause-specific HR answers:","text":"<p>\"Among those still event-free, how does X affect instantaneous hazard of relapse?\"</p>"},{"location":"Survival_Analysis/12-competing-risks/#finegray-hr-answers","title":"Fine\u2013Gray HR answers:","text":"<p>\"How does X affect cumulative incidence probability of relapse over time, accounting for death?\"</p> <p>They can differ because: - Fine\u2013Gray keeps competing events \u201cin the risk set\u201d in a special way.</p>"},{"location":"Survival_Analysis/12-competing-risks/#19-reporting-examples","title":"19. Reporting examples","text":""},{"location":"Survival_Analysis/12-competing-risks/#cif-reporting","title":"CIF reporting","text":"<p>\u201cThe 5-year cumulative incidence of relapse was 0.24 (accounting for competing risk of death).\u201d</p>"},{"location":"Survival_Analysis/12-competing-risks/#cause-specific-cox-reporting","title":"Cause-specific Cox reporting","text":"<p>\u201cIn cause-specific Cox regression, treatment reduced relapse hazard (HR 0.62, 95% CI \u2026).\u201d</p>"},{"location":"Survival_Analysis/12-competing-risks/#finegray-reporting","title":"Fine\u2013Gray reporting","text":"<p>\u201cIn Fine\u2013Gray regression, treatment reduced subdistribution hazard of relapse (sHR 0.70, 95% CI \u2026).\u201d</p> <p>Always specify: - which model - which interpretation - competing event definition</p>"},{"location":"Survival_Analysis/12-competing-risks/#20-common-mistakes","title":"20. Common mistakes","text":""},{"location":"Survival_Analysis/12-competing-risks/#mistake-1-using-km-to-estimate-relapse-probability-with-death-competing","title":"Mistake 1: using KM to estimate relapse probability with death competing","text":"<p>KM overestimates relapse probability.</p> <p>Fix: use CIF.</p>"},{"location":"Survival_Analysis/12-competing-risks/#mistake-2-interpreting-cause-specific-hr-as-directly-affecting-cif-probability","title":"Mistake 2: interpreting cause-specific HR as directly affecting CIF probability","text":"<p>Cause-specific HR affects hazard, not CIF directly.</p> <p>Fix: use Fine\u2013Gray if question is CIF probability.</p>"},{"location":"Survival_Analysis/12-competing-risks/#mistake-3-calling-competing-risks-censoring","title":"Mistake 3: calling competing risks \u201ccensoring\u201d","text":"<p>Death is not censoring if relapse is endpoint.</p> <p>Fix: treat as competing event.</p>"},{"location":"Survival_Analysis/12-competing-risks/#21-key-takeaways","title":"21. Key takeaways","text":"<ul> <li>Competing risks occur when another event prevents event of interest.</li> <li>KM is wrong for event probability under competing risks.</li> <li>CIF is the correct event probability estimate.</li> <li>Cause-specific Cox models hazard among those still event-free.</li> <li>Fine\u2013Gray models the cumulative incidence (probability) directly.</li> <li>R is currently the best ecosystem for full competing risks regression.</li> </ul>"},{"location":"Survival_Analysis/12-competing-risks/#22-exercises","title":"22. Exercises","text":"Click to try   1. Simulate competing risks data and compare KM relapse estimate (treat death as censoring) vs CIF relapse estimate. Which is higher and why?    2. Fit cause-specific Cox for relapse and interpret HR clinically.    3. Fit Fine\u2013Gray for relapse and interpret subdistribution HR.    4. Create a scenario where treatment reduces relapse but increases death. What happens to CIF of relapse?    5. Plot CIF curves by treatment and report 5-year relapse incidence."},{"location":"Survival_Analysis/13-frailty-models/","title":"Frailty Models (Unobserved Heterogeneity + Clustering)","text":"<p>In many biostatistics datasets, subjects are not independent.</p> <p>Examples:  - patients clustered within hospitals/centers  - family members share genetics and environment  - repeated patients within the same physician practice  - multi-country clinical trials with site effects</p> <p>If we ignore clustering, standard Cox regression often gives:</p> <ul> <li>standard errors too small  </li> <li>p-values too optimistic  </li> <li>confidence intervals too narrow  </li> </ul> <p>Sometimes we also have unobserved heterogeneity:  - two patients with same covariates still have different risk because of unmeasured factors.</p> <p>Frailty models handle both.</p> <p>This chapter covers:</p> <ul> <li>what frailty is  </li> <li>shared frailty for clustering  </li> <li>individual frailty for unobserved heterogeneity  </li> <li>interpretation  </li> <li>how to fit in R </li> <li>best practices for Python (robust SE + stratification alternatives)  </li> <li>what to report in papers  </li> </ul>"},{"location":"Survival_Analysis/13-frailty-models/#1-what-is-frailty-in-survival-analysis","title":"1. What is \u201cfrailty\u201d in survival analysis?","text":"<p>Frailty is a random effect that multiplies the hazard:</p> \\[ h_i(t \\mid X_i, u_i) = u_i \\, h_0(t)\\exp(\\beta^T X_i) \\] <p>Where: - \\(u_i &gt; 0\\) is the frailty (random effect) - usually \\(E[u_i]=1\\)</p> <p>Interpretation: - \\(u_i &gt; 1\\): higher risk than average (frailer) - \\(u_i &lt; 1\\): lower risk than average</p> <p>Frailty is like \u201crandom risk multiplier\u201d not explained by measured covariates.</p>"},{"location":"Survival_Analysis/13-frailty-models/#2-why-frailty-matters-clinical-intuition","title":"2. Why frailty matters (clinical intuition)","text":"<p>Even after adjusting for:  - age  - sex  - treatment  - stage</p> <p>some hospitals may have higher mortality because:  - different surgical skill  - ICU quality  - patient mix not fully captured  - protocols</p> <p>Frailty models capture this unmeasured cluster risk.</p>"},{"location":"Survival_Analysis/13-frailty-models/#3-two-main-frailty-settings","title":"3. Two main frailty settings","text":""},{"location":"Survival_Analysis/13-frailty-models/#31-shared-frailty","title":"3.1 Shared frailty","text":"<p>All subjects in a cluster share the same frailty term.</p> <p>Example: hospital clustering</p> \\[ h_{ij}(t)=u_j h_0(t)\\exp(\\beta^T X_{ij}) \\] <ul> <li>\\(j\\) indexes clusters (hospital)</li> <li>\\(i\\) indexes patients in cluster</li> </ul> <p>Interpretation:  - hospitals have random baseline risk differences</p>"},{"location":"Survival_Analysis/13-frailty-models/#32-individual-frailty","title":"3.2 Individual frailty","text":"<p>Each subject has their own frailty (unobserved heterogeneity).</p> <p>Used more in: - recurrent events - unmeasured patient-level risk</p>"},{"location":"Survival_Analysis/13-frailty-models/#4-common-frailty-distributions","title":"4. Common frailty distributions","text":"<p>Frailty must be positive, so common choices:</p>"},{"location":"Survival_Analysis/13-frailty-models/#41-gamma-frailty","title":"4.1 Gamma frailty","text":"<ul> <li>mathematically convenient</li> <li>leads to closed-form marginal likelihood in some cases</li> </ul>"},{"location":"Survival_Analysis/13-frailty-models/#42-log-normal-frailty","title":"4.2 Log-normal frailty","text":"<ul> <li>random effect on log-hazard scale</li> <li>more flexible but computationally heavier</li> </ul> <p>In practice:  - gamma shared frailty is a standard default.</p>"},{"location":"Survival_Analysis/13-frailty-models/#5-what-frailty-changes-compared-to-standard-cox","title":"5. What frailty changes compared to standard Cox","text":""},{"location":"Survival_Analysis/13-frailty-models/#51-coefficients","title":"5.1 Coefficients","text":"<p>Fixed effects \\(\\beta\\) may change slightly, but often similar.</p>"},{"location":"Survival_Analysis/13-frailty-models/#52-standard-errors","title":"5.2 Standard errors","text":"<p>Usually increase because clustering reduces effective sample size.</p>"},{"location":"Survival_Analysis/13-frailty-models/#53-interpretation","title":"5.3 Interpretation","text":"<p>Hazard ratios remain conditional on frailty (cluster effect).</p>"},{"location":"Survival_Analysis/13-frailty-models/#6-frailty-vs-robust-standard-errors","title":"6. Frailty vs robust standard errors","text":""},{"location":"Survival_Analysis/13-frailty-models/#robust-se-sandwich","title":"Robust SE (sandwich)","text":"<ul> <li>adjusts SE for clustering</li> <li>does NOT model cluster heterogeneity</li> <li>does NOT estimate cluster variance</li> </ul>"},{"location":"Survival_Analysis/13-frailty-models/#frailty-model","title":"Frailty model","text":"<ul> <li>explicitly models clustering as random effect</li> <li>estimates variance of frailty</li> <li>can improve predictions and interpretation</li> </ul> <p>Rule of thumb:  - if you just need correct inference: robust SE  - if you want to model heterogeneity: frailty</p> <p>Many papers:  - use robust SE for simplicity  - use frailty when clustering is central</p>"},{"location":"Survival_Analysis/13-frailty-models/#part-a-python","title":"PART A \u2014 PYTHON","text":"<p>Python currently has limited frailty support compared to R. The most common practical options in Python:</p> <ul> <li>robust standard errors (cluster correction)  </li> <li>stratified Cox (different baseline hazards per cluster)  </li> </ul> <p>We show both.</p>"},{"location":"Survival_Analysis/13-frailty-models/#7a-simulate-clustered-survival-data-python","title":"7A. Simulate clustered survival data (Python)","text":"<p>We create:  - 10 hospitals  - each hospital has its own frailty multiplier  - treatment reduces hazard  - age increases hazard</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(2027)\n\nn = 600\nhospitals = np.random.choice(range(1, 11), size=n)  # 10 hospitals\n\n# Gamma frailty-like multipliers per hospital\n# mean 1, some variance\nhospital_effect = {h: np.random.gamma(shape=2.0, scale=0.5) for h in range(1, 11)}\n\nage = np.random.normal(60, 10, n)\ntrt = np.random.binomial(1, 0.5, n)\n\nbeta_age = 0.03\nbeta_trt = -0.40\nbase = 0.04\n\nu = np.array([hospital_effect[h] for h in hospitals])\n\nhazard = u * base * np.exp(beta_age*age + beta_trt*trt)\n\nT = np.random.exponential(1/hazard)\nC = np.random.uniform(2, 25, n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\n    \"time\": time,\n    \"event\": event,\n    \"age\": age,\n    \"treatment\": trt,\n    \"hospital\": hospitals\n})\n\ndf.head()\n</code></pre>"},{"location":"Survival_Analysis/13-frailty-models/#8a-fit-cox-with-and-without-robust-se-python","title":"8A. Fit Cox with and without robust SE (Python)","text":""},{"location":"Survival_Analysis/13-frailty-models/#8a1-standard-cox-ignores-clustering","title":"8A.1 Standard Cox (ignores clustering)","text":"<p>Python</p> <pre><code>from lifelines import CoxPHFitter\n\ncph = CoxPHFitter()\ncph.fit(df[[\"time\",\"event\",\"age\",\"treatment\"]], duration_col=\"time\", event_col=\"event\")\ncph.print_summary()\n</code></pre>"},{"location":"Survival_Analysis/13-frailty-models/#8a2-cox-with-robust-se","title":"8A.2 Cox with robust SE","text":"<p>Python</p> <pre><code>cph_robust = CoxPHFitter()\ncph_robust.fit(df[[\"time\",\"event\",\"age\",\"treatment\"]],\n               duration_col=\"time\", event_col=\"event\", robust=True)\ncph_robust.print_summary()\n</code></pre> <p>What you\u2019ll often see:  - coefficients similar  - SE larger with robust=True  - p-values less optimistic</p> <p>Note: <code>robust=True</code> is a general sandwich correction and does not require specifying cluster ID explicitly in lifelines.</p>"},{"location":"Survival_Analysis/13-frailty-models/#9a-stratified-cox-by-hospital-python","title":"9A. Stratified Cox by hospital (Python)","text":"<p>Stratification allows each hospital its own baseline hazard:</p> \\[ h(t|X, \\text{hospital}) = h_{0,hospital}(t)\\exp(\\beta^TX) \\] <p>This adjusts for hospital differences without estimating an HR for hospital.</p> <p>Python</p> <pre><code>cph_strat = CoxPHFitter()\ncph_strat.fit(df, duration_col=\"time\", event_col=\"event\", strata=[\"hospital\"])\ncph_strat.print_summary()\n</code></pre> <p>Interpretation: - age/treatment HRs are estimated by comparing subjects within the same hospital strata.</p> <p>Use stratification if: - you don\u2019t need hospital effect estimates - you just need to control for hospital baseline hazard differences</p>"},{"location":"Survival_Analysis/13-frailty-models/#part-b-r-true-frailty-models","title":"PART B \u2014 R (true frailty models)","text":"<p>R has excellent frailty support via the <code>survival</code> package.</p> <p>We will show:</p> <ul> <li>shared frailty (gamma)  </li> <li>robust SE alternative  </li> <li>interpretation and reporting  </li> </ul>"},{"location":"Survival_Analysis/13-frailty-models/#10b-simulate-clustered-survival-data-r","title":"10B. Simulate clustered survival data (R)","text":"<p>R</p> <pre><code>set.seed(2027)\n\nn &lt;- 600\nhospital &lt;- sample(1:10, n, replace=TRUE)\n\n# Gamma frailty multipliers per hospital\nhospital_u &lt;- rgamma(10, shape=2, scale=0.5)  # mean 1\nu &lt;- hospital_u[hospital]\n\nage &lt;- rnorm(n, 60, 10)\ntrt &lt;- rbinom(n, 1, 0.5)\n\nbeta_age &lt;- 0.03\nbeta_trt &lt;- -0.40\nbase &lt;- 0.04\n\nhazard &lt;- u * base * exp(beta_age*age + beta_trt*trt)\n\nT &lt;- rexp(n, rate=hazard)\nC &lt;- runif(n, 2, 25)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event, age=age, treatment=trt, hospital=factor(hospital))\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/13-frailty-models/#11b-standard-cox-ignores-clustering","title":"11B. Standard Cox (ignores clustering)","text":"<p>R</p> <pre><code>library(survival)\n\nfit &lt;- coxph(Surv(time, event) ~ age + treatment, data=df)\nsummary(fit)\n</code></pre>"},{"location":"Survival_Analysis/13-frailty-models/#12b-cox-with-robust-se-for-hospital-clustering-r","title":"12B. Cox with robust SE for hospital clustering (R)","text":"<p>R</p> <pre><code>fit_robust &lt;- coxph(Surv(time, event) ~ age + treatment + cluster(hospital), data=df)\nsummary(fit_robust)\n</code></pre> <p>This corrects SE for clustering but does not estimate frailty variance.</p>"},{"location":"Survival_Analysis/13-frailty-models/#13b-shared-frailty-cox-model-gamma-frailty","title":"13B. Shared frailty Cox model (gamma frailty)","text":"<p>This is the real frailty model:</p> <p>R</p> <pre><code>fit_frailty &lt;- coxph(Surv(time, event) ~ age + treatment + frailty(hospital), data=df)\nsummary(fit_frailty)\n</code></pre> <p>Output includes:  - HRs for covariates  - an estimate of frailty variance (often shown as \u201ctheta\u201d or variance parameter)  - likelihood ratio test for frailty term</p>"},{"location":"Survival_Analysis/13-frailty-models/#14b-interpreting-frailty-variance","title":"14B. Interpreting frailty variance","text":"<p>If frailty variance \u2248 0:  - little clustering/unobserved heterogeneity  - frailty may not be needed</p> <p>If frailty variance is large:  - strong between-hospital heterogeneity  - ignoring clustering likely distorted inference</p> <p>Often reported as:  - variance estimate  - p-value from LRT comparing with/without frailty</p>"},{"location":"Survival_Analysis/13-frailty-models/#15-how-to-interpret-covariate-hrs-in-frailty-model","title":"15. How to interpret covariate HRs in frailty model","text":"<p>The HR is conditional on the frailty term.</p> <p>Interpretation:</p> <p>For two patients in the same hospital (same frailty), treatment HR is X.</p> <p>If you want marginal population-level effects, interpretation gets more complex.</p> <p>Most clinical papers interpret conditional HRs.</p>"},{"location":"Survival_Analysis/13-frailty-models/#16-when-to-prefer-frailty-vs-stratification","title":"16. When to prefer frailty vs stratification","text":""},{"location":"Survival_Analysis/13-frailty-models/#stratification","title":"Stratification:","text":"<ul> <li>controls for cluster baseline differences</li> <li>no estimate of cluster variance</li> <li>does not assume random effects distribution</li> <li>can handle many strata if enough events per stratum</li> </ul>"},{"location":"Survival_Analysis/13-frailty-models/#frailty","title":"Frailty:","text":"<ul> <li>models random cluster effect</li> <li>estimates cluster heterogeneity</li> <li>can improve prediction</li> <li>assumes frailty distribution (gamma/lognormal)</li> </ul> <p>Use frailty when:  - clustering is an important scientific feature  - you want to quantify heterogeneity between clusters</p>"},{"location":"Survival_Analysis/13-frailty-models/#17-reporting-examples","title":"17. Reporting examples","text":""},{"location":"Survival_Analysis/13-frailty-models/#robust-se-report","title":"Robust SE report","text":"<p>\u201cCox models used robust sandwich standard errors clustered by hospital.\u201d</p>"},{"location":"Survival_Analysis/13-frailty-models/#frailty-model-report","title":"Frailty model report","text":"<p>\u201cA shared frailty Cox model with hospital-level gamma frailty was fitted to account for within-hospital correlation.\u201d</p> <p>Then report: - HRs with CI - frailty variance estimate - p-value for frailty term (if relevant)</p>"},{"location":"Survival_Analysis/13-frailty-models/#18-common-mistakes","title":"18. Common mistakes","text":""},{"location":"Survival_Analysis/13-frailty-models/#mistake-1-ignore-clustering-entirely","title":"Mistake 1: ignore clustering entirely","text":"<p>Leads to under-estimated SE.</p>"},{"location":"Survival_Analysis/13-frailty-models/#mistake-2-treat-hospital-as-a-normal-covariate-with-many-levels","title":"Mistake 2: treat hospital as a normal covariate with many levels","text":"<p>This wastes degrees of freedom and can be unstable.</p> <p>Better options:   - strata(hospital)   - cluster(hospital) robust SE   - frailty(hospital)</p>"},{"location":"Survival_Analysis/13-frailty-models/#mistake-3-interpret-frailty-as-measured-covariate","title":"Mistake 3: interpret frailty as measured covariate","text":"<p>Frailty is unobserved heterogeneity; not directly measured.</p>"},{"location":"Survival_Analysis/13-frailty-models/#19-key-takeaways","title":"19. Key takeaways","text":"<ul> <li>Frailty models add a multiplicative random effect to hazard.</li> <li>Shared frailty handles clustering (hospital, family, center).</li> <li>Robust SE adjusts inference but does not model heterogeneity.</li> <li>Stratification controls baseline differences without estimating effects.</li> <li>R provides full frailty modeling (<code>frailty()</code> in coxph).</li> <li>Python best practice: robust SE and/or stratified Cox.</li> </ul>"},{"location":"Survival_Analysis/13-frailty-models/#20-exercises","title":"20. Exercises","text":"Click to try   1. Simulate data with strong hospital frailty and fit: standard Cox vs robust SE vs frailty. Compare SE and p-values.    2. Increase frailty variance by changing gamma distribution parameters; observe stronger clustering effects.    3. Fit stratified Cox by hospital and compare treatment HR to frailty model.    4. Interpret frailty variance in plain language.    5. Write a short \u201cMethods\u201d paragraph describing a frailty model analysis for a multi-center trial."},{"location":"Survival_Analysis/14-recurrent-events/","title":"Recurrent Events (Multiple Events per Subject)","text":"<p>Many biostatistics outcomes are not \u201ctime to the first event.\u201d</p> <p>Instead, subjects can experience the event multiple times.</p> <p>Examples:  - repeated hospitalizations  - recurrent infections (UTI, malaria episodes)  - repeated asthma exacerbations  - recurrent falls in geriatrics  - repeated device malfunctions</p> <p>These are recurrent events.</p> <p>If you use standard survival analysis on only the first event, you lose information.</p> <p>This chapter covers:</p> <ul> <li>what recurrent event data looks like  </li> <li>why standard Cox is not enough  </li> <li>major recurrent-event approaches  </li> <li>Andersen\u2013Gill (AG) model  </li> <li>PWP models (total-time and gap-time)  </li> <li>robust SE and frailty  </li> <li>Python + R implementation  </li> </ul>"},{"location":"Survival_Analysis/14-recurrent-events/#1-what-is-a-recurrent-event","title":"1. What is a recurrent event?","text":"<p>A recurrent event means:</p> <p>A subject can experience the same event multiple times during follow-up.</p> <p>We observe multiple event times:</p> \\[ T_{i1}, T_{i2}, \\dots \\] <p>And the process may stop at:  - study end  - dropout  - death (terminal event)</p>"},{"location":"Survival_Analysis/14-recurrent-events/#2-why-time-to-first-event-can-be-insufficient","title":"2. Why \u201ctime to first event\u201d can be insufficient","text":"<p>If you analyze only first hospitalization:</p> <ul> <li>you ignore later hospitalizations (important clinically)</li> <li>you underestimate disease burden</li> <li>treatment might reduce recurrence even if first event is similar</li> </ul> <p>So recurrent event analysis helps quantify total burden.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#3-recurrent-events-vs-competing-risks-vs-terminal-events","title":"3. Recurrent events vs competing risks vs terminal events","text":"<p>Important distinction:</p> <ul> <li>Recurrent event: can happen multiple times</li> <li>Competing risk: different event prevents event of interest</li> <li>Terminal event: death stops recurrence process</li> </ul> <p>In many studies you have both:  - repeated hospitalizations  - followed by death</p> <p>That is a more advanced joint modeling topic, but we mention it.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#4-data-structure-for-recurrent-events-startstop","title":"4. Data structure for recurrent events (start\u2013stop)","text":"<p>Recurrent event data typically uses counting process format:</p> id start stop event covariates 1 0 5 1 ... 1 5 9 1 ... 1 9 14 0 ... <ul> <li>each row represents a time interval at risk</li> <li>event=1 indicates event occurred at end of interval</li> <li>after an event, subject re-enters risk set (with new interval)</li> </ul>"},{"location":"Survival_Analysis/14-recurrent-events/#5-key-modeling-challenge-within-subject-dependence","title":"5. Key modeling challenge: within-subject dependence","text":"<p>Events for the same subject are correlated:</p> <ul> <li>some patients are \u201cfrequent flyers\u201d</li> <li>unmeasured frailty may increase recurrence risk</li> </ul> <p>So we must adjust for correlation:  - robust SE  - frailty  - event-order models</p>"},{"location":"Survival_Analysis/14-recurrent-events/#6-main-recurrent-event-model-families","title":"6. Main recurrent-event model families","text":""},{"location":"Survival_Analysis/14-recurrent-events/#61-andersengill-ag-model","title":"6.1 Andersen\u2013Gill (AG) model","text":"<ul> <li>treats recurrent events as a counting process</li> <li>subject is at risk again immediately after each event</li> <li>assumes same baseline hazard for all events</li> <li>uses robust SE (cluster by subject)</li> </ul> <p>Great for:  - overall recurrence rate comparison</p> <p>Limitations:  - does not explicitly model event order  - assumes same risk mechanism for first and later events</p>"},{"location":"Survival_Analysis/14-recurrent-events/#62-prenticewilliamspeterson-pwp-models","title":"6.2 Prentice\u2013Williams\u2013Peterson (PWP) models","text":"<p>These model event order:</p> <ul> <li>PWP Total-time: time measured from baseline</li> <li>PWP Gap-time: time resets after each event</li> </ul> <p>These are good when:  - event 2 depends on having event 1  - baseline hazard differs by event number</p>"},{"location":"Survival_Analysis/14-recurrent-events/#63-frailty-models-for-recurrence","title":"6.3 Frailty models for recurrence","text":"<p>Random effect per subject:  - frequent-event subjects have higher frailty  - accounts for unobserved heterogeneity</p>"},{"location":"Survival_Analysis/14-recurrent-events/#7-andersengill-model-in-detail","title":"7. Andersen\u2013Gill model in detail","text":""},{"location":"Survival_Analysis/14-recurrent-events/#71-model-form","title":"7.1 Model form","text":"\\[ h_i(t)=h_0(t)\\exp(\\beta^TX_i(t)) \\] <p>But each subject can have multiple events.</p> <p>Key concept: counting process \\(N_i(t)\\):  - counts how many events by time \\(t\\)</p> <p>AG treats each event as contributing to Cox partial likelihood with risk sets.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#72-dependence-handling","title":"7.2 Dependence handling","text":"<p>Standard errors are usually computed using:</p> <ul> <li>robust sandwich estimator clustered by subject (id)</li> </ul> <p>In R: <code>cluster(id)</code> In Python: robust=True can help, but full recurrent support is limited</p>"},{"location":"Survival_Analysis/14-recurrent-events/#8-pwp-models-event-order-models","title":"8. PWP models (event-order models)","text":""},{"location":"Survival_Analysis/14-recurrent-events/#81-total-time","title":"8.1 Total-time","text":"<p>Time is measured from baseline. Event strata created by event number.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#82-gap-time","title":"8.2 Gap-time","text":"<p>Time resets after each event. Good when you care about time between recurrences.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#part-a-r","title":"PART A \u2014 R","text":"<p>R\u2019s <code>survival</code> package is the standard for recurrent event modeling.</p> <p>We will show:  - how to build recurrent-event dataset  - fit AG model  - fit PWP total-time and gap-time</p>"},{"location":"Survival_Analysis/14-recurrent-events/#9a-simulate-recurrent-event-data-r","title":"9A. Simulate recurrent event data (R)","text":"<p>We simulate:  - 300 subjects  - treatment reduces recurrence rate  - each subject can have up to 3 events  - random censoring</p> <p>R</p> <pre><code>set.seed(2028)\n\nn &lt;- 300\ntrt &lt;- rbinom(n, 1, 0.5)\nage &lt;- rnorm(n, 60, 10)\n\n# baseline recurrence rate\nbase &lt;- 0.15\n\nbeta_trt &lt;- -0.50\nbeta_age &lt;- 0.02\n\nmax_events &lt;- 3\n\nrows &lt;- list()\nidx &lt;- 1\n\nfor (i in 1:n) {\n\n  # subject-specific frailty-like multiplier (optional)\n  u &lt;- rgamma(1, shape=2, scale=0.5)  # mean 1\n\n  t &lt;- 0\n  event_count &lt;- 0\n\n  censor &lt;- runif(1, 4, 12)\n\n  while (event_count &lt; max_events) {\n\n    # hazard for next event (exponential gap time for simplicity)\n    h &lt;- u * base * exp(beta_trt*trt[i] + beta_age*(age[i]-60))\n\n    gap &lt;- rexp(1, rate=h)\n    t_next &lt;- t + gap\n\n    if (t_next &lt;= censor) {\n      # event occurs\n      rows[[idx]] &lt;- data.frame(\n        id=i,\n        start=t,\n        stop=t_next,\n        event=1,\n        event_number=event_count+1,\n        trt=trt[i],\n        age=age[i]\n      )\n      idx &lt;- idx + 1\n\n      t &lt;- t_next\n      event_count &lt;- event_count + 1\n    } else {\n      # censored before next event\n      rows[[idx]] &lt;- data.frame(\n        id=i,\n        start=t,\n        stop=censor,\n        event=0,\n        event_number=event_count+1,\n        trt=trt[i],\n        age=age[i]\n      )\n      idx &lt;- idx + 1\n      break\n    }\n  }\n}\n\nd &lt;- do.call(rbind, rows)\nhead(d, 12)\n</code></pre>"},{"location":"Survival_Analysis/14-recurrent-events/#10a-andersengill-model-in-r","title":"10A. Andersen\u2013Gill model in R","text":"<p>Andersen\u2013Gill is just Cox with start\u2013stop and robust SE clustered by id:</p> <p>R</p> <pre><code>library(survival)\n\nfit_ag &lt;- coxph(Surv(start, stop, event) ~ trt + age + cluster(id), data=d)\nsummary(fit_ag)\n</code></pre> <p>Interpretation:  - HR for <code>trt</code> compares recurrence hazard at any moment between groups.  - Robust SE accounts for within-subject correlation.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#11a-pwp-total-time-model-event-strata","title":"11A. PWP Total-Time model (event strata)","text":"<p>PWP total-time uses strata by event number: - each event number has its own baseline hazard</p> <p>R</p> <pre><code>fit_pwp_tt &lt;- coxph(Surv(start, stop, event) ~ trt + age + strata(event_number) + cluster(id), data=d)\nsummary(fit_pwp_tt)\n</code></pre> <p>Interpretation:  - HRs compare covariate effects across event strata.  - baseline hazard differs by event number.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#12a-pwp-gap-time-model","title":"12A. PWP Gap-Time model","text":"<p>For gap-time, we reset time within each event interval:</p> <p>Define:  - gap_start = 0 for each interval  - gap_stop = stop - start</p> <p>R</p> <pre><code>d$gap_start &lt;- 0\nd$gap_stop &lt;- d$stop - d$start\n\nfit_pwp_gt &lt;- coxph(Surv(gap_start, gap_stop, event) ~ trt + age + strata(event_number) + cluster(id), data=d)\nsummary(fit_pwp_gt)\n</code></pre> <p>Interpretation:  - models time between events  - baseline hazard differs by event number</p>"},{"location":"Survival_Analysis/14-recurrent-events/#13a-plotting-cumulative-mean-function","title":"13A. Plotting cumulative mean function","text":"<p>Another descriptive way to visualize recurrence is cumulative events over time.</p> <p>A simple approach:  - estimate mean cumulative function by group</p> <p>(Advanced: use <code>survfit</code> on counting process, or specialized packages.)</p>"},{"location":"Survival_Analysis/14-recurrent-events/#part-b-python","title":"PART B \u2014 PYTHON","text":"<p>Python currently lacks full native tooling for recurrent events compared to R. But you can still do:</p> <ul> <li>create start\u2013stop data  </li> <li>use <code>CoxTimeVaryingFitter</code> as an AG-style model  </li> <li>use robust SE cautiously  </li> <li>or do marginal approaches externally  </li> </ul> <p>We show an AG-style approach using lifelines time-varying fitter.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#14b-simulate-recurrent-events-and-build-startstop-data-python","title":"14B. Simulate recurrent events and build start\u2013stop data (Python)","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(2028)\n\nn = 250\ntrt = np.random.binomial(1, 0.5, n)\nage = np.random.normal(60, 10, n)\n\nbase = 0.15\nbeta_trt = -0.50\nbeta_age = 0.02\nmax_events = 3\n\nrows = []\n\nfor i in range(n):\n    u = np.random.gamma(shape=2.0, scale=0.5)  # mean 1\n    t = 0.0\n    ev = 0\n    censor = np.random.uniform(4, 12)\n\n    while ev &lt; max_events:\n        h = u * base * np.exp(beta_trt*trt[i] + beta_age*(age[i]-60))\n        gap = np.random.exponential(1/h)\n        t_next = t + gap\n\n        if t_next &lt;= censor:\n            rows.append([i, t, t_next, 1, ev+1, trt[i], age[i]])\n            t = t_next\n            ev += 1\n        else:\n            rows.append([i, t, censor, 0, ev+1, trt[i], age[i]])\n            break\n\nd = pd.DataFrame(rows, columns=[\"id\",\"start\",\"stop\",\"event\",\"event_number\",\"treatment\",\"age\"])\nd.head(12)\n</code></pre>"},{"location":"Survival_Analysis/14-recurrent-events/#15b-andersengill-style-fit-in-python-lifelines","title":"15B. Andersen\u2013Gill style fit in Python (lifelines)","text":"<p>We fit start\u2013stop using <code>CoxTimeVaryingFitter</code>.</p> <p>Python</p> <pre><code>from lifelines import CoxTimeVaryingFitter\n\nctv = CoxTimeVaryingFitter()\nctv.fit(d, id_col=\"id\", start_col=\"start\", stop_col=\"stop\", event_col=\"event\")\nctv.print_summary()\n</code></pre> <p>Important note:  - lifelines standard errors for recurrent events may not match R\u2019s robust cluster(id) sandwich perfectly.  - For publication-grade recurrent-event analysis, R is typically preferred.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#16-which-recurrent-event-method-should-you-choose","title":"16. Which recurrent-event method should you choose?","text":""},{"location":"Survival_Analysis/14-recurrent-events/#161-if-you-want-a-simple-overall-recurrence-rate-effect","title":"16.1 If you want a simple \u201coverall recurrence rate\u201d effect:","text":"<p>Andersen\u2013Gill with robust SE</p>"},{"location":"Survival_Analysis/14-recurrent-events/#162-if-you-believe-event-order-matters","title":"16.2 If you believe event order matters:","text":"<p>PWP total-time or gap-time</p>"},{"location":"Survival_Analysis/14-recurrent-events/#163-if-you-believe-subjects-have-different-baseline-recurrence-tendencies","title":"16.3 If you believe subjects have different baseline recurrence tendencies:","text":"<p>frailty model (random effect per subject)</p> <p>Often, analysts do:  - AG as primary  - PWP as sensitivity analysis  - frailty as additional robustness check</p>"},{"location":"Survival_Analysis/14-recurrent-events/#17-reporting-recurrent-event-results-biostat-style","title":"17. Reporting recurrent-event results (biostat style)","text":"<p>Example:</p> <p>\u201cRecurrent hospitalizations were analyzed using an Andersen\u2013Gill Cox model with robust sandwich standard errors clustered by subject. Treatment reduced the hospitalization hazard (HR 0.72, 95% CI \u2026).\u201d</p> <p>For PWP:</p> <p>\u201cEvent-order was accounted for using PWP models stratified by event number.\u201d</p> <p>Always report:  - model type (AG / PWP)  - use of robust SE / frailty  - what time scale (total-time vs gap-time)  - interpretation of HR</p>"},{"location":"Survival_Analysis/14-recurrent-events/#18-common-mistakes","title":"18. Common mistakes","text":""},{"location":"Survival_Analysis/14-recurrent-events/#mistake-1-treat-repeated-events-as-independent-rows-without-clustering-correction","title":"Mistake 1: treat repeated events as independent rows without clustering correction","text":"<p>This underestimates SE.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#mistake-2-ignore-death-as-terminal-event","title":"Mistake 2: ignore death as terminal event","text":"<p>Death ends recurrence. Treating it as censoring might be informative.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#mistake-3-interpret-ag-hr-as-first-event-effect","title":"Mistake 3: interpret AG HR as first-event effect","text":"<p>AG HR is about overall recurrence hazard, not first-event survival.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#mistake-4-too-few-events-per-subject-but-still-using-complex-models","title":"Mistake 4: too few events per subject but still using complex models","text":"<p>If almost everyone has 0\u20131 events, use standard Cox.</p>"},{"location":"Survival_Analysis/14-recurrent-events/#19-key-takeaways","title":"19. Key takeaways","text":"<ul> <li>Recurrent events require start\u2013stop counting-process data.</li> <li>Within-subject correlation must be handled (robust SE, frailty, event-strata).</li> <li>Andersen\u2013Gill is the common baseline recurrent-event model.</li> <li>PWP models incorporate event order (total-time / gap-time).</li> <li>R has best support; Python can approximate via time-varying Cox.</li> </ul>"},{"location":"Survival_Analysis/14-recurrent-events/#20-exercises","title":"20. Exercises","text":"Click to try   1. Simulate recurrent events with strong treatment effect and fit AG model. Interpret HR.    2. Fit PWP total-time and compare with AG. Does effect change?    3. Fit PWP gap-time and interpret what changes.    4. Increase within-subject heterogeneity (frailty variance) and see how robust SE changes inference.    5. Write a \u201cMethods\u201d paragraph describing recurrent-event analysis of hospitalizations."},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/","title":"Survival Analysis Reporting, Tables, and Publication-Quality Plots","text":"<p>You now know the core survival methods. The next step is to present results like a real biostatistics paper.</p> <p>This chapter focuses on:</p> <ul> <li>what to report (minimum standards)  </li> <li>how to write survival results in Methods + Results  </li> <li>publication-quality KM plots with number-at-risk tables  </li> <li>Cox regression tables with HR, CI, p-values  </li> <li>common reporting mistakes to avoid  </li> <li>Python + R code for clean outputs  </li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#1-what-survival-analysis-results-should-include","title":"1. What survival analysis results should include","text":""},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#11-kaplanmeier-km","title":"1.1 Kaplan\u2013Meier (KM)","text":"<p>A KM analysis should report:</p> <ul> <li>definition of time origin and endpoint</li> <li>number of subjects and number of events</li> <li>median follow-up time (often)</li> <li>median survival with 95% CI (or \u201cnot reached\u201d)</li> <li>survival probabilities at clinically relevant times (1-year, 5-year)</li> <li>KM plot with censor ticks and number-at-risk table</li> <li>group comparison p-value (log-rank)</li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#12-cox-regression","title":"1.2 Cox regression","text":"<p>A Cox analysis should report:</p> <ul> <li>covariates included (and why)</li> <li>HR, 95% CI, p-values</li> <li>PH assumption checks (Schoenfeld)</li> <li>model performance (optional but common: concordance/C-index)</li> <li>how missing data was handled</li> <li>robust SE or clustering strategy if applicable</li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#2-recommended-workflow","title":"2. Recommended workflow","text":"<p>A typical clinical paper flow:</p> <p>1) Descriptive summary: baseline table (not covered deeply here)  2) KM curves by group + log-rank p-value  3) Cox model (unadjusted then adjusted)  4) PH checks  5) Sensitivity analyses   6) Report clinically meaningful estimates (5-year survival, median)</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#3-a-methods-template-paragraph","title":"3. A \u201cMethods\u201d template paragraph","text":""},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#31-methods-paragraph-km-log-rank-cox","title":"3.1 Methods paragraph (KM + log-rank + Cox)","text":"<p>Time-to-event was defined as time from [time zero] to [event definition]. Patients without an event were censored at last follow-up. Kaplan\u2013Meier methods were used to estimate survival functions and median survival times with 95% confidence intervals. Survival distributions were compared using the log-rank test. Cox proportional hazards regression was used to estimate hazard ratios (HRs) and 95% confidence intervals, adjusting for [covariates]. Proportional hazards assumptions were assessed using Schoenfeld residuals. All analyses were conducted in [R/Python], and statistical tests were two-sided with \u03b1=0.05.</p> <p>Replace:  - [time zero]  - [event definition]  - [covariates]  - [R/Python]</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#4-a-results-template-paragraph","title":"4. A \u201cResults\u201d template paragraph","text":"<p>Among N patients, E events occurred during follow-up. Median follow-up was M months. The Kaplan\u2013Meier estimated median survival was X months (95% CI: L\u2013U). Five-year survival was S (95% CI: L\u2013U). Survival differed between groups (log-rank p=...). In univariable Cox regression, treatment was associated with [higher/lower] hazard (HR ..., 95% CI ..., p=...). After adjustment for age, sex, and stage, the association remained [similar/attenuated] (adjusted HR ..., 95% CI ..., p=...). No violation of proportional hazards was observed based on Schoenfeld residuals.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#5-publication-quality-kaplanmeier-plots","title":"5. Publication-quality Kaplan\u2013Meier plots","text":"<p>What makes a plot \u201cpublication quality\u201d?</p> <ul> <li>clear labels + units  </li> <li>censor tick marks  </li> <li>confidence bands (optional)  </li> <li>number-at-risk table  </li> <li>clean style and legible fonts  </li> <li>not over-cluttered  </li> <li>shows group legend clearly  </li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#part-a-r","title":"PART A \u2014 R","text":"<p>R ecosystem is strongest for survival plotting via <code>survminer</code>.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#6a-r-km-plot-risk-table-survminer","title":"6A. R: KM plot + risk table (survminer)","text":""},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#6a1-example-data-simulation","title":"6A.1 Example data simulation","text":"<p>R</p> <pre><code>set.seed(55)\n\nn &lt;- 300\ngroup &lt;- rbinom(n, 1, 0.5)\nage &lt;- rnorm(n, 60, 10)\n\n# Different hazards for groups\nT0 &lt;- rexp(sum(group==0), rate=1/10)\nT1 &lt;- rexp(sum(group==1), rate=1/14)\nT &lt;- c(T0, T1)\n\nC &lt;- runif(n, 2, 18)\n\ntime &lt;- pmin(T, C)\nevent &lt;- as.integer(T &lt;= C)\n\ndf &lt;- data.frame(time=time, event=event, group=factor(group, labels=c(\"Control\",\"Treatment\")), age=age)\n\nhead(df)\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#6a2-km-fit-log-rank","title":"6A.2 KM fit + log-rank","text":"<p>R</p> <pre><code>library(survival)\n\nfit_km &lt;- survfit(Surv(time, event) ~ group, data=df)\nfit_km\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#6a3-publication-km-plot-risk-table","title":"6A.3 Publication KM plot (risk table)","text":"<p>R</p> <pre><code># install.packages(\"survminer\") # if needed\nlibrary(survminer)\n\nggsurvplot(\n  fit_km, data=df,\n  conf.int=TRUE,\n  risk.table=TRUE,\n  censor=TRUE,\n  pval=TRUE,\n  xlab=\"Time (months)\",\n  ylab=\"Survival probability\",\n  title=\"Kaplan\u2013Meier Survival by Group\",\n  legend.title=\"Group\",\n  ggtheme=theme_minimal()\n)\n</code></pre> <p>This produces:  - KM curve with CI  - censor ticks  - log-rank p-value  - number-at-risk table</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#7a-r-extracting-survival-at-fixed-times-table-ready","title":"7A. R: Extracting survival at fixed times (table-ready)","text":"<p>R</p> <pre><code>times &lt;- c(6, 12, 24)\n\ns &lt;- summary(fit_km, times=times)\n\nout &lt;- data.frame(\n  group = rep(names(s$strata), each=length(times)),\n  time = s$time,\n  surv = s$surv,\n  lower = s$lower,\n  upper = s$upper\n)\n\nout\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#8a-r-cox-regression-table-hr-ci-p-value","title":"8A. R: Cox regression table (HR, CI, p-value)","text":"<p>R</p> <pre><code>fit_cox &lt;- coxph(Surv(time, event) ~ group + age, data=df)\nsummary(fit_cox)\n</code></pre> <p>To create a nice table:</p> <p>R</p> <pre><code>hr &lt;- exp(coef(fit_cox))\nci &lt;- exp(confint(fit_cox))\np &lt;- summary(fit_cox)$coefficients[,5]\n\ntable_out &lt;- data.frame(\n  Variable = names(hr),\n  HR = hr,\n  CI_lower = ci[,1],\n  CI_upper = ci[,2],\n  p_value = p\n)\n\ntable_out\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#9a-r-ph-check-reporting-coxzph","title":"9A. R: PH check reporting (cox.zph)","text":"<p>R</p> <pre><code>z &lt;- cox.zph(fit_cox)\nz\nplot(z)\n</code></pre> <p>Methods writing:</p> <p>\u201cProportional hazards assumptions were assessed with Schoenfeld residuals.\u201d</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#part-b-python-clean-plotting-tables","title":"PART B \u2014 PYTHON (clean plotting + tables)","text":"<p>Python can do excellent survival analysis with lifelines, but risk tables require manual work or custom plotting.</p> <p>We give a clean practical pipeline.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#10b-python-km-plot-with-ci-and-censor-ticks","title":"10B. Python: KM plot with CI and censor ticks","text":""},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#10b1-simulate-data","title":"10B.1 Simulate data","text":"<p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\nnp.random.seed(55)\n\nn = 300\ngroup = np.random.binomial(1, 0.5, n)\nage = np.random.normal(60, 10, n)\n\nT0 = np.random.exponential(10, (group==0).sum())\nT1 = np.random.exponential(14, (group==1).sum())\nT = np.concatenate([T0, T1])\n\nC = np.random.uniform(2, 18, n)\n\ntime = np.minimum(T, C)\nevent = (T &lt;= C).astype(int)\n\ndf = pd.DataFrame({\"time\": time, \"event\": event, \"group\": group, \"age\": age})\ndf.head()\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#10b2-km-plot","title":"10B.2 KM plot","text":"<p>Python</p> <pre><code>import matplotlib.pyplot as plt\nfrom lifelines import KaplanMeierFitter\n\nkm0 = KaplanMeierFitter()\nkm1 = KaplanMeierFitter()\n\nax = plt.subplot(111)\n\nkm0.fit(df.loc[df.group==0, \"time\"], df.loc[df.group==0, \"event\"], label=\"Control\").plot(ax=ax, ci_show=True)\nkm1.fit(df.loc[df.group==1, \"time\"], df.loc[df.group==1, \"event\"], label=\"Treatment\").plot(ax=ax, ci_show=True)\n\nplt.title(\"Kaplan\u2013Meier Survival by Group\")\nplt.xlabel(\"Time (months)\")\nplt.ylabel(\"Survival probability\")\nplt.show()\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#11b-python-number-at-risk-table","title":"11B. Python: number-at-risk table","text":"<p>We compute number at risk at chosen times.</p> <p>Python</p> <pre><code>import numpy as np\nimport pandas as pd\n\ntimes = [0, 6, 12, 18]\n\ndef n_at_risk(df_sub, times):\n    return [int((df_sub[\"time\"] &gt;= t).sum()) for t in times]\n\nrisk = pd.DataFrame({\n    \"time\": times,\n    \"Control\": n_at_risk(df[df.group==0], times),\n    \"Treatment\": n_at_risk(df[df.group==1], times)\n})\n\nrisk\n</code></pre> <p>You can print this table under the plot in MkDocs, or convert to markdown.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#12b-python-log-rank-p-value","title":"12B. Python: log-rank p-value","text":"<p>Python</p> <pre><code>from lifelines.statistics import logrank_test\n\nres = logrank_test(\n    df.loc[df.group==0, \"time\"],\n    df.loc[df.group==1, \"time\"],\n    event_observed_A=df.loc[df.group==0, \"event\"],\n    event_observed_B=df.loc[df.group==1, \"event\"]\n)\n\nres.p_value, res.test_statistic\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#13b-python-cox-regression-table","title":"13B. Python: Cox regression table","text":"<p>Python</p> <pre><code>from lifelines import CoxPHFitter\n\ndf2 = df.copy()\ndf2[\"group\"] = df2[\"group\"].astype(int)\n\ncph = CoxPHFitter()\ncph.fit(df2[[\"time\",\"event\",\"group\",\"age\"]], duration_col=\"time\", event_col=\"event\")\n\ncph.summary\n</code></pre> <p>To produce a clean HR table:</p> <p>Python</p> <pre><code>out = cph.summary.copy()\nout[\"HR\"] = np.exp(out[\"coef\"])\nout[\"CI_lower\"] = np.exp(out[\"coef lower 95%\"])\nout[\"CI_upper\"] = np.exp(out[\"coef upper 95%\"])\n\nout[[\"HR\",\"CI_lower\",\"CI_upper\",\"p\"]]\n</code></pre>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#14-reporting-checklist","title":"14. Reporting checklist","text":""},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#km","title":"KM","text":"<ul> <li>Define time zero and event precisely</li> <li>Report N, events, censoring</li> <li>Show KM curve with censor ticks</li> <li>Provide median survival + CI (or not reached)</li> <li>Provide survival at relevant times + CI</li> <li>Provide number at risk table</li> <li>Log-rank p-value</li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#cox","title":"Cox","text":"<ul> <li>Report covariates and coding</li> <li>HR + 95% CI + p-value</li> <li>Check PH (Schoenfeld)</li> <li>Handle clustering if needed</li> <li>Mention missing data handling</li> <li>Provide model performance </li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#15-common-reporting-mistakes","title":"15. Common reporting mistakes","text":""},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#mistake-1-survival-differed-without-p-value-or-effect-size","title":"Mistake 1: \u201cSurvival differed\u201d without p-value or effect size","text":"<p>Fix: report log-rank p and Cox HR.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#mistake-2-hr-reported-without-ci","title":"Mistake 2: HR reported without CI","text":"<p>Fix: always include 95% CI.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#mistake-3-median-survival-with-no-time-unit","title":"Mistake 3: \u201cMedian survival\u201d with no time unit","text":"<p>Fix: specify months/years.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#mistake-4-not-stating-censoring-rules","title":"Mistake 4: not stating censoring rules","text":"<p>Fix: define censoring explicitly.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#mistake-5-not-checking-ph","title":"Mistake 5: not checking PH","text":"<p>Fix: report Schoenfeld-based check.</p>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#16-key-takeaways","title":"16. Key takeaways","text":"<ul> <li>Good survival reporting requires both estimates and uncertainty.</li> <li>Use KM + risk table + log-rank for descriptive comparison.</li> <li>Use Cox for adjusted HR with CI and p-values.</li> <li>Always mention PH checking.</li> <li>Use R survminer for best publication plots; Python lifelines is strong but risk tables are manual.</li> </ul>"},{"location":"Survival_Analysis/15-survival-analysis-summary-workflow/#17-exercises","title":"17. Exercises","text":"Click to try   1. Make a KM plot with risk table (R) and replicate the same in Python using manual risk table.    2. Write a Methods paragraph for a study with time-to-relapse outcome.    3. Write a Results paragraph reporting median survival and adjusted HR.    4. Fit Cox, check PH, and report how you would write it in a paper.    5. Create a table of 1-, 3-, 5-year survival with 95% CI for each group."}]}